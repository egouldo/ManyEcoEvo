---
# Example from https://joss.readthedocs.io/en/latest/submitting.html
title: 'ManyEcoEvo: an R package for working with the "Same Data, Different Analysts" Project in Ecology and Evolutionary Biology, and other many-analyst style data'
tags:
  - R
  - meta-analysis
  - metaresearch
  - ecology
  - evolutionary biology
  - many-analysts
authors:
  - name: Elliot Gould
    orcid: 0000-0003-0872-7098
    affiliation: "1" 
  - name: Hannah S. Fraser
    orcid: 0000-0000-0000-0000
    affiliation: "1"
  - name: Shinichi Nakagawa
    orcid: 0000-0000-0000-0000
    affiliation: "2"
  - name: Timothy H. Parker
    orcid: 0000-0000-0000-0000
    affiliation: "3"
affiliations:
 - name: The University of Melbourne
   index: 1
 - name: The University of New South Wales
   index: 2
 - name: Whitman College
   index: 3
citation_author: Gould and Fraser et al. 
date: "`r Sys.Date()`"
year: 2025
bibliography: paper.bib
output: 
  # word_document: default
  rticles::joss_article:
    journal: JOSS
csl: apa.csl
---

```{r setup, echo=FALSE, message=FALSE}
# library(ManyEcoEvo)
devtools::load_all()
library(dplyr)
library(metafor)
library(tidyverse)
set.seed(1)
knitr::opts_chunk$set(
  # collapse = TRUE,
  # comment = "#>",
  # fig.width = 7,
  # fig.height = 5,
  message = FALSE,
  warning = FALSE
)
```

# Summary

Many-analyst studies are a format of crowd-sourced scientific analysis [@schweinsberg2021], where analysts simultaneously, but independently, research the same research question, using the same dataset [@Voracek2019; @silberzahn2018]. Many-analyst studies demonstrate how subjective, often arbitrary and usually defensible analysis decisions may influence research results [@silberzahn2018] due to either disagreement among researchers or due to analytic uncertainty about choices such as which observations to include and what data-analysis strategy is most appropriate [@Voracek2019]. Managing the analysis pipelines to implement many-analyst studies is complex and best implemented with dedicated software.

Typical scientific approaches proceed with a single team publishing only one or several ‘analysis specifications,’ or unique sequences of analysis choices. Yet, researchers routinely explore and implement multiple plausible analysis specifications, often without disclosing the full set of ‘garden of forking paths’ they explored, and so the effect of alternative defensible analytic choices is unknown. The growing body of many-analyst, and ‘multiverse’ or ‘specification analysis’ studies, in which a large decision space containing the full set of combinatorial alternatives is implemented and statistically analysed, reveals that researcher degrees of freedom can result in spurious findings, and are susceptible to publication bias, p-hacking and other questionable research practices when undisclosed [@botvinik-nezer2020; @Simonsohn2020; @Olsson-Collentine].

*ManyEcoEvo* is an R package [@RCoreTeam2022] designed to *facilitate the analysis of* an existing many-analyst study in ecology and evolutionary biology, the *ManyEcoEvo Project* [@Gould2025]. The purpose of *ManyEcoEvo* is to reproducibly implement the analysis and presentation of results for Gould *et al.* [-Gould2025] such that the 246 analysts as well as other interested researchers may independently reproduce the study's findings. The package also aims to allow re-analyses and replications of Gould *et al.* [-Gould2025], as well as facilitating the analysis of similar many-analyst style datasets.

The ManyEcoEvo project is a many-analyst study that aimed to empirically explore the variation in effect sizes and model predictions generated by analytical decisions of different researchers within ecology and evolutionary biology [Gould2025]. 174 analyst teams, comprising 246 analysts, independently investigated the answers to two pre-specified research questions using two previously unpublished datasets, one from conservation ecology, and one from evolutionary biology. Analysts investigating the evolutionary biology dataset examined the effect of sibling number and nestling growth of blue tits (*Cyanistes caeruleus*), while analysts investigating the conservation ecology dataset examined the relationship between grass cover and *Eucalyptus* tree seedling recruitment. The ManyEcoEvo project quantified the variation in results among analyses using meta-analysis and additionally sought to understand how features of studies such as, variable selection, random effects structures, qualitative and numeric ratings of the methods by peer-reviewers, influenced deviation from the meta-analytic mean.

All raw data sets and metadata provided to independent teams for analysis are publicly archived at <https://osf.io/qjzby> and <https://osf.io/hdv8m>, respectively. Analyst survey responses and results are provided in the package GitHub repository (<https://github.com/egouldo/ManyEcoEvo/>), which is also archived on Zenodo (<https://doi.org/10.5281/zenodo.10046153>). *ManyEcoEvo* contains tools for data-cleaning and processing tasks encountered when working with many-analyst style data, functions for implementing and reproducing the analysis described inGould *et al.* [-Gould2025], establishes a structured workflow that facilitates re-analyses and replications of Gould *et al.* [-Gould2025] as well as implementation for new many-analyst studies, including a planned extension of the ManyEcoEvo project.

# Statement of Need

The last ten years has seen the growing emergence of many-analyst projects, [e.g. @silberzahn2018; @botvinik-nezer2020; @huntington-klein2021; @schweinsberg2021; @breznau2022; @hoogeveen2022many; @coretta2023], predominantly in the disciplines of psychology and social and behavioural sciences. Given the increasing attention on the reproducibility crisis, it is expected that more of these types of studies will be published in the near future across other disciplines. Moreover, collaborative and distributed big team open science projects are increasingly common in ecology and evolutionary biology (e.g. NutNet and DragNet [nutnet.org/index.php/](https://nutnet.org/index.php/){.uri}; ManyBirds [themanybirds.com](http://themanybirds.com){.uri}) as well as other disciplines [ManyBabies @ManyBabies , ManyPrimates @ManyPrimates] which pose computationally analogous data-manipulation and analysis problems to the many-analyst workflow addressed by the *ManyEcoEvo* approach.

The *ManyEcoEvo* package was created to implement the analysis for the 'Same Data, Many Analysts in Ecology and Evolutionary Biology' project [@Gould2025]. We opted to develop this research compendium as an R package as we find it best encapsulates the principles of 'clean code' for effective communication of the science [@Filazzola2022], and therefore facilitates future reproduction, replication and potential synthesis [@Marwick2018; @Vuorre2021].

The results of some many-analyst studies have been controversial, yielding re-analyses criticising the original implementation of some many-analyst studies. For example, [@Auspurg2021] re-analysed part of the seminal 'Red-Card' many-analyst study examining the influence of whether referees were more likely to give red cards to soccer players with dark skin tone than those with light skin tone [@silberzahn2018]. By providing the code and data for Gould *et al.* [-@Gould2025] in the *ManyEcoEvo* package, we allow similar re-analyses of the ‘Same Data, Many Analysts in Ecology and Evolutionary Biology’, wherein ManyEcoEvo can be used to re-run the analysis in [@Gould2025] with slightly different methods, or subsets of data in order to verify and examine the robustness of our findings. We also provide infrastructure to support others performing many-analyst studies.

We are not aware of any R packages or software in other languages exclusively focussed on facilitating many-analyst style studies. Existing many-analyst code if shared, is written as R scripts tailored to that study's analysis (e.g. <https://github.com/manybabies/mb1-analysis-public>, <https://github.com/many-speech-analyses/many_analyses>). However, there are a range of existing packages with select functionality that addresses various components of many-analyst style analyses, namely meta-analysis, its associated preparation and visualisation, as well as the visualisation component of specification curve analysis / multiverse analysis. Our package unites the functions of these packages to provide a selection of tools that are customized to the needs of a many-analyst project. In a many-analyst study, multiple researchers submit their analyses and results. The submitted data must be cleaned and prepared for meta-analysis and other model analysis, then subjected to model checking, statistic extraction and visualisation [@aczel2021].

We provide a suite of miscellaneous functions for data cleaning and processing tasks that we expect to be common to the sorts of data collected by many-analyst style studies. This was the most time and effort-intensive aspect of the analysis in Gould *et al.* [-Gould2025], and we hope these functions will ease the burden on future researchers conducting many-analyst studies.

*ManyEcoEvo* provides custom functions to calculate standardised effect sizes in the form of Fishers' Z correlation scores in preparation for meta-analysis. While some existing functions exist within other packages [e.g. `DescTools::FishersZ()` @DescTools, `DiagTest3Grp::FisherZ.var()` @luo2012diagtest3grp], the method for calculating variance of the standardised effect size in Gould *et al.* [-Gould2025] differed slightly, and we wished to avoid reliance on too many external packages [@wickham2023r, Chapter 10.1]. Should *ManyEcoEvo* users wish to deviate from the effect-size standardisation method used in Gould *et al.* [-Gould2025], they are free to use their own functions provided by other software or custom functions [@harrer2021, see chapter 3 for a range of R code to calculate various effect sizes].

The two most commonly used software packages for undertaking meta-analysis in R are `metafor::` [@Viechtbauer:2010ks; @Viechtbauer2017] and `meta::` [@Balduzzi2019; @lortie2020]. We provide functions for fitting the exact meta-analysis models used in Gould *et al.* [-@Gould2025], which were implemented with the `metafor::` package [@Viechtbauer2017]. However, *ManyEcoEvo* users are free to supply alternative model-fitting functions should they wish to deviate from these specified models. After model-fitting and analysis, model checking and extraction of model fit and heterogeneity statistics is implemented using a range of existing packages, including: `performance::` [@ludecke2021], `broom.mixed::` [@Bolker2022], `metafor::` [@Viechtbauer2017]. *ManyEcoEvo* also draws on existing visualisation packages to implement forest plots [`ggforestplot::`, @ggforestplot; @orchaRd], funnel plots [`metafor::` @Viechtbauer2017], and specification curve analysis plots [`specr::` @Masur2020] to examine the influence of analysis specifications on variation in analysis outcomes. Select functions from the above packages have been thoughtfully abstracted and coded into wrapper functions according to a principled and structured workflow (described below) for ease of application and generalisation to alternative datasets.

# Same Data, Different Analysts: variation in effect sizes due to analytical decisions in ecology and evolutionary biology


The ManyEcoEvo dataset contains anonymised analyst responses for two research questions: one examining blue tit nestling growth (evolutionary biology) and another examining eucalyptus seedling recruitment (conservation ecology).

```{r}
# Load the built-in dataset
data("ManyEcoEvo")
# Examine the basic structure
ManyEcoEvo
glimpse(ManyEcoEvo)
```

The data is structured with list-columns:

-    `data`: Contains the effect size estimates and analysis metadata for each dataset
-    `diversity_data`: Contains information about variables used by each analysis team

We will work with a subset of the the Blue tit dataset for illustration purposes.

```{r}
# Key columns for effect size analysis
key_cols <- c("id_col", "TeamIdentifier", "beta_estimate", "beta_SE", 
              "sample_size", "adjusted_df", "dataset", "mixed_model")

analysis_data <- ManyEcoEvo %>% 
  mutate(
    data = map(data, ~ .x %>% 
                  # mutate(study_id = id_col) %>% 
                 filter(if_all(all_of(key_cols), ~ !is.na(.))) %>% 
      slice_sample(n = 25) %>%
      arrange(TeamIdentifier, analysis_id)
    ),
    diversity_data = map2(diversity_data, data, ~ 
      semi_join(.x, .y, by = "id_col")
    )
  )

effect_sizes <- analysis_data %>% 
  pluck("data", 1) %>% 
  select(all_of(key_cols))

head(effect_sizes)
```

Each row represents a unique analysis (`id_col`), potentially with multiple analyses per team (`TeamIdentifier`).

## Analysing the Blue tit dataset

### Data Preparation for Meta-analysis

The first step in any meta-analysis is ensuring that the estimands of interest – in this case, effect sizes as correlation coefficients – are on the same response scale to ensure that we are not 'comparing apples to oranges.'

The meta-analyses in the ManyEcoEvo project are performed on Fishers' Z transformed correlation coefficients $Z_r$ with the function `est_to_zr()`, which is called b `standardise_response()`, adding columns of standardised estimates `Zr` and their variance `VZr`:

```{r}

standardised_effect_sizes <- effect_sizes %>% 
  standardise_response(estimate_type = "Zr")

standardised_effect_sizes %>% glimpse()
```

Now that we have standardised the analysts' estimates, we can progress to conducting our meta-analysis.

### Meta-analysis and Univariate Analyses

We fit a metaregression to the standardised effect sizes, using the `metafor::` package, with nested random effects:

```{r}
standardised_effect_sizes <- standardised_effect_sizes %>% 
    mutate(study_id = id_col)

ma_model <- fit_MA_mv(
  effects_analysis = standardised_effect_sizes,
  outcome_colname = "Zr",
  outcome_SE_colname = "VZr", 
  estimate_type = "Zr"
)

summary(ma_model)
```

#### Calculate inputs for univariate analyses

Calculate deviation of $Z_r$ from the meta-analytic mean for each analysis `id_col`, then Box-Cox transform each deviation score:

```{r}
effect_size_data <- standardised_effect_sizes %>% 
  calculate_deviation_score(
                          meta_analytic_model = ma_model,
                          outcome_colname = "Zr"
                          ) %>% 
  # select(starts_with("abs_deviation_score_"))
  box_cox_transform(dataset = "blue tit",
                    outcome_SE_colname = "VZr")
```

Calculate mean Sorensen's diversity index for each analysis:

```{r}

# Extract diversity data
diversity_data <- analysis_data %>% 
  pluck("diversity_data", 1)

mean_sorensen_data <- 
  diversity_data %>% 
  calculate_sorensen_diversity_index(.id = "id_col")

mean_sorensen_data
```

#### Regression on distinctiveness of analysis variables

Join required `mean_diversity_indices` into `effect_size_data` and fit a univariate `glm::` model of deviation scores on mean Sorensen's diversity index. Note that the returned model is fitted using `parsnip::`.

```{r}
effect_size_data <- effect_size_data %>%
  left_join(mean_sorensen_data, 
            by = join_by(id_col))

diversity_model <- fit_sorensen_glm(effect_size_data)
diversity_model # View model summary
```

#### Visualise Results

Create a forest plot for the blue tit meta-analysis:

```{r include=FALSE}
get_forest_plot_data(ma_model) %>% 
  plot_forest(intercept = TRUE)
```

Create a marginal effects plot for the univariate analysis on the distinctiveness of variables, back-transforming the response variables for easier interpretation:

```{r}

plot_effects_diversity(mod = diversity_model, 
                       df = effect_size_data , 
                       back_transform = TRUE)
```

## Scaling Up

We conducted further univariate regressions to quantify the effects of different analysis features on heterogeneity among analysts' results in addition to the distinctiveness of variables in each analysis, as we illustrated above. We also performed the full analysis on a second dataset, the Eucalyptus dataset, and repeated the analysis on different outcome variables (point predictions from analysts' models, not shown in this manuscript), and different subsets of data (e.g., with outliers removed, with poorly rated analyses, among others).

To make conducting multiple analyses easier and to facilitate scaling up the analysis pipeline for repeated application over different analysis questions, data subsets, and outcome variables, we provide a selection of 'wrapper' functions. The wrapper frameworks utilise the tidyverse's (ref) list-column data structures and iteration with `purrr::` (ref purrr and R4ds list-cols + iteration). Here, we illustrate the simplest case demonstrating this functionality, standardising the estimates in the Blue tit and Eucalyptus datasets, and computing the Sorensen diversity indices, and meta-analysing both datasets (separately) before constructing outputs for further visualisation.

```{r, message =FALSE, warning=FALSE, results = 'hide'}

meta_analysis_results <- 
  analysis_data %>% 
  prepare_response_variables(
    estimate_type = "Zr",
    dataset_standardise = 
      c("blue tit", "eucalyptus")) %>% 
  compute_MA_inputs() %>% 
  meta_analyse_datasets() %>% 
  make_viz()
```

The `make_viz()` function creates many other visualisation and summary objects for easy extraction:

```{r}
# Extract heterogeneity statistics
meta_analysis_results %>% 
  select(dataset, MA_fit_stats) %>%
    unnest(MA_fit_stats) %>% 
  drop_na()

# Model fit statistics for univariate model of effect of peer-review ratings on heterogeneity
meta_analysis_results %>% 
  filter(model_name == "box_cox_rating_cat") %>% 
  select(dataset, mod_fit_stats) %>% 
  unnest(c(dataset, mod_fit_stats))
```



<!-- # CRediT Author Statement -->

<!-- # Acknowledgements -->

<!-- We acknowledge the contributions of all 246 analysts and co-authors of Gould *et al. [-Gould2025]* please see the original manuscript for a full list of contributors to the ManyEcoEvo project. -->

<!-- - [ ] Copy from Many Analysts paper - nothing for HF. -->

<!-- EG is supported by an Australian Government Research Training Program Scholarship. -->

# References
