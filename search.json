[{"path":[]},{"path":"https://egouldo.github.io/ManyEcoEvo/CODE_OF_CONDUCT.html","id":"our-pledge","dir":"","previous_headings":"","what":"Our Pledge","title":"Contributor Covenant Code of Conduct","text":"members, contributors, leaders pledge make participation community harassment-free experience everyone, regardless age, body size, visible invisible disability, ethnicity, sex characteristics, gender identity expression, level experience, education, socio-economic status, nationality, personal appearance, race, religion, sexual identity orientation. pledge act interact ways contribute open, welcoming, diverse, inclusive, healthy community.","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/CODE_OF_CONDUCT.html","id":"our-standards","dir":"","previous_headings":"","what":"Our Standards","title":"Contributor Covenant Code of Conduct","text":"Examples behavior contributes positive environment community include: Demonstrating empathy kindness toward people respectful differing opinions, viewpoints, experiences Giving gracefully accepting constructive feedback Accepting responsibility apologizing affected mistakes, learning experience Focusing best just us individuals, overall community Examples unacceptable behavior include: use sexualized language imagery, sexual attention advances kind Trolling, insulting derogatory comments, personal political attacks Public private harassment Publishing others’ private information, physical email address, without explicit permission conduct reasonably considered inappropriate professional setting","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/CODE_OF_CONDUCT.html","id":"enforcement-responsibilities","dir":"","previous_headings":"","what":"Enforcement Responsibilities","title":"Contributor Covenant Code of Conduct","text":"Community leaders responsible clarifying enforcing standards acceptable behavior take appropriate fair corrective action response behavior deem inappropriate, threatening, offensive, harmful. Community leaders right responsibility remove, edit, reject comments, commits, code, wiki edits, issues, contributions aligned Code Conduct, communicate reasons moderation decisions appropriate.","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/CODE_OF_CONDUCT.html","id":"scope","dir":"","previous_headings":"","what":"Scope","title":"Contributor Covenant Code of Conduct","text":"Code Conduct applies within community spaces, also applies individual officially representing community public spaces. Examples representing community include using official e-mail address, posting via official social media account, acting appointed representative online offline event.","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/CODE_OF_CONDUCT.html","id":"enforcement","dir":"","previous_headings":"","what":"Enforcement","title":"Contributor Covenant Code of Conduct","text":"Instances abusive, harassing, otherwise unacceptable behavior may reported community leaders responsible enforcement elliot.gould@unimelb.edu.au. complaints reviewed investigated promptly fairly. community leaders obligated respect privacy security reporter incident.","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/CODE_OF_CONDUCT.html","id":"enforcement-guidelines","dir":"","previous_headings":"","what":"Enforcement Guidelines","title":"Contributor Covenant Code of Conduct","text":"Community leaders follow Community Impact Guidelines determining consequences action deem violation Code Conduct:","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/CODE_OF_CONDUCT.html","id":"id_1-correction","dir":"","previous_headings":"Enforcement Guidelines","what":"1. Correction","title":"Contributor Covenant Code of Conduct","text":"Community Impact: Use inappropriate language behavior deemed unprofessional unwelcome community. Consequence: private, written warning community leaders, providing clarity around nature violation explanation behavior inappropriate. public apology may requested.","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/CODE_OF_CONDUCT.html","id":"id_2-warning","dir":"","previous_headings":"Enforcement Guidelines","what":"2. Warning","title":"Contributor Covenant Code of Conduct","text":"Community Impact: violation single incident series actions. Consequence: warning consequences continued behavior. interaction people involved, including unsolicited interaction enforcing Code Conduct, specified period time. includes avoiding interactions community spaces well external channels like social media. Violating terms may lead temporary permanent ban.","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/CODE_OF_CONDUCT.html","id":"id_3-temporary-ban","dir":"","previous_headings":"Enforcement Guidelines","what":"3. Temporary Ban","title":"Contributor Covenant Code of Conduct","text":"Community Impact: serious violation community standards, including sustained inappropriate behavior. Consequence: temporary ban sort interaction public communication community specified period time. public private interaction people involved, including unsolicited interaction enforcing Code Conduct, allowed period. Violating terms may lead permanent ban.","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/CODE_OF_CONDUCT.html","id":"id_4-permanent-ban","dir":"","previous_headings":"Enforcement Guidelines","what":"4. Permanent Ban","title":"Contributor Covenant Code of Conduct","text":"Community Impact: Demonstrating pattern violation community standards, including sustained inappropriate behavior, harassment individual, aggression toward disparagement classes individuals. Consequence: permanent ban sort public interaction within community.","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/CODE_OF_CONDUCT.html","id":"attribution","dir":"","previous_headings":"","what":"Attribution","title":"Contributor Covenant Code of Conduct","text":"Code Conduct adapted Contributor Covenant, version 2.0, available https://www.contributor-covenant.org/version/2/0/code_of_conduct.html. Community Impact Guidelines inspired Mozilla’s code conduct enforcement ladder. answers common questions code conduct, see FAQ https://www.contributor-covenant.org/faq. Translations available https://www.contributor-covenant.org/translations.","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/CONTRIBUTING.html","id":null,"dir":"","previous_headings":"","what":"Contributing to ManyEcoEvo","title":"Contributing to ManyEcoEvo","text":"outlines propose change ManyEcoEvo. detailed discussion contributing tidyverse packages, please see development contributing guide code review principles.","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/CONTRIBUTING.html","id":"fixing-typos","dir":"","previous_headings":"","what":"Fixing typos","title":"Contributing to ManyEcoEvo","text":"can fix typos, spelling mistakes, grammatical errors documentation directly using GitHub web interface, long changes made source file. generally means ’ll need edit roxygen2 comments .R, .Rd file. can find .R file generates .Rd reading comment first line.","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/CONTRIBUTING.html","id":"bigger-changes","dir":"","previous_headings":"","what":"Bigger changes","title":"Contributing to ManyEcoEvo","text":"want make bigger change, ’s good idea first file issue make sure someone team agrees ’s needed. ’ve found bug, please file issue illustrates bug minimal reprex (also help write unit test, needed). See guide create great issue advice.","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/CONTRIBUTING.html","id":"pull-request-process","dir":"","previous_headings":"Bigger changes","what":"Pull request process","title":"Contributing to ManyEcoEvo","text":"Fork package clone onto computer. haven’t done , recommend using usethis::create_from_github(\"egouldo/ManyEcoEvo\", fork = TRUE). Install development dependencies devtools::install_dev_deps(), make sure package passes R CMD check running devtools::check(). R CMD check doesn’t pass cleanly, ’s good idea ask help continuing. Create Git branch pull request (PR). recommend using usethis::pr_init(\"brief-description--change\"). Make changes, commit git, create PR running usethis::pr_push(), following prompts browser. title PR briefly describe change. body PR contain Fixes #issue-number. user-facing changes, add bullet top NEWS.md (.e. just first header). Follow style described https://style.tidyverse.org/news.html.","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/CONTRIBUTING.html","id":"code-style","dir":"","previous_headings":"Bigger changes","what":"Code style","title":"Contributing to ManyEcoEvo","text":"New code follow tidyverse style guide. can use styler package apply styles, please don’t restyle code nothing PR. use roxygen2, Markdown syntax, documentation. use testthat unit tests. Contributions test cases included easier accept.","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/CONTRIBUTING.html","id":"code-of-conduct","dir":"","previous_headings":"","what":"Code of Conduct","title":"Contributing to ManyEcoEvo","text":"Please note ManyEcoEvo project released Contributor Code Conduct. contributing project agree abide terms.","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"GNU General Public License","title":"GNU General Public License","text":"Version 3, 29 June 2007Copyright © 2007 Free Software Foundation, Inc. <http://fsf.org/> Everyone permitted copy distribute verbatim copies license document, changing allowed.","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/LICENSE.html","id":"preamble","dir":"","previous_headings":"","what":"Preamble","title":"GNU General Public License","text":"GNU General Public License free, copyleft license software kinds works. licenses software practical works designed take away freedom share change works. contrast, GNU General Public License intended guarantee freedom share change versions program–make sure remains free software users. , Free Software Foundation, use GNU General Public License software; applies also work released way authors. can apply programs, . speak free software, referring freedom, price. General Public Licenses designed make sure freedom distribute copies free software (charge wish), receive source code can get want , can change software use pieces new free programs, know can things. protect rights, need prevent others denying rights asking surrender rights. Therefore, certain responsibilities distribute copies software, modify : responsibilities respect freedom others. example, distribute copies program, whether gratis fee, must pass recipients freedoms received. must make sure , , receive can get source code. must show terms know rights. Developers use GNU GPL protect rights two steps: (1) assert copyright software, (2) offer License giving legal permission copy, distribute /modify . developers’ authors’ protection, GPL clearly explains warranty free software. users’ authors’ sake, GPL requires modified versions marked changed, problems attributed erroneously authors previous versions. devices designed deny users access install run modified versions software inside , although manufacturer can . fundamentally incompatible aim protecting users’ freedom change software. systematic pattern abuse occurs area products individuals use, precisely unacceptable. Therefore, designed version GPL prohibit practice products. problems arise substantially domains, stand ready extend provision domains future versions GPL, needed protect freedom users. Finally, every program threatened constantly software patents. States allow patents restrict development use software general-purpose computers, , wish avoid special danger patents applied free program make effectively proprietary. prevent , GPL assures patents used render program non-free. precise terms conditions copying, distribution modification follow.","code":""},{"path":[]},{"path":"https://egouldo.github.io/ManyEcoEvo/LICENSE.html","id":"id_0-definitions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"0. Definitions","title":"GNU General Public License","text":"“License” refers version 3 GNU General Public License. “Copyright” also means copyright-like laws apply kinds works, semiconductor masks. “Program” refers copyrightable work licensed License. licensee addressed “”. “Licensees” “recipients” may individuals organizations. “modify” work means copy adapt part work fashion requiring copyright permission, making exact copy. resulting work called “modified version” earlier work work “based ” earlier work. “covered work” means either unmodified Program work based Program. “propagate” work means anything , without permission, make directly secondarily liable infringement applicable copyright law, except executing computer modifying private copy. Propagation includes copying, distribution (without modification), making available public, countries activities well. “convey” work means kind propagation enables parties make receive copies. Mere interaction user computer network, transfer copy, conveying. interactive user interface displays “Appropriate Legal Notices” extent includes convenient prominently visible feature (1) displays appropriate copyright notice, (2) tells user warranty work (except extent warranties provided), licensees may convey work License, view copy License. interface presents list user commands options, menu, prominent item list meets criterion.","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/LICENSE.html","id":"id_1-source-code","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"1. Source Code","title":"GNU General Public License","text":"“source code” work means preferred form work making modifications . “Object code” means non-source form work. “Standard Interface” means interface either official standard defined recognized standards body, , case interfaces specified particular programming language, one widely used among developers working language. “System Libraries” executable work include anything, work whole, () included normal form packaging Major Component, part Major Component, (b) serves enable use work Major Component, implement Standard Interface implementation available public source code form. “Major Component”, context, means major essential component (kernel, window system, ) specific operating system () executable work runs, compiler used produce work, object code interpreter used run . “Corresponding Source” work object code form means source code needed generate, install, (executable work) run object code modify work, including scripts control activities. However, include work’s System Libraries, general-purpose tools generally available free programs used unmodified performing activities part work. example, Corresponding Source includes interface definition files associated source files work, source code shared libraries dynamically linked subprograms work specifically designed require, intimate data communication control flow subprograms parts work. Corresponding Source need include anything users can regenerate automatically parts Corresponding Source. Corresponding Source work source code form work.","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/LICENSE.html","id":"id_2-basic-permissions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"2. Basic Permissions","title":"GNU General Public License","text":"rights granted License granted term copyright Program, irrevocable provided stated conditions met. License explicitly affirms unlimited permission run unmodified Program. output running covered work covered License output, given content, constitutes covered work. License acknowledges rights fair use equivalent, provided copyright law. may make, run propagate covered works convey, without conditions long license otherwise remains force. may convey covered works others sole purpose make modifications exclusively , provide facilities running works, provided comply terms License conveying material control copyright. thus making running covered works must exclusively behalf, direction control, terms prohibit making copies copyrighted material outside relationship . Conveying circumstances permitted solely conditions stated . Sublicensing allowed; section 10 makes unnecessary.","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/LICENSE.html","id":"id_3-protecting-users-legal-rights-from-anti-circumvention-law","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"3. Protecting Users’ Legal Rights From Anti-Circumvention Law","title":"GNU General Public License","text":"covered work shall deemed part effective technological measure applicable law fulfilling obligations article 11 WIPO copyright treaty adopted 20 December 1996, similar laws prohibiting restricting circumvention measures. convey covered work, waive legal power forbid circumvention technological measures extent circumvention effected exercising rights License respect covered work, disclaim intention limit operation modification work means enforcing, work’s users, third parties’ legal rights forbid circumvention technological measures.","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/LICENSE.html","id":"id_4-conveying-verbatim-copies","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"4. Conveying Verbatim Copies","title":"GNU General Public License","text":"may convey verbatim copies Program’s source code receive , medium, provided conspicuously appropriately publish copy appropriate copyright notice; keep intact notices stating License non-permissive terms added accord section 7 apply code; keep intact notices absence warranty; give recipients copy License along Program. may charge price price copy convey, may offer support warranty protection fee.","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/LICENSE.html","id":"id_5-conveying-modified-source-versions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"5. Conveying Modified Source Versions","title":"GNU General Public License","text":"may convey work based Program, modifications produce Program, form source code terms section 4, provided also meet conditions: ) work must carry prominent notices stating modified , giving relevant date. b) work must carry prominent notices stating released License conditions added section 7. requirement modifies requirement section 4 “keep intact notices”. c) must license entire work, whole, License anyone comes possession copy. License therefore apply, along applicable section 7 additional terms, whole work, parts, regardless packaged. License gives permission license work way, invalidate permission separately received . d) work interactive user interfaces, must display Appropriate Legal Notices; however, Program interactive interfaces display Appropriate Legal Notices, work need make . compilation covered work separate independent works, nature extensions covered work, combined form larger program, volume storage distribution medium, called “aggregate” compilation resulting copyright used limit access legal rights compilation’s users beyond individual works permit. Inclusion covered work aggregate cause License apply parts aggregate.","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/LICENSE.html","id":"id_6-conveying-non-source-forms","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"6. Conveying Non-Source Forms","title":"GNU General Public License","text":"may convey covered work object code form terms sections 4 5, provided also convey machine-readable Corresponding Source terms License, one ways: ) Convey object code , embodied , physical product (including physical distribution medium), accompanied Corresponding Source fixed durable physical medium customarily used software interchange. b) Convey object code , embodied , physical product (including physical distribution medium), accompanied written offer, valid least three years valid long offer spare parts customer support product model, give anyone possesses object code either (1) copy Corresponding Source software product covered License, durable physical medium customarily used software interchange, price reasonable cost physically performing conveying source, (2) access copy Corresponding Source network server charge. c) Convey individual copies object code copy written offer provide Corresponding Source. alternative allowed occasionally noncommercially, received object code offer, accord subsection 6b. d) Convey object code offering access designated place (gratis charge), offer equivalent access Corresponding Source way place charge. need require recipients copy Corresponding Source along object code. place copy object code network server, Corresponding Source may different server (operated third party) supports equivalent copying facilities, provided maintain clear directions next object code saying find Corresponding Source. Regardless server hosts Corresponding Source, remain obligated ensure available long needed satisfy requirements. e) Convey object code using peer--peer transmission, provided inform peers object code Corresponding Source work offered general public charge subsection 6d. separable portion object code, whose source code excluded Corresponding Source System Library, need included conveying object code work. “User Product” either (1) “consumer product”, means tangible personal property normally used personal, family, household purposes, (2) anything designed sold incorporation dwelling. determining whether product consumer product, doubtful cases shall resolved favor coverage. particular product received particular user, “normally used” refers typical common use class product, regardless status particular user way particular user actually uses, expects expected use, product. product consumer product regardless whether product substantial commercial, industrial non-consumer uses, unless uses represent significant mode use product. “Installation Information” User Product means methods, procedures, authorization keys, information required install execute modified versions covered work User Product modified version Corresponding Source. information must suffice ensure continued functioning modified object code case prevented interfered solely modification made. convey object code work section , , specifically use , User Product, conveying occurs part transaction right possession use User Product transferred recipient perpetuity fixed term (regardless transaction characterized), Corresponding Source conveyed section must accompanied Installation Information. requirement apply neither third party retains ability install modified object code User Product (example, work installed ROM). requirement provide Installation Information include requirement continue provide support service, warranty, updates work modified installed recipient, User Product modified installed. Access network may denied modification materially adversely affects operation network violates rules protocols communication across network. Corresponding Source conveyed, Installation Information provided, accord section must format publicly documented (implementation available public source code form), must require special password key unpacking, reading copying.","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/LICENSE.html","id":"id_7-additional-terms","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"7. Additional Terms","title":"GNU General Public License","text":"“Additional permissions” terms supplement terms License making exceptions one conditions. Additional permissions applicable entire Program shall treated though included License, extent valid applicable law. additional permissions apply part Program, part may used separately permissions, entire Program remains governed License without regard additional permissions. convey copy covered work, may option remove additional permissions copy, part . (Additional permissions may written require removal certain cases modify work.) may place additional permissions material, added covered work, can give appropriate copyright permission. Notwithstanding provision License, material add covered work, may (authorized copyright holders material) supplement terms License terms: ) Disclaiming warranty limiting liability differently terms sections 15 16 License; b) Requiring preservation specified reasonable legal notices author attributions material Appropriate Legal Notices displayed works containing ; c) Prohibiting misrepresentation origin material, requiring modified versions material marked reasonable ways different original version; d) Limiting use publicity purposes names licensors authors material; e) Declining grant rights trademark law use trade names, trademarks, service marks; f) Requiring indemnification licensors authors material anyone conveys material (modified versions ) contractual assumptions liability recipient, liability contractual assumptions directly impose licensors authors. non-permissive additional terms considered “restrictions” within meaning section 10. Program received , part , contains notice stating governed License along term restriction, may remove term. license document contains restriction permits relicensing conveying License, may add covered work material governed terms license document, provided restriction survive relicensing conveying. add terms covered work accord section, must place, relevant source files, statement additional terms apply files, notice indicating find applicable terms. Additional terms, permissive non-permissive, may stated form separately written license, stated exceptions; requirements apply either way.","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/LICENSE.html","id":"id_8-termination","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"8. Termination","title":"GNU General Public License","text":"may propagate modify covered work except expressly provided License. attempt otherwise propagate modify void, automatically terminate rights License (including patent licenses granted third paragraph section 11). However, cease violation License, license particular copyright holder reinstated () provisionally, unless copyright holder explicitly finally terminates license, (b) permanently, copyright holder fails notify violation reasonable means prior 60 days cessation. Moreover, license particular copyright holder reinstated permanently copyright holder notifies violation reasonable means, first time received notice violation License (work) copyright holder, cure violation prior 30 days receipt notice. Termination rights section terminate licenses parties received copies rights License. rights terminated permanently reinstated, qualify receive new licenses material section 10.","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/LICENSE.html","id":"id_9-acceptance-not-required-for-having-copies","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"9. Acceptance Not Required for Having Copies","title":"GNU General Public License","text":"required accept License order receive run copy Program. Ancillary propagation covered work occurring solely consequence using peer--peer transmission receive copy likewise require acceptance. However, nothing License grants permission propagate modify covered work. actions infringe copyright accept License. Therefore, modifying propagating covered work, indicate acceptance License .","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/LICENSE.html","id":"id_10-automatic-licensing-of-downstream-recipients","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"10. Automatic Licensing of Downstream Recipients","title":"GNU General Public License","text":"time convey covered work, recipient automatically receives license original licensors, run, modify propagate work, subject License. responsible enforcing compliance third parties License. “entity transaction” transaction transferring control organization, substantially assets one, subdividing organization, merging organizations. propagation covered work results entity transaction, party transaction receives copy work also receives whatever licenses work party’s predecessor interest give previous paragraph, plus right possession Corresponding Source work predecessor interest, predecessor can get reasonable efforts. may impose restrictions exercise rights granted affirmed License. example, may impose license fee, royalty, charge exercise rights granted License, may initiate litigation (including cross-claim counterclaim lawsuit) alleging patent claim infringed making, using, selling, offering sale, importing Program portion .","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/LICENSE.html","id":"id_11-patents","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"11. Patents","title":"GNU General Public License","text":"“contributor” copyright holder authorizes use License Program work Program based. work thus licensed called contributor’s “contributor version”. contributor’s “essential patent claims” patent claims owned controlled contributor, whether already acquired hereafter acquired, infringed manner, permitted License, making, using, selling contributor version, include claims infringed consequence modification contributor version. purposes definition, “control” includes right grant patent sublicenses manner consistent requirements License. contributor grants non-exclusive, worldwide, royalty-free patent license contributor’s essential patent claims, make, use, sell, offer sale, import otherwise run, modify propagate contents contributor version. following three paragraphs, “patent license” express agreement commitment, however denominated, enforce patent (express permission practice patent covenant sue patent infringement). “grant” patent license party means make agreement commitment enforce patent party. convey covered work, knowingly relying patent license, Corresponding Source work available anyone copy, free charge terms License, publicly available network server readily accessible means, must either (1) cause Corresponding Source available, (2) arrange deprive benefit patent license particular work, (3) arrange, manner consistent requirements License, extend patent license downstream recipients. “Knowingly relying” means actual knowledge , patent license, conveying covered work country, recipient’s use covered work country, infringe one identifiable patents country reason believe valid. , pursuant connection single transaction arrangement, convey, propagate procuring conveyance , covered work, grant patent license parties receiving covered work authorizing use, propagate, modify convey specific copy covered work, patent license grant automatically extended recipients covered work works based . patent license “discriminatory” include within scope coverage, prohibits exercise , conditioned non-exercise one rights specifically granted License. may convey covered work party arrangement third party business distributing software, make payment third party based extent activity conveying work, third party grants, parties receive covered work , discriminatory patent license () connection copies covered work conveyed (copies made copies), (b) primarily connection specific products compilations contain covered work, unless entered arrangement, patent license granted, prior 28 March 2007. Nothing License shall construed excluding limiting implied license defenses infringement may otherwise available applicable patent law.","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/LICENSE.html","id":"id_12-no-surrender-of-others-freedom","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"12. No Surrender of Others’ Freedom","title":"GNU General Public License","text":"conditions imposed (whether court order, agreement otherwise) contradict conditions License, excuse conditions License. convey covered work satisfy simultaneously obligations License pertinent obligations, consequence may convey . example, agree terms obligate collect royalty conveying convey Program, way satisfy terms License refrain entirely conveying Program.","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/LICENSE.html","id":"id_13-use-with-the-gnu-affero-general-public-license","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"13. Use with the GNU Affero General Public License","title":"GNU General Public License","text":"Notwithstanding provision License, permission link combine covered work work licensed version 3 GNU Affero General Public License single combined work, convey resulting work. terms License continue apply part covered work, special requirements GNU Affero General Public License, section 13, concerning interaction network apply combination .","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/LICENSE.html","id":"id_14-revised-versions-of-this-license","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"14. Revised Versions of this License","title":"GNU General Public License","text":"Free Software Foundation may publish revised /new versions GNU General Public License time time. new versions similar spirit present version, may differ detail address new problems concerns. version given distinguishing version number. Program specifies certain numbered version GNU General Public License “later version” applies , option following terms conditions either numbered version later version published Free Software Foundation. Program specify version number GNU General Public License, may choose version ever published Free Software Foundation. Program specifies proxy can decide future versions GNU General Public License can used, proxy’s public statement acceptance version permanently authorizes choose version Program. Later license versions may give additional different permissions. However, additional obligations imposed author copyright holder result choosing follow later version.","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/LICENSE.html","id":"id_15-disclaimer-of-warranty","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"15. Disclaimer of Warranty","title":"GNU General Public License","text":"WARRANTY PROGRAM, EXTENT PERMITTED APPLICABLE LAW. EXCEPT OTHERWISE STATED WRITING COPYRIGHT HOLDERS /PARTIES PROVIDE PROGRAM “” WITHOUT WARRANTY KIND, EITHER EXPRESSED IMPLIED, INCLUDING, LIMITED , IMPLIED WARRANTIES MERCHANTABILITY FITNESS PARTICULAR PURPOSE. ENTIRE RISK QUALITY PERFORMANCE PROGRAM . PROGRAM PROVE DEFECTIVE, ASSUME COST NECESSARY SERVICING, REPAIR CORRECTION.","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/LICENSE.html","id":"id_16-limitation-of-liability","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"16. Limitation of Liability","title":"GNU General Public License","text":"EVENT UNLESS REQUIRED APPLICABLE LAW AGREED WRITING COPYRIGHT HOLDER, PARTY MODIFIES /CONVEYS PROGRAM PERMITTED , LIABLE DAMAGES, INCLUDING GENERAL, SPECIAL, INCIDENTAL CONSEQUENTIAL DAMAGES ARISING USE INABILITY USE PROGRAM (INCLUDING LIMITED LOSS DATA DATA RENDERED INACCURATE LOSSES SUSTAINED THIRD PARTIES FAILURE PROGRAM OPERATE PROGRAMS), EVEN HOLDER PARTY ADVISED POSSIBILITY DAMAGES.","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/LICENSE.html","id":"id_17-interpretation-of-sections-15-and-16","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"17. Interpretation of Sections 15 and 16","title":"GNU General Public License","text":"disclaimer warranty limitation liability provided given local legal effect according terms, reviewing courts shall apply local law closely approximates absolute waiver civil liability connection Program, unless warranty assumption liability accompanies copy Program return fee. END TERMS CONDITIONS","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/LICENSE.html","id":"how-to-apply-these-terms-to-your-new-programs","dir":"","previous_headings":"","what":"How to Apply These Terms to Your New Programs","title":"GNU General Public License","text":"develop new program, want greatest possible use public, best way achieve make free software everyone can redistribute change terms. , attach following notices program. safest attach start source file effectively state exclusion warranty; file least “copyright” line pointer full notice found. Also add information contact electronic paper mail. program terminal interaction, make output short notice like starts interactive mode: hypothetical commands show w show c show appropriate parts General Public License. course, program’s commands might different; GUI interface, use “box”. also get employer (work programmer) school, , sign “copyright disclaimer” program, necessary. information , apply follow GNU GPL, see <http://www.gnu.org/licenses/>. GNU General Public License permit incorporating program proprietary programs. program subroutine library, may consider useful permit linking proprietary applications library. want , use GNU Lesser General Public License instead License. first, please read <http://www.gnu.org/philosophy/--lgpl.html>.","code":"<one line to give the program's name and a brief idea of what it does.> Copyright (C) <year>  <name of author>  This program is free software: you can redistribute it and/or modify it under the terms of the GNU General Public License as published by the Free Software Foundation, either version 3 of the License, or (at your option) any later version.  This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for more details.  You should have received a copy of the GNU General Public License along with this program.  If not, see <http://www.gnu.org/licenses/>. <program>  Copyright (C) <year>  <name of author> This program comes with ABSOLUTELY NO WARRANTY; for details type 'show w'. This is free software, and you are welcome to redistribute it under certain conditions; type 'show c' for details."},{"path":"https://egouldo.github.io/ManyEcoEvo/SUPPORT.html","id":null,"dir":"","previous_headings":"","what":"Getting help with ManyEcoEvo","title":"Getting help with ManyEcoEvo","text":"Thanks using ManyEcoEvo! filing issue, places explore pieces put together make process smooth possible.","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/SUPPORT.html","id":"make-a-reprex","dir":"","previous_headings":"","what":"Make a reprex","title":"Getting help with ManyEcoEvo","text":"Start making minimal reproducible example using reprex package. haven’t heard used reprex , ’re treat! Seriously, reprex make R-question-asking endeavors easier (pretty incredible ROI five ten minutes ’ll take learn ’s ). additional reprex pointers, check Get help! section tidyverse site.","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/SUPPORT.html","id":"where-to-ask","dir":"","previous_headings":"","what":"Where to ask?","title":"Getting help with ManyEcoEvo","text":"Armed reprex, next step figure ask. ’s question: start community.rstudio.com, /StackOverflow. people answer questions. ’s bug: ’re right place, file issue. ’re sure: let community help figure ! problem bug feature request, can easily return report . opening new issue, sure search issues pull requests make sure bug hasn’t reported /already fixed development version. default, search pre-populated :issue :open. can edit qualifiers (e.g. :pr, :closed) needed. example, ’d simply remove :open search issues repo, open closed.","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/SUPPORT.html","id":"what-happens-next","dir":"","previous_headings":"","what":"What happens next?","title":"Getting help with ManyEcoEvo","text":"efficient possible, development tidyverse packages tends bursty, shouldn’t worry don’t get immediate response. Typically don’t look repo sufficient quantity issues accumulates, ’s burst intense activity focus efforts. makes development efficient avoids expensive context switching problems, cost taking longer get back . process makes good reprex particularly important might multiple months initial report start working . can’t reproduce bug, can’t fix !","code":""},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":"https://egouldo.github.io/ManyEcoEvo/articles/data_cleaning_preparation.html","id":"anonymising-data","dir":"Articles","previous_headings":"0.1 Data Cleaning","what":"Anonymising Data","title":"Data Cleaning & Preparation for Analysis","text":"anonymised public dataset data(ManyEcoEvo) anonymise_teams(), takes look-table new old identifier names replace analysis identifier. lookup table original non-anonymised data can stored private repository component, OSF example, anonymised dataset can released publicly.","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/articles/data_cleaning_preparation.html","id":"data-pre-processing-for-meta-analysis","dir":"Articles","previous_headings":"","what":"Data Pre-processing for Meta-analysis","title":"Data Cleaning & Preparation for Analysis","text":"meta-analysis requires estimates scale. meta-analysis based assumption outcome measures comparable. Note ManyAnalysts project utilises two different outcomes meta-analysis, standardised effect-sizes, \\(Z_r\\) --sample predictions \\(y_i\\), alternative effect-size measures may utilised instead1. provide function standardise_response() standardise data-frame analyst-data. Note beta_estimate, beta_SE adjusted_df missing, standardise_response() unable compute standardised correlation coefficients \\(Z_r\\) associated variance \\(\\text{VZ}_r\\). standardise data frame containing --sample point-estimate predictions, stored list-column dataframes, called augmented_data, notice additional console messages back-transformations, well additional step Transforming sample predictions link response scale. ’s , depending estimate_type standardised, different workflow implemented standardise_response().","code":"data(\"ManyEcoEvo\")  blue_tit_effect_sizes <-    ManyEcoEvo %>%    dplyr::filter(dataset == \"blue tit\") %>%    pluck(\"data\", 1) %>%    slice(1:10) %>%    select(contains(\"id\"),           -response_id_S2,          contains(\"beta\"),           adjusted_df)  blue_tit_effect_sizes #> # A tibble: 10 × 9 #>    response_id       submission_id analysis_id split_id TeamIdentifier id_col    #>    <chr>                     <dbl>       <dbl>    <dbl> <chr>          <chr>     #>  1 R_11787O3NmejXKAH             1           2        2 Ayr            Ayr-1-2-2 #>  2 R_11787O3NmejXKAH             1           2        3 Ayr            Ayr-1-2-3 #>  3 R_11787O3NmejXKAH             1           2        1 Ayr            Ayr-1-2-1 #>  4 R_126erjKKuN3IwSJ             2           2        1 Bega           Bega-2-2… #>  5 R_126erjKKuN3IwSJ             2           2        2 Bega           Bega-2-2… #>  6 R_126erjKKuN3IwSJ             1           1        1 Bega           Bega-1-1… #>  7 R_126erjKKuN3IwSJ             1           1        2 Bega           Bega-1-1… #>  8 R_12cozGev3IOOBG2             4           4        1 Bell           Bell-4-4… #>  9 R_12cozGev3IOOBG2             3           3        1 Bell           Bell-3-3… #> 10 R_12cozGev3IOOBG2             1           1        1 Bell           Bell-1-1… #> # ℹ 3 more variables: beta_estimate <dbl>, beta_SE <dbl>, adjusted_df <dbl>  standardise_response(dat = blue_tit_effect_sizes,                       estimate_type = \"Zr\",                      param_table = NULL,                       dataset = \"blue tit\") %>%    select(id_col, contains(\"beta\"), adjusted_df, Zr, VZr ) #>  #> ── Computing meta-analysis inputsfor `estimate_type` = \"Zr\" ──────────────────── #>  #> ── Computing standardised effect sizes `Zr` and variance `VZr` ── #>  #> ✖ Required values for computing standardised effect sizes missing: #> ! Returning \"NA\" for tupple: #> 1. beta_estimate NA, #> 2. beta_se NA, #> 3. adjusted_df 484.0193. #> ✖ Required values for computing standardised effect sizes missing: #> ! Returning \"NA\" for tupple: #> 1. beta_estimate NA, #> 2. beta_se NA, #> 3. adjusted_df 666.56874. #> ✖ Required values for computing standardised effect sizes missing: #> ! Returning \"NA\" for tupple: #> 1. beta_estimate NA, #> 2. beta_se NA, #> 3. adjusted_df 590.18263. #> ✖ Required values for computing standardised effect sizes missing: #> ! Returning \"NA\" for tupple: #> 1. beta_estimate NA, #> 2. beta_se 0.006225, #> 3. adjusted_df NA. #> ✖ Required values for computing standardised effect sizes missing: #> ! Returning \"NA\" for tupple: #> 1. beta_estimate NA, #> 2. beta_se 0.003996, #> 3. adjusted_df NA. #> ✖ Required values for computing standardised effect sizes missing: #> ! Returning \"NA\" for tupple: #> 1. beta_estimate NA, #> 2. beta_se NA, #> 3. adjusted_df NA. #> # A tibble: 10 × 6 #>    id_col     beta_estimate  beta_SE adjusted_df      Zr      VZr #>    <chr>              <dbl>    <dbl>       <dbl>   <dbl>    <dbl> #>  1 Ayr-1-2-2          NA    NA              484. NA      NA       #>  2 Ayr-1-2-3          NA    NA              667. NA      NA       #>  3 Ayr-1-2-1          NA    NA              590. NA      NA       #>  4 Bega-2-2-1         -4.05  2.11           389. -0.0972  0.00257 #>  5 Bega-2-2-2         -2.55  1.91           384. -0.0681  0.00260 #>  6 Bega-1-1-1         -9.2   2.45           388. -0.189   0.00257 #>  7 Bega-1-1-2          1.26  2.21           382.  0.0292  0.00262 #>  8 Bell-4-4-1         NA     0.00622         NA  NA      NA       #>  9 Bell-3-3-1         NA     0.00400         NA  NA      NA       #> 10 Bell-1-1-1         NA    NA               NA  NA      NA # ----- Create example blue tit dataset ----  data(\"ManyEcoEvo_yi\") blue_tit_predictions <-    ManyEcoEvo_yi %>%    dplyr::filter(dataset == \"blue tit\") %>%    pluck(\"data\", 1) %>%    head()  # ----- back-transform analyst estimates to original response scale ---- blue_tit_back_transformed <-    blue_tit_predictions %>%    back_transform_response_vars_yi(estimate_type = \"yi\",                                   dataset = \"blue tit\") %>%    ungroup %>%    select(     id_col,     response_variable_name,     contains(\"transformation\"),     augmented_data,      back_transformed_data   ) #TODO transformation column seems wrong! but output from convert_predictions() suggests correct transformation occured! #> ✔ Applied back-transformation for squared effect sizes or out-of-sample predictions. #> ✔ Applied back-transformation for squared effect sizes or out-of-sample predictions. #> ✔ Applied back-transformation for squared effect sizes or out-of-sample predictions. #> ✔ Applied back-transformation for squared effect sizes or out-of-sample predictions. #> ✔ Applied back-transformation for squared effect sizes or out-of-sample predictions. #> ✔ Applied back-transformation for squared effect sizes or out-of-sample predictions. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used.  blue_tit_back_transformed #> # A tibble: 6 × 8 #>   id_col    response_variable_name response_transformat…¹ response_transformat…² #>   <chr>     <chr>                  <chr>                  <chr>                  #> 1 Bega-1-1… day_14_weight          power2                 square                 #> 2 Bega-2-2… day_14_tarsus_length   power2                 square                 #> 3 Bell-2-2… day_14_tarsus_length   NA                     NA                     #> 4 Berr-1-1… day_14_weight          z.score                identity               #> 5 Burr-1-1… day_14_tarsus_length   NA                     NA                     #> 6 Burr-2-2… day_14_weight          NA                     NA                     #> # ℹ abbreviated names: ¹​response_transformation_description, #> #   ²​response_transformation_status #> # ℹ 4 more variables: transformation <chr>, transformation_type <chr>, #> #   augmented_data <named list>, back_transformed_data <named list>  # ----- standardize to Z scale ------  blue_tit_standardised <-    blue_tit_back_transformed %>%    standardise_response(     estimate_type = \"yi\" ,     param_table = ManyEcoEvo:::analysis_data_param_tables,      dataset = \"blue tit\"   ) %>%    ungroup %>%    select(     id_col,     params,      transformation,     augmented_data,      back_transformed_data   ) #>  #> ── Computing meta-analysis inputsfor `estimate_type` = \"yi\" ──────────────────── #>  #> ── Standardising out-of-sample predictions ── #>   blue_tit_standardised #> # A tibble: 6 × 5 #>   id_col     params   transformation augmented_data     back_transformed_data #>   <chr>      <list>   <chr>          <named list>       <named list>          #> 1 Bega-1-1-1 <tibble> identity       <gropd_df [3 × 5]> <tibble [3 × 3]>      #> 2 Bega-2-2-1 <tibble> identity       <gropd_df [3 × 5]> <tibble [3 × 3]>      #> 3 Bell-2-2-1 <tibble> identity       <gropd_df [3 × 5]> <tibble [3 × 3]>      #> 4 Berr-1-1-1 <tibble> identity       <gropd_df [3 × 5]> <tibble [3 × 3]>      #> 5 Burr-1-1-1 <tibble> identity       <gropd_df [3 × 5]> <tibble [3 × 3]>      #> 6 Burr-2-2-1 <tibble> identity       <gropd_df [3 × 5]> <tibble [3 × 3]>  # ----- parameters ----  blue_tit_standardised %>% pluck(\"params\", 1)  #> # A tibble: 2 × 4 #>   variable      parameter value dataset  #>   <chr>         <chr>     <dbl> <chr>    #> 1 day_14_weight mean      10.3  blue tit #> 2 day_14_weight sd         1.19 blue tit blue_tit_standardised %>% pluck(\"params\", 2) # gets a different set depending on the variable #> # A tibble: 2 × 4 #>   variable             parameter  value dataset  #>   <chr>                <chr>      <dbl> <chr>    #> 1 day_14_tarsus_length mean      16.7   blue tit #> 2 day_14_tarsus_length sd         0.684 blue tit  # ---- raw predictions data ---- blue_tit_back_transformed %>% pluck(\"augmented_data\", 1) #> # A tibble: 3 × 5 #> # Groups:   scenario [3] #>   scenario estimate se.fit ci.low ci.hi #>      <int>    <dbl>  <dbl>  <dbl> <dbl> #> 1        1     87.6   6.20   74.9  99.1 #> 2        2    115.    6.31  102.  126.  #> 3        3    124.    6.04  112.  135. blue_tit_back_transformed %>% pluck(\"back_transformed_data\", 1) #> # A tibble: 3 × 5 #>   scenario estimate  se.fit ci.low ci.hi #>      <int>    <dbl>   <dbl>  <dbl> <dbl> #> 1        1     9.35 0.00329   8.70  9.97 #> 2        2    10.7  0.00294  10.1  11.3  #> 3        3    11.1  0.00269  10.6  11.6  # ---- back-transformed & standardised predictions_data ---- blue_tit_standardised %>% pluck(\"back_transformed_data\", 1)  #> # A tibble: 3 × 3 #>   scenario      Z      VZ #>      <int>  <dbl>   <dbl> #> 1        1 -0.778 0.00277 #> 2        2  0.360 0.00248 #> 3        3  0.708 0.00227  MA_data_yi <- blue_tit_standardised %>%    select(id_col, back_transformed_data) %>%    unnest(back_transformed_data) %>%    pointblank::col_vals_between(columns = \"Z\", left = -3, right = 3, inclusive = TRUE)"},{"path":"https://egouldo.github.io/ManyEcoEvo/articles/data_cleaning_preparation.html","id":"sec-standardisation","dir":"Articles","previous_headings":"0.2 Data Pre-processing for Meta-analysis","what":"Standardising effect-sizes to \\(Z_r\\)","title":"Data Cleaning & Preparation for Analysis","text":"Standardisation effect-sizes (fishers’ Z), however transformations applied using packages need (Gurrindgi green meta-analsis handbook). Coefficients est_to_Zr()","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/articles/data_cleaning_preparation.html","id":"standardising-out-of-sample-predictions-to-z_y_i","dir":"Articles","previous_headings":"0.2 Data Pre-processing for Meta-analysis","what":"Standardising out-of-sample predictions to \\(Z_{y_i}\\)","title":"Data Cleaning & Preparation for Analysis","text":"standardising --sample predictions, need ensure estimates scale. analysts may report estimates link scale, others may report estimates response scale, instance. ManyEcoEvo:: provides suite functions back-transforming estimates prior standardising effect sizes.","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/articles/data_cleaning_preparation.html","id":"cleaning-response-transformation-values-and-assigning-a-back-transformation","dir":"Articles","previous_headings":"0.2 Data Pre-processing for Meta-analysis > 0.2.2 Standardising out-of-sample predictions to \\(Z_{y_i}\\)","what":"Cleaning response-transformation values and assigning a back-transformation","title":"Data Cleaning & Preparation for Analysis","text":"Analysts may report estimates various scales, example may report values link response scales, may also, may transformed response-variable prior model-fitting reported effect-sizes transformed scale, rather scale original variable. order proceed standardisation effect-sizes --sample estimates, back-transform analysts’ reported estimates original response scale datasets euc_data blue_tit_data, rather link- transformed- scale. assign_transformation_type() takes information response_transformation link_fun given analysis, assigns analysis appropriate back-transformation rule applied, one either \"identity\", value link-function response-transformation, \"double.transformation\", NA appropriate transformation type assigned. Next, type response transformation cleaned using clean_response_transformation(), cleans value returned assign_transformation_type() step 1 c(\"identity\", \"double.transformation\", NA) value lookup-tibble assigns appropriate transformation apply. Users can supply lookup table, else use modify version supplied ManyEcoEvo:::transformation_tbl. estimates now ready back-transformation (section 0.2.2.2) /standardisation (section 0.2.1).","code":"#TODO demonstrate assign transformation and clean response transformation"},{"path":"https://egouldo.github.io/ManyEcoEvo/articles/data_cleaning_preparation.html","id":"sec-back-transformation","dir":"Articles","previous_headings":"0.2 Data Pre-processing for Meta-analysis > 0.2.2 Standardising out-of-sample predictions to \\(Z_{y_i}\\)","what":"Back-transforming analysts’ reported out-of-sample predictions","title":"Data Cleaning & Preparation for Analysis","text":"provide conversion() function, applies relevant back() function depending required transformation assigned analysis:","code":"#TODO demonstrate conversion() with back functions"},{"path":"https://egouldo.github.io/ManyEcoEvo/articles/data_cleaning_preparation.html","id":"standardising-out-of-sample-predictions","dir":"Articles","previous_headings":"0.2 Data Pre-processing for Meta-analysis > 0.2.2 Standardising out-of-sample predictions to \\(Z_{y_i}\\)","what":"Standardising out-of-sample predictions","title":"Data Cleaning & Preparation for Analysis","text":"pred_to_Z() (data frame level), Z_VZ_preds()","code":"#TODO demonstrate application of V_Zr_preds() and or pred_to_z()"},{"path":"https://egouldo.github.io/ManyEcoEvo/articles/data_cleaning_preparation.html","id":"calculating-sorensen-similarity-index","dir":"Articles","previous_headings":"0.2 Data Pre-processing for Meta-analysis","what":"Calculating Sorensen similarity index","title":"Data Cleaning & Preparation for Analysis","text":"apply_sorensen_calc() calculate_sorensen_diversity_index() (also needs renamed)","code":""},{"path":[]},{"path":"https://egouldo.github.io/ManyEcoEvo/articles/data_cleaning_preparation.html","id":"excluding-data","dir":"Articles","previous_headings":"0.2 Data Pre-processing for Meta-analysis","what":"Excluding Data","title":"Data Cleaning & Preparation for Analysis","text":"exclude_extreme_VZ() - exclude extreme values VZ","code":""},{"path":[]},{"path":"https://egouldo.github.io/ManyEcoEvo/articles/multiple_datasets.html","id":"a-tidy-approach-with-list-columns-and-nested-dataframes","dir":"Articles","previous_headings":"","what":"A tidy approach with list-columns and nested dataframes","title":"Scaling Up: working with multiple subsets or multiple datasets","text":"list-columns tidy modelling approach.","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/articles/multiple_datasets.html","id":"working-with-multiple-datasets","dir":"Articles","previous_headings":"1 A tidy approach with list-columns and nested dataframes","what":"Working with Multiple datasets","title":"Scaling Up: working with multiple subsets or multiple datasets","text":"Multiple different datasets might want replicate analyses compare. E.g. Blue tit vs. Eucalyptus. Demonstrate approach analysis pipeline ManyEcoEvo just using blue tit Eucalyptus data -> make_viz() etc.","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/articles/multiple_datasets.html","id":"creating-data-subsets-based-on-various-exclusion-principles","dir":"Articles","previous_headings":"1 A tidy approach with list-columns and nested dataframes","what":"Creating data subsets based on various exclusion principles","title":"Scaling Up: working with multiple subsets or multiple datasets","text":"Generate different subsets: - generate_exclusion_subsets() - generate_expertise_subsets() - generate_outlier_subsets() - generate_rating_subsets() - generate_yi_subsets()","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/articles/multiple_datasets.html","id":"out-of-sample-predictions","dir":"Articles","previous_headings":"1 A tidy approach with list-columns and nested dataframes","what":"Out-of-sample predictions","title":"Scaling Up: working with multiple subsets or multiple datasets","text":"Note function generate_exclusion_subsets() currently need executed ManyEcoEvo_yi dataset since default subsetting functions called subset_fns_yi() function don’t result different subsets data:","code":"ManyEcoEvo_yi %>%    hoist(data, \"exclusions_all\",.transform = unique) %>%    select(-contains(\"data\")) #> # A tibble: 2 × 1 #>   exclusions_all #>   <chr>          #> 1 retain         #> 2 retain"},{"path":"https://egouldo.github.io/ManyEcoEvo/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Elliot Gould. Author, maintainer. Hannah S. Fraser. Author. Shinichi Nakagawa. Author. Timothy H. Parker. Author.","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Gould E, Fraser H, Nakagawa S, Parker T (2023). “ManyEcoEvo: Meta-analyse data ManyAnalyst style studies.” TBC.","code":"@Article{,   title = {ManyEcoEvo: Meta-analyse data from ManyAnalyst style studies},   author = {Elliot Gould and Hannah S. Fraser and Shinichi Nakagawa and Timothy H. Parker},   journal = {TBC},   year = {2023}, }"},{"path":"https://egouldo.github.io/ManyEcoEvo/index.html","id":"manyecoevo-","dir":"","previous_headings":"","what":"Meta-analyse data from Many-Analysts style studies","title":"Meta-analyse data from Many-Analysts style studies","text":"ManyEcoEvo package provides suite functions : Summarising, analysing visualising ManyEcoEvo dataset Gould et al.1 Tidying cleaning many-analyst style data analysis Reproducing analysis Gould et al. using many-analyst style data Note manuscript source-code Gould et al. located separate repository https://github.com/egouldo/ManyAnalysts, can viewed https://egouldo.github.io/ManyAnalysts/.","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Meta-analyse data from Many-Analysts style studies","text":"ManyEcoEvo:: can installed using devtools:: GitHub :","code":"devtools::install_github(\"egouldo/ManyEcoEvo\")"},{"path":"https://egouldo.github.io/ManyEcoEvo/index.html","id":"regenerating-the-manyecoevo-dataset","dir":"","previous_headings":"","what":"Regenerating the ManyEcoEvo dataset","title":"Meta-analyse data from Many-Analysts style studies","text":"data processing analysis can freely reproduced help targets:: package. Please see documentation https://docs.ropensci.org/targets/ detail. wish completely reproduce dataset generation analysis Gould et al., complete following steps: Clone download https://github.com/egouldo/repository Run renv::restore() load packages used analysis pipeline locally machine (see renv:: details) Run targets::tar_destroy() remove record caches existing targets Run targets::tar_make() console, depending power machine, analysis pipeline take 2 7 minutes execute (plus minus !) can view table targets pipeline running targets::tar_meta() interact objects ‘targets’ within analysis pipeline, call targest::tar_load() targets::tar_read(): script generates datasets used ManyEcoEvo:: package located ManyEcoEvo/data-raw/tar_make.R.","code":"targets::tar_read(\"ManyEcoEvo\") # A tibble: 2 × 4   dataset    data                diversity_data      estimate_type   <chr>      <list>              <named list>        <chr>         1 blue tit   <tibble [174 × 38]> <tibble [174 × 54]> Zr            2 eucalyptus <tibble [128 × 38]> <tibble [128 × 61]> Zr"},{"path":"https://egouldo.github.io/ManyEcoEvo/index.html","id":"license","dir":"","previous_headings":"","what":"License","title":"Meta-analyse data from Many-Analysts style studies","text":"software licensed GNU GPL 3 license.","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/index.html","id":"contributing","dir":"","previous_headings":"","what":"Contributing","title":"Meta-analyse data from Many-Analysts style studies","text":"package released Contributor Code Conduct.","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/index.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Meta-analyse data from Many-Analysts style studies","text":"","code":"To cite package ‘ManyEcoEvo’ in publications use:    Gould E, Fraser H, Nakagawa S, Parker T (2023). _ManyEcoEvo: Meta-analyse   data from 'Many-Analysts' style studies_. R package version 1.0.0,   <https://github.com/egouldo/ManyEcoEvo>.  A BibTeX entry for LaTeX users is    @Manual{,     title = {ManyEcoEvo: Meta-analyse data from 'Many-Analysts' style studies},     author = {Elliot Gould and Hannah S. Fraser and Shinichi Nakagawa and Timothy H. Parker},     year = {2023},     note = {R package version 1.0.0},     url = {https://github.com/egouldo/ManyEcoEvo},   }"},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/ManyEcoEvo-package.html","id":null,"dir":"Reference","previous_headings":"","what":"ManyEcoEvo: Meta-analyse data from 'Many-Analysts' style studies — ManyEcoEvo-package","title":"ManyEcoEvo: Meta-analyse data from 'Many-Analysts' style studies — ManyEcoEvo-package","text":"ManyEcoEvo package provides set functions aiding data cleaning, preparation conducting analysis multi-analyst style studies. also contains datasets ManyEcoEvo project reproducing ManyEcoEvo analysis.","code":""},{"path":[]},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/ManyEcoEvo-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"ManyEcoEvo: Meta-analyse data from 'Many-Analysts' style studies — ManyEcoEvo-package","text":"Maintainer: Elliot Gould elliot.gould@unimelb.edu.au (ORCID) Authors: Hannah S. Fraser (ORCID) Shinichi Nakagawa (ORCID) Timothy H. Parker (ORCID)","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/NotIn.html","id":null,"dir":"Reference","previous_headings":"","what":"Negative Value Matching — %nin%","title":"Negative Value Matching — %nin%","text":"See base:: details. %nin% binary operator, returning logical vector indicating negative match .","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/NotIn.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Negative Value Matching — %nin%","text":"","code":"lhs %in% rhs"},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/NotIn.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Negative Value Matching — %nin%","text":"lhs vector NULL: values matched. Long vectors supported. rhs vector NULL: values matched. Long vectors  supported.","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/NotIn.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Negative Value Matching — %nin%","text":"logical vector indicating value lhs matched rhs","code":""},{"path":[]},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/NotIn.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Negative Value Matching — %nin%","text":"","code":"\"A\" %nin% LETTERS[1:10] #> [1] FALSE \"A\" %in% LETTERS[1:10] #> [1] TRUE"},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/Z_VZ_preds.html","id":null,"dir":"Reference","previous_headings":"","what":"Standardize out-of-sample predictions — Z_VZ_preds","title":"Standardize out-of-sample predictions — Z_VZ_preds","text":"Standardize --sample predictions","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/Z_VZ_preds.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Standardize out-of-sample predictions — Z_VZ_preds","text":"","code":"Z_VZ_preds(yi, yi_se, mu_p, sd_p)"},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/Z_VZ_preds.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Standardize out-of-sample predictions — Z_VZ_preds","text":"yi point-estimate prediction, response scale yi_se standard error yi mu_p Population mean variable estimated yi sd_p Population standard deviation variable estimated yi","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/Z_VZ_preds.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Standardize out-of-sample predictions — Z_VZ_preds","text":"tibble columns Z VZ","code":""},{"path":[]},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/anonymise_teams.html","id":null,"dir":"Reference","previous_headings":"","what":"Anonymise ManyEcoEvo Data — anonymise_teams","title":"Anonymise ManyEcoEvo Data — anonymise_teams","text":"Anonymise ManyEcoEvo Data","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/anonymise_teams.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Anonymise ManyEcoEvo Data — anonymise_teams","text":"","code":"anonymise_teams(df, lookup)"},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/anonymise_teams.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Anonymise ManyEcoEvo Data — anonymise_teams","text":"df dataframe containing column id_col lookup dataframe containing columns TeamIdentifier New_Identifier","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/anonymise_teams.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Anonymise ManyEcoEvo Data — anonymise_teams","text":"df anonymised values id_col based New_Identifier colum lookup","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/apply_VZ_exclusions.html","id":null,"dir":"Reference","previous_headings":"","what":"Apply VZ exclusion to a data-frame containing list-columns of yi subsets — apply_VZ_exclusions","title":"Apply VZ exclusion to a data-frame containing list-columns of yi subsets — apply_VZ_exclusions","text":"Apply VZ exclusion data-frame containing list-columns yi subsets","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/apply_VZ_exclusions.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Apply VZ exclusion to a data-frame containing list-columns of yi subsets — apply_VZ_exclusions","text":"","code":"apply_VZ_exclusions(df = data.frame(), VZ_colname, VZ_cutoff)"},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/apply_VZ_exclusions.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Apply VZ exclusion to a data-frame containing list-columns of yi subsets — apply_VZ_exclusions","text":"df dataframe yi data subsets generated generate_yi_subsets() split_yi_subsets(). VZ_colname Either character vector length 1, name column dataframes stored df's list-column data contains VZ values. else named list character values, names dataset names values VZ_colnames  dataset df. VZ_cutoff numeric vector length 1, values equal greater value VZ filtered dataframes stored df's list-column data, else named list numeric values, names dataset names values VZ_cutoffs dataset df.","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/apply_VZ_exclusions.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Apply VZ exclusion to a data-frame containing list-columns of yi subsets — apply_VZ_exclusions","text":"dataframe yi subsets, whose extreme values VZ removed.","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/apply_VZ_exclusions.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Apply VZ exclusion to a data-frame containing list-columns of yi subsets — apply_VZ_exclusions","text":"df must contain columns \"data\", \"diversity_data\" \"dataset\". one value VZ_colname VZ_cutoff supplied, recycled match number datasets df. named list supplied VZ_colname VZ_cutoff, names must match dataset names df.","code":""},{"path":[]},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/apply_VZ_exclusions.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Apply VZ exclusion to a data-frame containing list-columns of yi subsets — apply_VZ_exclusions","text":"","code":"data(ManyEcoEvo_yi) ManyEcoEvo_yi %>%   prepare_response_variables(     estimate_type = \"yi\",     param_table =       ManyEcoEvo:::analysis_data_param_tables,     dataset_standardise = \"blue tit\",     dataset_log_transform = \"eucalyptus\") %>%   generate_yi_subsets() %>%    apply_VZ_exclusions(VZ_colname =                          list(\"eucalyptus\" = \"se_log\",                               \"blue tit\" = \"VZ\"),                        VZ_cutoff = 3) #>  #> ── Generating out-of-sample prediction subsets. ──────────────────────────────── #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ✔ Applied back-transformation for squared effect sizes or out-of-sample predictions. #> ✔ Applied back-transformation for squared effect sizes or out-of-sample predictions. #> ✔ Applied back-transformation for squared effect sizes or out-of-sample predictions. #> ✔ Applied back-transformation for squared effect sizes or out-of-sample predictions. #> ✔ Applied back-transformation for squared effect sizes or out-of-sample predictions. #> ✔ Applied back-transformation for squared effect sizes or out-of-sample predictions. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ✔ Applied back-transformation for ^100 effect sizes or out of sample predictions. #> ✔ Applied back-transformation for cubed effect sizes #> ✔ Applied back-transformation for ^100 effect sizes or out of sample predictions. #> ✔ Applied back-transformation for cubed effect sizes #> ✔ Applied back-transformation for ^100 effect sizes or out of sample predictions. #> ✔ Applied back-transformation for cubed effect sizes #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ✔ Applied back-transformation for ^14 effect sizes or out of sample predictions. #> ✔ Applied back-transformation for ^14 effect sizes or out of sample predictions. #> ✔ Applied back-transformation for ^14 effect sizes or out of sample predictions. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for logit-transformed effect sizes or out-of-sample predictions #> ✔ Applied back-transformation for logit-transformed effect sizes or out-of-sample predictions #> ✔ Applied back-transformation for logit-transformed effect sizes or out-of-sample predictions #> ✔ Applied back-transformation for logit-transformed effect sizes or out-of-sample predictions #> ✔ Applied back-transformation for logit-transformed effect sizes or out-of-sample predictions #> ✔ Applied back-transformation for logit-transformed effect sizes or out-of-sample predictions #> ✔ Applied back-transformation for logit-transformed effect sizes or out-of-sample predictions #> ✔ Applied back-transformation for logit-transformed effect sizes or out-of-sample predictions #> ✔ Applied back-transformation for logit-transformed effect sizes or out-of-sample predictions #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for square-root transformed effect sizes or out-of-sample predictions. #> ✔ Applied back-transformation for square-root transformed effect sizes or out-of-sample predictions. #> ✔ Applied back-transformation for square-root transformed effect sizes or out-of-sample predictions. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ℹ Standardising and/or log-transforming response variables for \"yi\" estimates. #>  #> ── Computing meta-analysis inputsfor `estimate_type` = \"yi\" ──────────────────── #>  #> ── Standardising out-of-sample predictions ── #>  #> ── Computing meta-analysis inputs: ───────────────────────────────────────────── #>  #> ── Log-transforming response-variable ── #>  #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #>  #> ── Applying VZ exclusions ────────────────────────────────────────────────────── #> ! `VZ_cutoff` = 3 was recycled to match the number of unique datasets in `df`. #>  #> ── Excluding extreme values of VZ ── #>  #> → 0 extreme values of `VZ` removed at threshold of 3 for `dataset` \"blue tit\", `estimate_type` = \"y25\". #>  #> ── Excluding extreme values of VZ ── #>  #> → 0 extreme values of `VZ` removed at threshold of 3 for `dataset` \"blue tit\", `estimate_type` = \"y25\". #>  #> ── Excluding extreme values of VZ ── #>  #> → 0 extreme values of `VZ` removed at threshold of 3 for `dataset` \"blue tit\", `estimate_type` = \"y25\". #>  #> ── Excluding extreme values of VZ ── #>  #> → 0 extreme values of `se_log` removed at threshold of 3 for `dataset` \"blue tit\", `estimate_type` = \"y25\". #>  #> ── Excluding extreme values of VZ ── #>  #> → 0 extreme values of `se_log` removed at threshold of 3 for `dataset` \"blue tit\", `estimate_type` = \"y25\". #>  #> ── Excluding extreme values of VZ ── #>  #> → 0 extreme values of `se_log` removed at threshold of 3 for `dataset` \"blue tit\", `estimate_type` = \"y25\". #> # A tibble: 6 × 4 #>   dataset    estimate_type data               diversity_data     #>   <chr>      <chr>         <list>             <named list>       #> 1 blue tit   y25           <tibble [65 × 26]> <tibble [65 × 54]> #> 2 blue tit   y50           <tibble [60 × 26]> <tibble [60 × 54]> #> 3 blue tit   y75           <tibble [65 × 26]> <tibble [65 × 54]> #> 4 eucalyptus y25           <tibble [49 × 27]> <tibble [49 × 61]> #> 5 eucalyptus y50           <tibble [51 × 27]> <tibble [51 × 61]> #> 6 eucalyptus y75           <tibble [52 × 27]> <tibble [52 × 61]>"},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/apply_slice_conditionally.html","id":null,"dir":"Reference","previous_headings":"","what":"Apply slice conditionally — apply_slice_conditionally","title":"Apply slice conditionally — apply_slice_conditionally","text":"Apply slice conditionally","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/apply_slice_conditionally.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Apply slice conditionally — apply_slice_conditionally","text":"","code":"apply_slice_conditionally(x, filter_vars)"},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/apply_slice_conditionally.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Apply slice conditionally — apply_slice_conditionally","text":"x tibble, containing full dataset subset slice_conditionally() bound back original dataset x filter_vars list quosures used dplyr::filter() subset y n_min integer, number bottom outliers remove n_max integer, number top outliers remove","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/apply_slice_conditionally.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Apply slice conditionally — apply_slice_conditionally","text":"tibble x must contain columns data, outcome_colname, n_min, n_max. create columns exclusion_set present dataset, assigning \"complete\" x \"complete-rm_outliers\" subsetted data bound x.","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/apply_sorensen_calc.html","id":null,"dir":"Reference","previous_headings":"","what":"Applies the sorensen diversity index calculation to variable diversity dataset — apply_sorensen_calc","title":"Applies the sorensen diversity index calculation to variable diversity dataset — apply_sorensen_calc","text":"Applies sorensen diversity index calculation variable diversity dataset","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/apply_sorensen_calc.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Applies the sorensen diversity index calculation to variable diversity dataset — apply_sorensen_calc","text":"","code":"apply_sorensen_calc(data)"},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/apply_sorensen_calc.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Applies the sorensen diversity index calculation to variable diversity dataset — apply_sorensen_calc","text":"data variable diversity dataset columns unique variable used analyses. Values NA analysis use variable, take value variable character string analysis use variable. unique analysis row.","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/apply_sorensen_calc.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Applies the sorensen diversity index calculation to variable diversity dataset — apply_sorensen_calc","text":"tibble containing variables id_col, mean_diversity_index num_variables","code":""},{"path":[]},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/apportion_heterogeneity_ml.html","id":null,"dir":"Reference","previous_headings":"","what":"Apportion heterogeneity of a multi-level meta-analytic model — apportion_heterogeneity_ml","title":"Apportion heterogeneity of a multi-level meta-analytic model — apportion_heterogeneity_ml","text":"Estimates much total variance $^2$ can attributed - within- cluster heterogeneity separately.","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/apportion_heterogeneity_ml.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Apportion heterogeneity of a multi-level meta-analytic model — apportion_heterogeneity_ml","text":"","code":"apportion_heterogeneity_ml(fitted_model)"},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/apportion_heterogeneity_ml.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Apportion heterogeneity of a multi-level meta-analytic model — apportion_heterogeneity_ml","text":"fitted_model","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/apportion_heterogeneity_ml.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Apportion heterogeneity of a multi-level meta-analytic model — apportion_heterogeneity_ml","text":"named numeric vector length 2.","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/apportion_heterogeneity_ml.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Apportion heterogeneity of a multi-level meta-analytic model — apportion_heterogeneity_ml","text":"http://www.metafor-project.org/doku.php/tips:i2_multilevel_multivariate","code":""},{"path":[]},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/assign_transformation_type.html","id":null,"dir":"Reference","previous_headings":"","what":"Assign back-transformation type to be applied to analysts' point-estimates — assign_transformation_type","title":"Assign back-transformation type to be applied to analysts' point-estimates — assign_transformation_type","text":"Assign back-transformation type applied analysts' point-estimates","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/assign_transformation_type.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Assign back-transformation type to be applied to analysts' point-estimates — assign_transformation_type","text":"","code":"assign_transformation_type(   response_transformation = character(1L),   link_fun = character(1L) )"},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/assign_transformation_type.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Assign back-transformation type to be applied to analysts' point-estimates — assign_transformation_type","text":"response_transformation Character vector length 1L containing analysis response transformation link_fun Character vector length 1L containing analysis link function","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/assign_transformation_type.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Assign back-transformation type to be applied to analysts' point-estimates — assign_transformation_type","text":"character vector length 1L containing back-transformation type applied analysts' point-estimates. either \"identity\", \"double_transformation\", value link_fun response_transformation, NA, appropriate transformation type assigned.","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/assign_transformation_type.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Assign back-transformation type to be applied to analysts' point-estimates — assign_transformation_type","text":"Based response transformation link function, function assigns back-transformation type applied analysts' point-estimates. function assigns identity transformation effects reported link-scale estimates already back-transformed original response variable prior modelling. either cases true given analysis, function returns value link_fun response_transformation argument. analysis reported link-scale analyst transformed response variable prior modelling, function assigns \"double-transformation\"  value analysis. response_transformation link_fun arguments missing, function assigns \"identity\" value analysis, assuming NA values equivalent identity transformation.","code":""},{"path":[]},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/augment_prediction_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Augment analyst out-of-sample prediction data according to the outcome of pointblank interrogation — augment_prediction_data","title":"Augment analyst out-of-sample prediction data according to the outcome of pointblank interrogation — augment_prediction_data","text":"augment_prediction_data() relabel remove extraneous columns --sample prediction data.","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/augment_prediction_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Augment analyst out-of-sample prediction data according to the outcome of pointblank interrogation — augment_prediction_data","text":"","code":"augment_prediction_data(.data, checks, dataset)"},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/augment_prediction_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Augment analyst out-of-sample prediction data according to the outcome of pointblank interrogation — augment_prediction_data","text":".data data.frame -sample-predictions analyst submission data checks data.frame pointblank interrogation output .data dataset character string equal either \"blue tit\" \"eucalyptus\"","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/augment_prediction_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Augment analyst out-of-sample prediction data according to the outcome of pointblank interrogation — augment_prediction_data","text":"dataframe. Individual analyst submission containing augmented --sample prediction data ready meta-analysis.","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/augment_prediction_data.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Augment analyst out-of-sample prediction data according to the outcome of pointblank interrogation — augment_prediction_data","text":"missing variables .data checks missing, NA returned augmented prediction data instead.","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/augment_prediction_data.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Augment analyst out-of-sample prediction data according to the outcome of pointblank interrogation — augment_prediction_data","text":"","code":"# for testing and dev purposes: # safe_augment <- purrr:::safely(augment_prediction_data)"},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/back.html","id":null,"dir":"Reference","previous_headings":"","what":"Back-transform effect-sizes to response scale. — back","title":"Back-transform effect-sizes to response scale. — back","text":"Transforms effect-sizes standard errors response scale.","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/back.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Back-transform effect-sizes to response scale. — back","text":"","code":"log_back(beta, se, sim)  logit_back(beta, se, sim)  probit_back(beta, se, sim)  inverse_back(beta, se, sim)  square_back(beta, se, sim)  cube_back(beta, se, sim)  identity_back(beta, se, sim)  power_back(beta, se, sim, n)  divide_back(beta, se, sim, n)  square_root_back(beta, se, sim)"},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/back.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Back-transform effect-sizes to response scale. — back","text":"beta Analyst beta estimate se Standard error analyst's effect size estimate \\(\\beta\\) --sample prediction estimate \\(y_i\\). sim numeric vector length 1. number simulations. n Denominator used analyst divide response variable.","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/back.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Back-transform effect-sizes to response scale. — back","text":"data frame containing mean estimate, standard error, quantiles.","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/back.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Back-transform effect-sizes to response scale. — back","text":"assume analysts' estimates normally distributed. function uses normal distribution simulate distribution effect-sizes standard errors. Next distribution back-transformed desired response scale. mean m_est, standard error se_est, quantiles (lower upper) back-transformed distribution returned within dataframe.","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/back.html","id":"functions","dir":"Reference","previous_headings":"","what":"Functions","title":"Back-transform effect-sizes to response scale. — back","text":"log_back(): Back transform beta estimates models log-link logit_back(): Back transform beta estimates models logit-link probit_back(): Back transform beta estimates models probit-link inverse_back(): Back transform beta estimates models \\(1/x\\) link square_back(): Back transform beta estimates models \\(x^2\\)-link cube_back(): Back transform beta estimates models \\(x^3\\)-link identity_back(): Back transform beta estimates models identity-link power_back(): Back transform beta estimates models power-link divide_back(): Back transform beta estimates --sample predictions models whose response variable divided number, n. square_root_back(): Back transform beta estimates --sample predictions models whose response variable transformed square root","code":""},{"path":[]},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/back_transform_response_vars_yi.html","id":null,"dir":"Reference","previous_headings":"","what":"Back Transform Response Variables - yi — back_transform_response_vars_yi","title":"Back Transform Response Variables - yi — back_transform_response_vars_yi","text":"Back Transform Response Variables - yi","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/back_transform_response_vars_yi.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Back Transform Response Variables - yi — back_transform_response_vars_yi","text":"","code":"back_transform_response_vars_yi(   dat,   estimate_type = character(1L),   dataset = character(1L) )"},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/back_transform_response_vars_yi.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Back Transform Response Variables - yi — back_transform_response_vars_yi","text":"dat dataframe sample predictions analyst submission data estimate_type type estimate standardised. Character vector length 1, whose value may  \"yi\", \"y25\", \"y50\", \"y75\". dataset One either \"blue tit\" \"eucalyptus\"","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/back_transform_response_vars_yi.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Back Transform Response Variables - yi — back_transform_response_vars_yi","text":"tibble analyst data standardised values contained list-column called 'back_transformed_data'","code":""},{"path":[]},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/box_cox_transform.html","id":null,"dir":"Reference","previous_headings":"","what":"Box-cox transform absolute deviation from the meta-analytic mean scores — box_cox_transform","title":"Box-cox transform absolute deviation from the meta-analytic mean scores — box_cox_transform","text":"Box-cox transform absolute deviation meta-analytic mean scores","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/box_cox_transform.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Box-cox transform absolute deviation from the meta-analytic mean scores — box_cox_transform","text":"","code":"box_cox_transform(data, dataset, outcome_SE_colname)"},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/box_cox_transform.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Box-cox transform absolute deviation from the meta-analytic mean scores — box_cox_transform","text":"data Dataset model fitting, must contain columns \"abs_deviation_score_estimate\" standard error dataset character string length 1 either \"blue tit\" \"eucalyptus\"","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/box_cox_transform.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Box-cox transform absolute deviation from the meta-analytic mean scores — box_cox_transform","text":"data additional columns box-cox transformed deviation scores variance","code":""},{"path":[]},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/calc_I2_ml.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate I2 for a multilevel meta-analytic model — calc_I2_ml","title":"Calculate I2 for a multilevel meta-analytic model — calc_I2_ml","text":"Calculate I2 multilevel meta-analytic model","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/calc_I2_ml.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate I2 for a multilevel meta-analytic model — calc_I2_ml","text":"","code":"calc_I2_ml(fitted_model)"},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/calc_I2_ml.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate I2 for a multilevel meta-analytic model — calc_I2_ml","text":"fitted_model class rma.mv","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/calc_I2_ml.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate I2 for a multilevel meta-analytic model — calc_I2_ml","text":"numeric vector length 1.","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/calc_I2_ml.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Calculate I2 for a multilevel meta-analytic model — calc_I2_ml","text":"http://www.metafor-project.org/doku.php/tips:i2_multilevel_multivariate described Nakagawa & Santos, 2012.","code":""},{"path":[]},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/calc_analyses_per_team.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate total number of analyses per team for a given subset — calc_analyses_per_team","title":"Calculate total number of analyses per team for a given subset — calc_analyses_per_team","text":"Calculates number analyses conducted team dataset given subset.","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/calc_analyses_per_team.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate total number of analyses per team for a given subset — calc_analyses_per_team","text":"","code":"calc_analyses_per_team(data, subset_name = character(1L))"},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/calc_analyses_per_team.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate total number of analyses per team for a given subset — calc_analyses_per_team","text":"data tibble containing data analysed. subset_name character vector length 1, name subset data analysed.","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/calc_analyses_per_team.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate total number of analyses per team for a given subset — calc_analyses_per_team","text":"tibble containing number analyses per team dataset given subset_name.","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/calc_analyses_per_team.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate total number of analyses per team for a given subset — calc_analyses_per_team","text":"","code":"ManyEcoEvo::ManyEcoEvo %>%   select(data) %>%   unnest(everything()) %>%   prepare_df_for_summarising() %>%   calc_analyses_per_team(\"All\") #> Error in unnest(., everything()): could not find function \"unnest\""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/calc_summary_stats_binary.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate summary statistics for binary summary variables — calc_summary_stats_binary","title":"Calculate summary statistics for binary summary variables — calc_summary_stats_binary","text":"Calculates total number analyses using linear models, mixed models, Bayesian models dataset, given subset. See prepare_df_for_summarising() details binary variables.","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/calc_summary_stats_binary.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate summary statistics for binary summary variables — calc_summary_stats_binary","text":"","code":"calc_summary_stats_binary(data, subset_name = character(1L))"},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/calc_summary_stats_binary.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate summary statistics for binary summary variables — calc_summary_stats_binary","text":"data tibble containing data analysed. subset_name character vector length 1, name subset data analysed.","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/calc_summary_stats_binary.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate summary statistics for binary summary variables — calc_summary_stats_binary","text":"tibble containing sum binary variables used analyses dataset given subset.","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/calc_summary_stats_binary.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate summary statistics for binary summary variables — calc_summary_stats_binary","text":"","code":"ManyEcoEvo::ManyEcoEvo %>%   select(data) %>%   unnest(everything()) %>%   prepare_df_for_summarising() %>%   calc_summary_stats_binary(\"All\") #> Error in unnest(., everything()): could not find function \"unnest\""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/calc_summary_stats_numeric.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate summary statistics for numeric summary variables — calc_summary_stats_numeric","title":"Calculate summary statistics for numeric summary variables — calc_summary_stats_numeric","text":"Calculates mean, standard deviation, minimum maximum numeric summary variable (See prepare_df_for_summarising()). numeric variables used analyses dataset, given subset. Summary statistics aggregated across variable type \\(Number fixed variables within analysis, number random variables within analysis, analysis samplesize, number interaction terms within analysis\\).","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/calc_summary_stats_numeric.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate summary statistics for numeric summary variables — calc_summary_stats_numeric","text":"","code":"calc_summary_stats_numeric(data, subset_name = character(1L))"},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/calc_summary_stats_numeric.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate summary statistics for numeric summary variables — calc_summary_stats_numeric","text":"data tibble containing data analysed. subset_name character vector length 1, name subset data analysed.","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/calc_summary_stats_numeric.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate summary statistics for numeric summary variables — calc_summary_stats_numeric","text":"tibble containing mean, standard deviation, minimum maximum values numeric variable used analyses dataset given subset.","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/calc_summary_stats_numeric.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate summary statistics for numeric summary variables — calc_summary_stats_numeric","text":"","code":"ManyEcoEvo::ManyEcoEvo %>%   select(data) %>%   unnest(everything()) %>%   prepare_df_for_summarising() %>%   calc_summary_stats_numeric(\"All\") #> Error in unnest(., everything()): could not find function \"unnest\""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/calc_teams_per_dataset.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate the number of teams per dataset for a given subset — calc_teams_per_dataset","title":"Calculate the number of teams per dataset for a given subset — calc_teams_per_dataset","text":"Calculate number teams per dataset given subset","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/calc_teams_per_dataset.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate the number of teams per dataset for a given subset — calc_teams_per_dataset","text":"","code":"calc_teams_per_dataset(data, subset_name = character(1L))"},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/calc_teams_per_dataset.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate the number of teams per dataset for a given subset — calc_teams_per_dataset","text":"data tibble containing data analysed. subset_name character vector length 1, name subset data analysed.","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/calc_teams_per_dataset.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate the number of teams per dataset for a given subset — calc_teams_per_dataset","text":"tibble containing number teams per dataset given subset_name.","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/calc_teams_per_dataset.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate the number of teams per dataset for a given subset — calc_teams_per_dataset","text":"","code":"ManyEcoEvo::ManyEcoEvo %>%   select(data) %>%   unnest(everything()) %>%   prepare_df_for_summarising() %>%   calc_teams_per_dataset(\"all\") #> Error in unnest(., everything()): could not find function \"unnest\""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/calculate_deviation_score.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate deviation from meta-analytic mean — calculate_deviation_score","title":"Calculate deviation from meta-analytic mean — calculate_deviation_score","text":"Calculate absolute deviation standardised effect size meta-analytic mean","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/calculate_deviation_score.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate deviation from meta-analytic mean — calculate_deviation_score","text":"","code":"calculate_deviation_score(data, meta_analytic_model, outcome_colname)"},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/calculate_deviation_score.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate deviation from meta-analytic mean — calculate_deviation_score","text":"data Dataset containing column \"Z\" \\(standardised sample prediction piont estimates\\) standardised effect-sizes, \"Zr\". meta_analytic_model Fitted meta-analytic model class rma outcome_colname Column name data containing outcomes used meta-analysis","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/calculate_deviation_score.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate deviation from meta-analytic mean — calculate_deviation_score","text":"data additional column deviation score estimates \"abs_deviation_score_estimate\"","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/calculate_sorensen_diversity_index.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate mean Sorensen pair-wise dissimilarity values for a ManyAnalyst dataset — calculate_sorensen_diversity_index","title":"Calculate mean Sorensen pair-wise dissimilarity values for a ManyAnalyst dataset — calculate_sorensen_diversity_index","text":"Calculate mean Sorensen pair-wise dissimilarity values ManyAnalyst dataset","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/calculate_sorensen_diversity_index.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate mean Sorensen pair-wise dissimilarity values for a ManyAnalyst dataset — calculate_sorensen_diversity_index","text":"","code":"calculate_sorensen_diversity_index(.data, .id = character())"},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/calculate_sorensen_diversity_index.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate mean Sorensen pair-wise dissimilarity values for a ManyAnalyst dataset — calculate_sorensen_diversity_index","text":".data variable diversity dataset columns unique variable used analyses. Values NA analysis use variable, take value variable character string analysis use variable. unique analysis row. .id character string analysis identifier column","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/calculate_sorensen_diversity_index.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate mean Sorensen pair-wise dissimilarity values for a ManyAnalyst dataset — calculate_sorensen_diversity_index","text":"tibble containing variables id_col, mean_diversity_index num_variables; total number variables used given analysis.","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/calculate_sorensen_diversity_index.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Calculate mean Sorensen pair-wise dissimilarity values for a ManyAnalyst dataset — calculate_sorensen_diversity_index","text":"Sorensen pair-wise dissimilarity calculated number shared variables two analyses divided total number variables used analyses. calculating Sorensen dissimilarity pairwise comparisons, function computes mean diversity index analysis mean pairwise comparisons analysis, generating single value per analysis.","code":""},{"path":[]},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/calculate_variable_counts.html","id":null,"dir":"Reference","previous_headings":"","what":"Count the number of times variables are used across analyses — calculate_variable_counts","title":"Count the number of times variables are used across analyses — calculate_variable_counts","text":"function used count number times variable used across analyses dataset. output tibble columns variable count contains number times variable used across analyses dataset. Count number times variables used across analyses","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/calculate_variable_counts.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Count the number of times variables are used across analyses — calculate_variable_counts","text":"","code":"calculate_variable_counts(data, subset_name = character(1L))"},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/calculate_variable_counts.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Count the number of times variables are used across analyses — calculate_variable_counts","text":"data tibble variables used analyses dataset, given subset. subset_name character vector length 1, name subset data analysed.","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/calculate_variable_counts.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Count the number of times variables are used across analyses — calculate_variable_counts","text":"tibble containing number times variable used across analyses dataset.","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/calculate_variable_counts.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Count the number of times variables are used across analyses — calculate_variable_counts","text":"Takes tibble diversity data, .e. data ready computing Sorensen diversity indices computes number times variable used across analyses. Note, function group dataset, layout dataset assumes variable within given dataset occur another dataset.","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/capwords.html","id":null,"dir":"Reference","previous_headings":"","what":"Capitalise Words — capwords","title":"Capitalise Words — capwords","text":"Capitalise Words","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/capwords.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Capitalise Words — capwords","text":"","code":"capwords(s, strict = FALSE)"},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/capwords.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Capitalise Words — capwords","text":"s character string containing words captalised strict whether capitalise words ","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/capwords.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Capitalise Words — capwords","text":"character string whose words now capitalised","code":""},{"path":[]},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/capwords.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Capitalise Words — capwords","text":"","code":"capwords(\"bah, bah, black sheep\") #> [1] \"Bah, Bah, Black Sheep\""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/clean_response_transformation.html","id":null,"dir":"Reference","previous_headings":"","what":"Clean response transformation variable — clean_response_transformation","title":"Clean response transformation variable — clean_response_transformation","text":"Cleans response transformation variable names back-transformation functions","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/clean_response_transformation.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Clean response transformation variable — clean_response_transformation","text":"","code":"clean_response_transformation(   response_transformation,   transformation_tbl = ManyEcoEvo:::transformation_tbl )"},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/clean_response_transformation.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Clean response transformation variable — clean_response_transformation","text":"response_transformation character vector response transformation values transformation_tbl tibble response transformation values transformation_orig cleaned names cleaned_transformation","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/clean_response_transformation.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Clean response transformation variable — clean_response_transformation","text":"character vector cleaned response transformation values equal required transformation values conversion()","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/clean_response_transformation.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Clean response transformation variable — clean_response_transformation","text":"transformation_tbl tibble response transformation values transformation_orig cleaned names cleaned_transformation. transformation_orig values original response transformation values used analyst. cleaned_transformation values cleaned response transformation values equal required transformation values conversion(). user can supply alternate table transformations depending required back-transformation functions.","code":""},{"path":[]},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/clean_response_transformation.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Clean response transformation variable — clean_response_transformation","text":"","code":"clean_response_transformation(\"power2\", ManyEcoEvo:::transformation_tbl)  #> Error in flatten_chr(.): could not find function \"flatten_chr\" clean_response_transformation(\"log\", ManyEcoEvo:::transformation_tbl) #> Error in flatten_chr(.): could not find function \"flatten_chr\" clean_response_transformation(\"new_transformation\", ManyEcoEvo:::transformation_tbl ) # Returns NA if not found #> Error in flatten_chr(.): could not find function \"flatten_chr\""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/compare_ml_MA.html","id":null,"dir":"Reference","previous_headings":"","what":"Compare two fitted multi-level models — compare_ml_MA","title":"Compare two fitted multi-level models — compare_ml_MA","text":"Compares two fitted multi-level models tidies results","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/compare_ml_MA.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compare two fitted multi-level models — compare_ml_MA","text":"","code":"compare_ml_MA(object1, object2)"},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/compare_ml_MA.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compare two fitted multi-level models — compare_ml_MA","text":"object1 fitted model class mra.mv object2 Another fitted model class mra.mv","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/compare_ml_MA.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compare two fitted multi-level models — compare_ml_MA","text":"tibble descriptive statistics model fit","code":""},{"path":[]},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/compute_MA_inputs.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute meta-analysis inputs for a nested-dataframe containing different datasets/subsets of analyst data — compute_MA_inputs","title":"Compute meta-analysis inputs for a nested-dataframe containing different datasets/subsets of analyst data — compute_MA_inputs","text":"Computes Sorensen diversity indices joins data preparation meta-analysing subsets data meta_analyse_datasets().","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/compute_MA_inputs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute meta-analysis inputs for a nested-dataframe containing different datasets/subsets of analyst data — compute_MA_inputs","text":"","code":"compute_MA_inputs(ManyEcoEvo, estimate_type = NULL)"},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/compute_MA_inputs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute meta-analysis inputs for a nested-dataframe containing different datasets/subsets of analyst data — compute_MA_inputs","text":"ManyEcoEvo dataframe grouped character columns dataset, estimate_type, exclusion_set. group corresponds subset full dataset, subset analyst data  stored data, corresponding subset diversity_data. estimate_type character string, one \"Zr\", \"yi\", \"y25\", \"y50\", \"y75\".","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/compute_MA_inputs.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute meta-analysis inputs for a nested-dataframe containing different datasets/subsets of analyst data — compute_MA_inputs","text":"dataframe includes additional columns ManyEcoEvo, added columns diversity_indices effects_analysis.","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/compute_MA_inputs.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Compute meta-analysis inputs for a nested-dataframe containing different datasets/subsets of analyst data — compute_MA_inputs","text":"Computes Sorensen diversity indices diversity_indices subset data returning list-column diversity_indices joins relevant subset processed analyst data within list-column effects_analysis. Note , name subset derived functions within subset_fns_yi() /subset_fns_Zr() called previous step data processing generate_exclusion_subsets(). user wish skip generate_exclusion_subsets() step, can supply arbitrary values exclusion_set function still work. run data subsetting complete, otherwise diversity indices need recalculated.","code":""},{"path":[]},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/compute_metaanalysis_inputs.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute all metaanalysis inputs for different types of estimates — compute_metaanalysis_inputs","title":"Compute all metaanalysis inputs for different types of estimates — compute_metaanalysis_inputs","text":"Compute metaanalysis inputs different types estimates","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/compute_metaanalysis_inputs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute all metaanalysis inputs for different types of estimates — compute_metaanalysis_inputs","text":"","code":"compute_metaanalysis_inputs(.data, estimate_type = character(1L))"},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/compute_metaanalysis_inputs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute all metaanalysis inputs for different types of estimates — compute_metaanalysis_inputs","text":".data dataset containing necessary values computing meta-analysis inputs estimate_type character string, one \"Zr\", \"yi\", \"y25\", \"y50\", \"y75\".","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/compute_metaanalysis_inputs.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute all metaanalysis inputs for different types of estimates — compute_metaanalysis_inputs","text":"dataframe processed data ready meta-analysis","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/conversion.html","id":null,"dir":"Reference","previous_headings":"","what":"Apply back-transformation to beta estimates — conversion","title":"Apply back-transformation to beta estimates — conversion","text":"Conditionally apply back-transformation functions depending value transformation.","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/conversion.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Apply back-transformation to beta estimates — conversion","text":"","code":"conversion(beta, se, transformation, sim = 10000)"},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/conversion.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Apply back-transformation to beta estimates — conversion","text":"beta Beta estimate, numeric vector length 1. se Standard error beta estimate, numeric vector length 1 transformation Character string describing transformation sim Number simulations use back-transformation. Defaults $10000$.","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/conversion.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Apply back-transformation to beta estimates — conversion","text":"outputs back-transformation function, see family back-transformations","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/conversion.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Apply back-transformation to beta estimates — conversion","text":"transformation character strings may take values: \"log\" \"logit\" \"probit\" \"square\" \"probit\" \"double_transformation\" \"cube\" \"inverse\" \"square_root\" \"powerX\", X numeric \"divided..X\", X numeric","code":""},{"path":[]},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/conversion_2.html","id":null,"dir":"Reference","previous_headings":"","what":"Conditionally apply back-transformation — conversion_2","title":"Conditionally apply back-transformation — conversion_2","text":"Conditionally apply back-transformation functions depending value transformation","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/conversion_2.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Conditionally apply back-transformation — conversion_2","text":"","code":"conversion_2(beta, se, response_transformation, link_fun, sim = 10000)"},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/conversion_2.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Conditionally apply back-transformation — conversion_2","text":"beta Beta estimate, numeric vector length 1. se Standard error beta estimate, numeric vector length 1 response_transformation Character string describing transformation link_fun Character string describing link function sim Number simulations use back-transformation. Defaults $10000$.","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/conversion_2.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Conditionally apply back-transformation — conversion_2","text":"outputs back-transformation function, see family back-transformations","code":""},{"path":[]},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/convert_predictions.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert Predictions — convert_predictions","title":"Convert Predictions — convert_predictions","text":"Converts sample predictions link scale back response scale","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/convert_predictions.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert Predictions — convert_predictions","text":"","code":"convert_predictions(   augmented_data,   transformation_type,   response_transformation,   link_fun )"},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/convert_predictions.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert Predictions — convert_predictions","text":"augmented_data tibble analyst's sample prediction data 3 scenarios","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/convert_predictions.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert Predictions — convert_predictions","text":"tibble sample predictions response variable scale response variable used analyst","code":""},{"path":[]},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/count_analyses_variables_used.html","id":null,"dir":"Reference","previous_headings":"","what":"Count number of analyses each variable is used — count_analyses_variables_used","title":"Count number of analyses each variable is used — count_analyses_variables_used","text":"Count number analyses variable used","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/count_analyses_variables_used.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Count number of analyses each variable is used — count_analyses_variables_used","text":"","code":"count_analyses_variables_used(data)"},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/count_analyses_variables_used.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Count number of analyses each variable is used — count_analyses_variables_used","text":"data dataframe containing variables dataset, id_col columns filled name variable indicating variable usage.","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/count_analyses_variables_used.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Count number of analyses each variable is used — count_analyses_variables_used","text":"dataframe counts n variable used across analyses within given dataset","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/count_analyses_variables_used.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Count number of analyses each variable is used — count_analyses_variables_used","text":"Values variable columns character strings NA. NA values treated absence variable given analysis (observation / row), character strings treated presence variable given analysis. Variable presence analysis converted numeric 1's/0's summed calculate total times analysis used across analyses (n).","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/count_analyses_variables_used.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Count number of analyses each variable is used — count_analyses_variables_used","text":"Hannah S. Fraser Elliot Gould","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/count_analyses_variables_used.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Count number of analyses each variable is used — count_analyses_variables_used","text":"","code":"library(ManyEcoEvo) ManyEcoEvo %>%   select(diversity_data) %>%   tidyr::unnest(diversity_data) %>%   count_analyses_variables_used() #> Error in select(., diversity_data): could not find function \"select\""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/count_binary_coded_features.html","id":null,"dir":"Reference","previous_headings":"","what":"Summarise binary coded features of analyses — count_binary_coded_features","title":"Summarise binary coded features of analyses — count_binary_coded_features","text":"Summarise binary coded features analyses","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/count_binary_coded_features.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summarise binary coded features of analyses — count_binary_coded_features","text":"","code":"count_binary_coded_features(data)"},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/count_binary_coded_features.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summarise binary coded features of analyses — count_binary_coded_features","text":"data dataframe containing variables dataset, lm, mixed_model, Bayesian, coded binary numeric vectors.","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/count_binary_coded_features.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Summarise binary coded features of analyses — count_binary_coded_features","text":"dataframe variables","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/count_binary_coded_features.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Summarise binary coded features of analyses — count_binary_coded_features","text":"Hannah S. Fraser Elliot Gould","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/count_binary_coded_features.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Summarise binary coded features of analyses — count_binary_coded_features","text":"","code":"ManyEcoEvo %>%   filter(dataset == \"eucalyptus\") %>%   ungroup() %>%   select(data) %>%   unnest(data) %>%   mutate(     lm = ifelse(linear_model == \"linear\", 1, 0), # TODO move into master processing     glm = ifelse(linear_model == \"generalised\", 1, 0),     Bayesian = as.numeric(Bayesian)   ) %>%   count_binary_coded_features() #> Error in mutate(., lm = ifelse(linear_model == \"linear\", 1, 0), glm = ifelse(linear_model ==     \"generalised\", 1, 0), Bayesian = as.numeric(Bayesian)): could not find function \"mutate\""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/count_conclusions.html","id":null,"dir":"Reference","previous_headings":"","what":"Count the number of different conclusions made by analysts across each dataset. — count_conclusions","title":"Count the number of different conclusions made by analysts across each dataset. — count_conclusions","text":"Takes first analysis per team per dataset, analysis submitted. Thus filters analyses split_id == 1 analysis_id == 1","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/count_conclusions.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Count the number of different conclusions made by analysts across each dataset. — count_conclusions","text":"","code":"count_conclusions(data, subset_name = character(1L))"},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/count_conclusions.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Count the number of different conclusions made by analysts across each dataset. — count_conclusions","text":"data tibble containing data analysed. subset_name character vector length 1, name subset data analysed.","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/count_conclusions.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Count the number of different conclusions made by analysts across each dataset. — count_conclusions","text":"tibble containing counts conclusion type made analysts across dataset, given subset.","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/count_teams_analyses.html","id":null,"dir":"Reference","previous_headings":"","what":"Summarise number of analyst teams and total analyses per dataset — count_teams_analyses","title":"Summarise number of analyst teams and total analyses per dataset — count_teams_analyses","text":"Summarise number analyst teams total analyses per dataset","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/count_teams_analyses.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summarise number of analyst teams and total analyses per dataset — count_teams_analyses","text":"","code":"count_teams_analyses(data)"},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/count_teams_analyses.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summarise number of analyst teams and total analyses per dataset — count_teams_analyses","text":"data dataframe containing variables TeamIdentifier dataset","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/count_teams_analyses.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Summarise number of analyst teams and total analyses per dataset — count_teams_analyses","text":"dataframe columns  dataset, total_teams total_analyses equal number rows number unique values within dataset variable input data.","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/count_teams_analyses.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Summarise number of analyst teams and total analyses per dataset — count_teams_analyses","text":"Hannah S. Fraser Elliot Gould","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/count_teams_analyses.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Summarise number of analyst teams and total analyses per dataset — count_teams_analyses","text":"","code":"ManyEcoEvo %>%   filter(dataset == \"blue tit\") %>%   ungroup() %>%   select(data) %>%   unnest(data) %>%   count_teams_analyses() #> Error in unnest(., data): could not find function \"unnest\""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/est_to_zr.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert estimate to Zr — est_to_zr","title":"Convert estimate to Zr — est_to_zr","text":"Convert estimate Zr","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/est_to_zr.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert estimate to Zr — est_to_zr","text":"","code":"est_to_zr(beta_estimate, beta_SE, adjusted_df)"},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/est_to_zr.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert estimate to Zr — est_to_zr","text":"beta_estimate numeric vector, beta estimate analysis either blue tit eucalyptus dataset beta_SE numeric vector, standard error beta_estimate adjusted_df numeric vector adjusted degrees freedom analysis generating beta_SE beta_estimate","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/est_to_zr.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert estimate to Zr — est_to_zr","text":"named list length 2 containing converted Zr VZr values","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/est_to_zr.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Convert estimate to Zr — est_to_zr","text":"Convert beta estimate, standard error degrees freedom r Zr sampling variance","code":""},{"path":[]},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/exclude_extreme_VZ.html","id":null,"dir":"Reference","previous_headings":"","what":"Exclude extreme values of VZ from a dataframe of standardised predictions — exclude_extreme_VZ","title":"Exclude extreme values of VZ from a dataframe of standardised predictions — exclude_extreme_VZ","text":"Exclude extreme values VZ dataframe standardised predictions","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/exclude_extreme_VZ.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Exclude extreme values of VZ from a dataframe of standardised predictions — exclude_extreme_VZ","text":"","code":"exclude_extreme_VZ(df = data.frame(), VZ_colname, VZ_cutoff = numeric(1L))"},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/exclude_extreme_VZ.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Exclude extreme values of VZ from a dataframe of standardised predictions — exclude_extreme_VZ","text":"df dataframe containing processed --sample prediction values VZ_colname character vector corresponding column name df containing VZ values filter . VZ_cutoff numeric vector length 1, values equal greater value VZ filtered df.","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/exclude_extreme_VZ.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Exclude extreme values of VZ from a dataframe of standardised predictions — exclude_extreme_VZ","text":"dataframe observations removed value less VZ_cutoff.","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/fit_MA_mv.html","id":null,"dir":"Reference","previous_headings":"","what":"Fit Meta-regression with random-effects — fit_MA_mv","title":"Fit Meta-regression with random-effects — fit_MA_mv","text":"Fit meta-regression model random effects using metafor::rma.mv() function metafor::metafor package data.frame containing estimates variances meta-analysis.","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/fit_MA_mv.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fit Meta-regression with random-effects — fit_MA_mv","text":"","code":"fit_MA_mv(   effects_analysis = data.frame(),   outcome_colname,   outcome_SE_colname,   estimate_type = character(1L) )"},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/fit_MA_mv.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fit Meta-regression with random-effects — fit_MA_mv","text":"effects_analysis dataframe containing estimates variances meta-analysis. outcome_colname name column containing estimates. outcome_SE_colname name column containing variances. estimate_type type estimate used model. One c(\"Zr\", \"y50\", \"y25\", \"y75\", \"yi\").","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/fit_MA_mv.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fit Meta-regression with random-effects — fit_MA_mv","text":"fitted model class c(\"rma.mv\",\"rma\").","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/fit_MA_mv.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Fit Meta-regression with random-effects — fit_MA_mv","text":"function wrapper around metafor::rma.mv() function metafor::metafor package. takes dataframe containing estimates variances meta-analysis, name column containing estimates, name column containing variances, type estimate used model. fits metaregression model random-effects using metafor::rma.mv() function called fit_metafor_mv() returns fitted model. Nested random effects included TeamIdentifier TeamIdentifier/study_id.","code":""},{"path":[]},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/fit_MA_mv.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fit Meta-regression with random-effects — fit_MA_mv","text":"","code":"ManyEcoEvo_results$effects_analysis[[1]] %>%   fit_MA_mv(beta_estimate, beta_SE, \"Zr\") #>  #> ── Fitting metaregression ── #>  #>  #> Multivariate Meta-Analysis Model (k = 131; method: REML) #>  #> Variance Components: #>  #>                estim     sqrt  nlvls  fixed                   factor  #> sigma^2.1   979.7136  31.3004     63     no           TeamIdentifier  #> sigma^2.2  6623.0949  81.3824    131     no  TeamIdentifier/study_id  #>  #> Test for Heterogeneity: #> Q(df = 130) = 7544.9806, p-val < .0001 #>  #> Model Results: #>  #> estimate      se     zval    pval     ci.lb   ci.ub     #> -10.9500  8.4194  -1.3006  0.1934  -27.4517  5.5518     #>  #> --- #> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 #>"},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/fit_boxcox_ratings_cat.html","id":null,"dir":"Reference","previous_headings":"","what":"Fit model of boxcox deviation scores as function of continuous ratings — fit_boxcox_ratings_cat","title":"Fit model of boxcox deviation scores as function of continuous ratings — fit_boxcox_ratings_cat","text":"Fit lmer model box-cox transformed deviation meta-analytic mean scores function continuous peer-review ratings","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/fit_boxcox_ratings_cat.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fit model of boxcox deviation scores as function of continuous ratings — fit_boxcox_ratings_cat","text":"","code":"fit_boxcox_ratings_cat(   data,   outcome,   outcome_var,   interceptless = FALSE,   ...,   env = rlang::caller_env() )"},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/fit_boxcox_ratings_cat.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fit model of boxcox deviation scores as function of continuous ratings — fit_boxcox_ratings_cat","text":"data Data model fitting outcome outcome variable, unquoted. outcome_var Variance outcome variable interceptless logical relating whether model interceptless . Defaults FALSE.","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/fit_boxcox_ratings_cat.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fit model of boxcox deviation scores as function of continuous ratings — fit_boxcox_ratings_cat","text":"object class lme4::lmerMod-class","code":""},{"path":[]},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/fit_boxcox_ratings_cat.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fit model of boxcox deviation scores as function of continuous ratings — fit_boxcox_ratings_cat","text":"","code":"# Example Usage:   # library(tidyverse);library(targets);library(metafor)   # tar_load(meta_analysis_outputs)   # meta_analysis_outputs$data[[1]] %>%   #   fit_boxcox_ratings_cat(.,   # outcome = box_cox_abs_deviation_score_estimate,   #                                   outcome_var = VZr, interceptless = FALSE)"},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/fit_boxcox_ratings_cont.html","id":null,"dir":"Reference","previous_headings":"","what":"Fit model of boxcox deviation scores as function of continuous ratings — fit_boxcox_ratings_cont","title":"Fit model of boxcox deviation scores as function of continuous ratings — fit_boxcox_ratings_cont","text":"Fit lmer model box-cox transformed deviation meta-analytic mean scores function continuous peer-review ratings","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/fit_boxcox_ratings_cont.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fit model of boxcox deviation scores as function of continuous ratings — fit_boxcox_ratings_cont","text":"","code":"fit_boxcox_ratings_cont(   data,   outcome,   outcome_var,   ...,   env = rlang::caller_env() )"},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/fit_boxcox_ratings_cont.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fit model of boxcox deviation scores as function of continuous ratings — fit_boxcox_ratings_cont","text":"data Data model fitting outcome outcome variable, unquoted. outcome_var Variance outcome variable","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/fit_boxcox_ratings_cont.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fit model of boxcox deviation scores as function of continuous ratings — fit_boxcox_ratings_cont","text":"object class lme4::lmerMod-class","code":""},{"path":[]},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/fit_boxcox_ratings_ord.html","id":null,"dir":"Reference","previous_headings":"","what":"Fit model of boxcox deviation scores as function of continuous ratings — fit_boxcox_ratings_ord","title":"Fit model of boxcox deviation scores as function of continuous ratings — fit_boxcox_ratings_ord","text":"Fit lmer model box-cox transformed deviation meta-analytic mean scores function continuous peer-review ratings","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/fit_boxcox_ratings_ord.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fit model of boxcox deviation scores as function of continuous ratings — fit_boxcox_ratings_ord","text":"","code":"fit_boxcox_ratings_ord(.data, outcome, outcome_var, interceptless = FALSE)"},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/fit_boxcox_ratings_ord.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fit model of boxcox deviation scores as function of continuous ratings — fit_boxcox_ratings_ord","text":".data Data model fitting outcome outcome variable, unquoted. outcome_var Variance outcome variable interceptless logical relating whether model interceptless . Defaults FALSE.","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/fit_boxcox_ratings_ord.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fit model of boxcox deviation scores as function of continuous ratings — fit_boxcox_ratings_ord","text":"object class lme4::lmerMod-class","code":""},{"path":[]},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/fit_metafor_mv.html","id":null,"dir":"Reference","previous_headings":"","what":"Fit Multivariate Metaregression using metafoR — fit_metafor_mv","title":"Fit Multivariate Metaregression using metafoR — fit_metafor_mv","text":"Fit Multivariate Metaregression using metafoR","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/fit_metafor_mv.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fit Multivariate Metaregression using metafoR — fit_metafor_mv","text":"","code":"fit_metafor_mv(estimate, variance, estimate_type = character(1L), data)"},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/fit_metafor_mv.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fit Multivariate Metaregression using metafoR — fit_metafor_mv","text":"estimate Numeric vector variance Numeric vector estimate_type Character vector either \"Zr\", \"y50\", \"y25\", \"y75\". data Dataframe containing estimates variances case id column study_id.","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/fit_metafor_mv.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fit Multivariate Metaregression using metafoR — fit_metafor_mv","text":"Object class rma.mv","code":""},{"path":[]},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/fit_metafor_mv_reduced.html","id":null,"dir":"Reference","previous_headings":"","what":"Fit reduced metaregression model — fit_metafor_mv_reduced","title":"Fit reduced metaregression model — fit_metafor_mv_reduced","text":"Fit reduced metaregression model","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/fit_metafor_mv_reduced.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fit reduced metaregression model — fit_metafor_mv_reduced","text":"","code":"fit_metafor_mv_reduced(estimate, variance, estimate_type = character(1L), data)"},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/fit_metafor_mv_reduced.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fit reduced metaregression model — fit_metafor_mv_reduced","text":"estimate Numeric vector variance Numeric vector estimate_type Character vector either \"Zr\", \"y50\", \"y25\", \"y75\". data Dataframe containing estimates variances case id column study_id.","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/fit_metafor_mv_reduced.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fit reduced metaregression model — fit_metafor_mv_reduced","text":"Object class rma.mv","code":""},{"path":[]},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/fit_metafor_uni.html","id":null,"dir":"Reference","previous_headings":"","what":"Fit univariate meta-analysis with metafor — fit_metafor_uni","title":"Fit univariate meta-analysis with metafor — fit_metafor_uni","text":"Fit univariate meta-analysis metafor","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/fit_metafor_uni.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fit univariate meta-analysis with metafor — fit_metafor_uni","text":"","code":"fit_metafor_uni(Zr, VZr, data, slab)"},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/fit_metafor_uni.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fit univariate meta-analysis with metafor — fit_metafor_uni","text":"Zr Standardized beta-estimate VZr Standardised standard error beta estimate data Dataframe containing estimates variances slab Vector case identifiers","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/fit_metafor_uni.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fit univariate meta-analysis with metafor — fit_metafor_uni","text":"fitted model class rma","code":""},{"path":[]},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/fit_metafor_uni.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fit univariate meta-analysis with metafor — fit_metafor_uni","text":"","code":"# library(tidyverse);library(targets);library(metafor) # source(\"R/functions.R\") # tar_read(round_2_survey_meta_analysis) %>% #   filter(dataset == \"eucalyptus\") %>% #   filter(!is.na(Zr), #          !is.na(VZr), #          !is.infinite(Zr), #          !is.infinite(VZr)) %>% # fit_metafor_uni(Zr = .$Zr, #                      VZr = .$VZr, #                      data = ., #                      slab = .$study_id)"},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/fit_multivar_MA.html","id":null,"dir":"Reference","previous_headings":"","what":"Fit a multivariate meta-regression model — fit_multivar_MA","title":"Fit a multivariate meta-regression model — fit_multivar_MA","text":"Fit multivariate meta-regression model models effect peer-review ratings deviation meta-analytic mean (continuous categorical ratings), mean Sorensen's index, /whether analysis uses mixed effects model, .","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/fit_multivar_MA.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fit a multivariate meta-regression model — fit_multivar_MA","text":"","code":"fit_multivar_MA(data_tbl, N = 5, ..., env = rlang::caller_env())"},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/fit_multivar_MA.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fit a multivariate meta-regression model — fit_multivar_MA","text":"data_tbl Data model fitting N threshold number analyses must conducted using mixed effects models include binary predictor mixed_model meta-regression. Defaults 5. ... Additional arguments passed lme4::lmer env Environment evaluate formula, defaults calling environment","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/fit_multivar_MA.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fit a multivariate meta-regression model — fit_multivar_MA","text":"object class lmer.","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/fit_multivar_MA.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Fit a multivariate meta-regression model — fit_multivar_MA","text":"Depending whether enough analyses data_tbl conducted mixed_model variable, function fit model without predictor mixed_model. Expects following columns data_tbl: RateAnalysis: continuous peer-review ratings PublishableAsIs: categorical peer-review ratings mean_diversity_index: mean Sorensen's index box_cox_abs_deviation_score_estimate: response variable, Box-Cox transformed deviation meta-analytic mean effect-size analysis mixed_model: binary variable indicating whether analysis used mixed effects model ReviewerId: reviewer identifier","code":""},{"path":[]},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/fit_sorensen_glm.html","id":null,"dir":"Reference","previous_headings":"","what":"Fit univariate glm of deviation scores on sorensen diversity index — fit_sorensen_glm","title":"Fit univariate glm of deviation scores on sorensen diversity index — fit_sorensen_glm","text":"Fit univariate glm deviation scores sorensen diversity index","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/fit_sorensen_glm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fit univariate glm of deviation scores on sorensen diversity index — fit_sorensen_glm","text":"","code":"fit_sorensen_glm(data)"},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/fit_sorensen_glm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fit univariate glm of deviation scores on sorensen diversity index — fit_sorensen_glm","text":"data data.frame containing Box-Cox transformed absolute deviation meta-analytic mean scores mean Sorensen's scores analysis","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/fit_sorensen_glm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fit univariate glm of deviation scores on sorensen diversity index — fit_sorensen_glm","text":"fitted model object class glm parsnip","code":""},{"path":[]},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/fit_uni_mixed_effects.html","id":null,"dir":"Reference","previous_headings":"","what":"Fit model of Box-Cox transformed deviation scores as a function random-effects inclusion in analyses — fit_uni_mixed_effects","title":"Fit model of Box-Cox transformed deviation scores as a function random-effects inclusion in analyses — fit_uni_mixed_effects","text":"Fits univariate glm Box-Cox transformed absolute deviation meta-analytic mean scores function whether analysis mixed effects model (.e. included random effects) .","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/fit_uni_mixed_effects.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fit model of Box-Cox transformed deviation scores as a function random-effects inclusion in analyses — fit_uni_mixed_effects","text":"","code":"fit_uni_mixed_effects(data, N = 5)"},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/fit_uni_mixed_effects.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fit model of Box-Cox transformed deviation scores as a function random-effects inclusion in analyses — fit_uni_mixed_effects","text":"data Dataframe containing Box-Cox transformed absolute deviation scores binary column called mixed_model describing whether analysis used mixed-effects model. N threshold number analyses predictor category fitting model","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/fit_uni_mixed_effects.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fit model of Box-Cox transformed deviation scores as a function random-effects inclusion in analyses — fit_uni_mixed_effects","text":"fitted model object class glm parsnip","code":""},{"path":[]},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/fit_uni_mixed_effects.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fit model of Box-Cox transformed deviation scores as a function random-effects inclusion in analyses — fit_uni_mixed_effects","text":"","code":"# library(tidyverse);library(targets);library(metafor);library(tidymodels) # tar_load(meta_analysis_outputs) # fit_uni_mixed_effects(meta_analysis_results$data[[1]])"},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/folded_params.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate the folded parameters for the Box-Cox transformation — folded_params","title":"Calculate the folded parameters for the Box-Cox transformation — folded_params","text":"Calculate folded parameters Box-Cox transformation","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/folded_params.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate the folded parameters for the Box-Cox transformation — folded_params","text":"","code":"folded_params(abs_dev_score, VZr)"},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/folded_params.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate the folded parameters for the Box-Cox transformation — folded_params","text":"abs_dev_score absolute deviation score VZr variance standardised effect size","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/folded_params.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate the folded parameters for the Box-Cox transformation — folded_params","text":"named list containing mean fold_mu variance fold_v folded parameters","code":""},{"path":[]},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/formulae_match.html","id":null,"dir":"Reference","previous_headings":"","what":"Match formulae to outcome variables — formulae_match","title":"Match formulae to outcome variables — formulae_match","text":"Match formulae outcome variables","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/formulae_match.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Match formulae to outcome variables — formulae_match","text":"","code":"formulae_match(x, y)"},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/formulae_match.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Match formulae to outcome variables — formulae_match","text":"x character vector y vector","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/formulae_match.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Match formulae to outcome variables — formulae_match","text":"named list formulae","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/formulae_match.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Match formulae to outcome variables — formulae_match","text":"function used match formulae variables data.frame. x y vector, formulae matched variable.","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/generate_collinearity_subset.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate Collinearity Data Subset — generate_collinearity_subset","title":"Generate Collinearity Data Subset — generate_collinearity_subset","text":"function generates subset data used demonstrate effects collinearity regression models. data generated sampling multivariate normal distribution specified correlation matrix.","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/generate_collinearity_subset.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate Collinearity Data Subset — generate_collinearity_subset","text":"","code":"generate_collinearity_subset(ManyEcoEvo, collinearity_subset)"},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/generate_collinearity_subset.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate Collinearity Data Subset — generate_collinearity_subset","text":"ManyEcoEvo ManyEcoEvo dataframe containing formatted raw data, formatted diversity_data, estimate_type,  dataset, publishable_subset, exclusion_set. See details. collinearity_subset dataframe containing column response_id containing response ID's included expert subset","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/generate_collinearity_subset.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate Collinearity Data Subset — generate_collinearity_subset","text":"ManyEcoEvo dataframe added column expertise_subset new subsets data diversity_data","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/generate_collinearity_subset.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Generate Collinearity Data Subset — generate_collinearity_subset","text":"#' Note function needs run ManyEcoEvo following functions run (See examples): prepare_response_variables() generate_exclusion_subsets() generate_rating_subsets() generate_collinearity_subset() creates expertise subsets based full dataset exclusion_set == \"complete\" publishable_subset == \"\" expertise_subset == \"\".","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/generate_collinearity_subset.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generate Collinearity Data Subset — generate_collinearity_subset","text":"","code":"ManyEcoEvo %>%   prepare_response_variables(estimate_type = \"Zr\") |>   generate_exclusion_subsets(estimate_type = \"Zr\") |>   generate_rating_subsets() |>   generate_expertise_subsets(ManyEcoEvo:::expert_subset) |>   generate_collinearity_subset(collinearity_subset = collinearity_subset) #> Error in eval(expr, envir, enclos): object 'collinearity_subset' not found"},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/generate_exclusion_subsets.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate subsets of analyst data based on different exclusion criteria — generate_exclusion_subsets","title":"Generate subsets of analyst data based on different exclusion criteria — generate_exclusion_subsets","text":"Generates subsets data different combinations outliers removed different exclusion_sets.","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/generate_exclusion_subsets.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate subsets of analyst data based on different exclusion criteria — generate_exclusion_subsets","text":"","code":"generate_exclusion_subsets(ManyEcoEvo, estimate_type = NULL)"},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/generate_exclusion_subsets.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate subsets of analyst data based on different exclusion criteria — generate_exclusion_subsets","text":"ManyEcoEvo dataframe containing minimum character column dataset list-columns data diversity_data. estimate_type character vector, one \"Zr\", \"yi\", \"y25\", \"y50\", \"y75\", NULL.","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/generate_exclusion_subsets.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate subsets of analyst data based on different exclusion criteria — generate_exclusion_subsets","text":"dataframe grouped dataset exclusion_set contains subsets data diversity_data based exclusion criteria functions defined subset_fns_Zr() subset_funs_yi(), estimate_type column.","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/generate_exclusion_subsets.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Generate subsets of analyst data based on different exclusion criteria — generate_exclusion_subsets","text":"estimate_type NULL, column estimate_type must ManyEcoEvo. function uses functions subset_fns_Zr() []subset_fns_yi() create named lists elements containing purrr::-style lambda functions, whose element name name function. NULL provided argument estimate_type, column estimate_type must exist ManyEcoEvo, column used filter exclusion criteria functions. value column exclusion_set returned object name exclusion criteria function, prefix \"subset_\" removed, derived either subset_fns_Zr() subset_funs_yi(), depending estimate_type. Note: function exectued prepare_response_variables() generate_yi_subsets().","code":""},{"path":[]},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/generate_expertise_subsets.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate Expertise Data Subsets — generate_expertise_subsets","title":"Generate Expertise Data Subsets — generate_expertise_subsets","text":"Generate Expertise Data Subsets","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/generate_expertise_subsets.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate Expertise Data Subsets — generate_expertise_subsets","text":"","code":"generate_expertise_subsets(ManyEcoEvo, expert_subset)"},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/generate_expertise_subsets.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate Expertise Data Subsets — generate_expertise_subsets","text":"ManyEcoEvo ManyEcoEvo dataframe containing formatted raw data, formatted diversity_data, estimate_type,  dataset, publishable_subset, exclusion_set. See details. expert_subset dataframe containing column response_id containing response ID's included expert subset","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/generate_expertise_subsets.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate Expertise Data Subsets — generate_expertise_subsets","text":"ManyEcoEvo dataframe added column expertise_subset new subsets data diversity_data","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/generate_expertise_subsets.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Generate Expertise Data Subsets — generate_expertise_subsets","text":"Note function needs run ManyEcoEvo following functions run (See examples): prepare_response_variables() generate_exclusion_subsets() generate_rating_subsets() generate_rating_subsets() creates expertise subsets based full dataset exclusion_set == \"complete\" publishable_subset == \"\".","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/generate_expertise_subsets.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generate Expertise Data Subsets — generate_expertise_subsets","text":"","code":"library(ManyEcoEvo) library(tidyverse) #> ── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ── #> ✔ dplyr     1.1.4     ✔ readr     2.1.5 #> ✔ forcats   1.0.0     ✔ stringr   1.5.1 #> ✔ ggplot2   3.5.1     ✔ tibble    3.2.1 #> ✔ lubridate 1.9.3     ✔ tidyr     1.3.1 #> ✔ purrr     1.0.2      #> ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ── #> ✖ dplyr::filter() masks stats::filter() #> ✖ dplyr::lag()    masks stats::lag() #> ℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors library(targets) ManyEcoEvo %>%   prepare_response_variables(estimate_type = \"Zr\") |>   generate_exclusion_subsets(estimate_type = \"Zr\") |>   generate_rating_subsets() |>   generate_expertise_subsets(ManyEcoEvo:::expert_subset) #>  #> ── Applying exclusion rules and generating exclusion subsets ─────────────────── #> ℹ Standardising response variables for \"Zr\" estimates. #>  #> ── Computing meta-analysis inputsfor `estimate_type` = \"Zr\" ──────────────────── #>  #> ── Computing standardised effect sizes `Zr` and variance `VZr` ── #>  #> ✖ Required values for computing standardised effect sizes missing: #> ! Returning \"NA\" for tupple: #> 1. beta_estimate NA, #> 2. beta_se NA, #> 3. adjusted_df 484.0193. #> ✖ Required values for computing standardised effect sizes missing: #> ! Returning \"NA\" for tupple: #> 1. beta_estimate NA, #> 2. beta_se NA, #> 3. adjusted_df 666.56874. #> ✖ Required values for computing standardised effect sizes missing: #> ! Returning \"NA\" for tupple: #> 1. beta_estimate NA, #> 2. beta_se NA, #> 3. adjusted_df 590.18263. #> ✖ Required values for computing standardised effect sizes missing: #> ! Returning \"NA\" for tupple: #> 1. beta_estimate NA, #> 2. beta_se 0.006225, #> 3. adjusted_df NA. #> ✖ Required values for computing standardised effect sizes missing: #> ! Returning \"NA\" for tupple: #> 1. beta_estimate NA, #> 2. beta_se 0.003996, #> 3. adjusted_df NA. #> ✖ Required values for computing standardised effect sizes missing: #> ! Returning \"NA\" for tupple: #> 1. beta_estimate NA, #> 2. beta_se NA, #> 3. adjusted_df NA. #> ✖ Required values for computing standardised effect sizes missing: #> ! Returning \"NA\" for tupple: #> 1. beta_estimate NA, #> 2. beta_se NA, #> 3. adjusted_df NA. #> ✖ Required values for computing standardised effect sizes missing: #> ! Returning \"NA\" for tupple: #> 1. beta_estimate NA, #> 2. beta_se NA, #> 3. adjusted_df NA. #> ✖ Required values for computing standardised effect sizes missing: #> ! Returning \"NA\" for tupple: #> 1. beta_estimate NA, #> 2. beta_se NA, #> 3. adjusted_df NA. #> ✖ Required values for computing standardised effect sizes missing: #> ! Returning \"NA\" for tupple: #> 1. beta_estimate NA, #> 2. beta_se NA, #> 3. adjusted_df NA. #> ✖ Required values for computing standardised effect sizes missing: #> ! Returning \"NA\" for tupple: #> 1. beta_estimate NA, #> 2. beta_se NA, #> 3. adjusted_df 481. #> ✖ Required values for computing standardised effect sizes missing: #> ! Returning \"NA\" for tupple: #> 1. beta_estimate NA, #> 2. beta_se 0.09247, #> 3. adjusted_df 316.17526. #> ✖ Required values for computing standardised effect sizes missing: #> ! Returning \"NA\" for tupple: #> 1. beta_estimate NA, #> 2. beta_se 0.029, #> 3. adjusted_df 366.3. #> ✖ Required values for computing standardised effect sizes missing: #> ! Returning \"NA\" for tupple: #> 1. beta_estimate NA, #> 2. beta_se 0.042, #> 3. adjusted_df NA. #> ✖ Required values for computing standardised effect sizes missing: #> ! Returning \"NA\" for tupple: #> 1. beta_estimate NA, #> 2. beta_se NA, #> 3. adjusted_df NA. #> ✖ Required values for computing standardised effect sizes missing: #> ! Returning \"NA\" for tupple: #> 1. beta_estimate NA, #> 2. beta_se 0.01416305, #> 3. adjusted_df 257.905. #> ✖ Required values for computing standardised effect sizes missing: #> ! Returning \"NA\" for tupple: #> 1. beta_estimate NA, #> 2. beta_se NA, #> 3. adjusted_df NA. #> ✖ Required values for computing standardised effect sizes missing: #> ! Returning \"NA\" for tupple: #> 1. beta_estimate NA, #> 2. beta_se 0.030382264, #> 3. adjusted_df 2372.82. #> ✖ Required values for computing standardised effect sizes missing: #> ! Returning \"NA\" for tupple: #> 1. beta_estimate NA, #> 2. beta_se 0.01409, #> 3. adjusted_df NA. #> ✖ Required values for computing standardised effect sizes missing: #> ! Returning \"NA\" for tupple: #> 1. beta_estimate NA, #> 2. beta_se 0.008781, #> 3. adjusted_df NA. #> ✖ Required values for computing standardised effect sizes missing: #> ! Returning \"NA\" for tupple: #> 1. beta_estimate NA, #> 2. beta_se 0.014853, #> 3. adjusted_df NA. #> ✖ Required values for computing standardised effect sizes missing: #> ! Returning \"NA\" for tupple: #> 1. beta_estimate NA, #> 2. beta_se NA, #> 3. adjusted_df NA. #> ✖ Required values for computing standardised effect sizes missing: #> ! Returning \"NA\" for tupple: #> 1. beta_estimate NA, #> 2. beta_se NA, #> 3. adjusted_df NA. #> ✖ Required values for computing standardised effect sizes missing: #> ! Returning \"NA\" for tupple: #> 1. beta_estimate NA, #> 2. beta_se NA, #> 3. adjusted_df NA. #> ✖ Required values for computing standardised effect sizes missing: #> ! Returning \"NA\" for tupple: #> 1. beta_estimate NA, #> 2. beta_se NA, #> 3. adjusted_df NA. #> ✖ Required values for computing standardised effect sizes missing: #> ! Returning \"NA\" for tupple: #> 1. beta_estimate NA, #> 2. beta_se 0.000769, #> 3. adjusted_df NA. #> ✖ Required values for computing standardised effect sizes missing: #> ! Returning \"NA\" for tupple: #> 1. beta_estimate NA, #> 2. beta_se NA, #> 3. adjusted_df NA. #> ✖ Required values for computing standardised effect sizes missing: #> ! Returning \"NA\" for tupple: #> 1. beta_estimate NA, #> 2. beta_se NA, #> 3. adjusted_df NA. #> ✖ Required values for computing standardised effect sizes missing: #> ! Returning \"NA\" for tupple: #> 1. beta_estimate NA, #> 2. beta_se NA, #> 3. adjusted_df NA. #> ✖ Required values for computing standardised effect sizes missing: #> ! Returning \"NA\" for tupple: #> 1. beta_estimate NA, #> 2. beta_se 0.033978443, #> 3. adjusted_df 347.4992526. #> ✖ Required values for computing standardised effect sizes missing: #> ! Returning \"NA\" for tupple: #> 1. beta_estimate NA, #> 2. beta_se NA, #> 3. adjusted_df NA. #> ✖ Required values for computing standardised effect sizes missing: #> ! Returning \"NA\" for tupple: #> 1. beta_estimate NA, #> 2. beta_se NA, #> 3. adjusted_df NA. #> ✖ Required values for computing standardised effect sizes missing: #> ! Returning \"NA\" for tupple: #> 1. beta_estimate NA, #> 2. beta_se 0.01823188, #> 3. adjusted_df 55.44391. #> ✖ Required values for computing standardised effect sizes missing: #> ! Returning \"NA\" for tupple: #> 1. beta_estimate NA, #> 2. beta_se 0.02039768, #> 3. adjusted_df NA. #> ✖ Required values for computing standardised effect sizes missing: #> ! Returning \"NA\" for tupple: #> 1. beta_estimate NA, #> 2. beta_se 0.02496, #> 3. adjusted_df NA. #> ✖ Required values for computing standardised effect sizes missing: #> ! Returning \"NA\" for tupple: #> 1. beta_estimate NA, #> 2. beta_se 0.03575, #> 3. adjusted_df NA. #>  #> ── Computing meta-analysis inputsfor `estimate_type` = \"Zr\" ──────────────────── #>  #> ── Computing standardised effect sizes `Zr` and variance `VZr` ── #>  #> ✖ Required values for computing standardised effect sizes missing: #> ! Returning \"NA\" for tupple: #> 1. beta_estimate NA, #> 2. beta_se 0.29212, #> 3. adjusted_df 21. #> ✖ Required values for computing standardised effect sizes missing: #> ! Returning \"NA\" for tupple: #> 1. beta_estimate NA, #> 2. beta_se 0.007831, #> 3. adjusted_df NA. #> ✖ Required values for computing standardised effect sizes missing: #> ! Returning \"NA\" for tupple: #> 1. beta_estimate NA, #> 2. beta_se 0.07216, #> 3. adjusted_df 0.560867697. #> ✖ Required values for computing standardised effect sizes missing: #> ! Returning \"NA\" for tupple: #> 1. beta_estimate NA, #> 2. beta_se 0.57, #> 3. adjusted_df NA. #> ✖ Required values for computing standardised effect sizes missing: #> ! Returning \"NA\" for tupple: #> 1. beta_estimate NA, #> 2. beta_se NA, #> 3. adjusted_df NA. #> ✖ Required values for computing standardised effect sizes missing: #> ! Returning \"NA\" for tupple: #> 1. beta_estimate NA, #> 2. beta_se NA, #> 3. adjusted_df NA. #> ✖ Required values for computing standardised effect sizes missing: #> ! Returning \"NA\" for tupple: #> 1. beta_estimate NA, #> 2. beta_se NA, #> 3. adjusted_df NA. #> ✖ Required values for computing standardised effect sizes missing: #> ! Returning \"NA\" for tupple: #> 1. beta_estimate NA, #> 2. beta_se NA, #> 3. adjusted_df NA. #> ✖ Required values for computing standardised effect sizes missing: #> ! Returning \"NA\" for tupple: #> 1. beta_estimate NA, #> 2. beta_se NA, #> 3. adjusted_df NA. #> ✖ Required values for computing standardised effect sizes missing: #> ! Returning \"NA\" for tupple: #> 1. beta_estimate NA, #> 2. beta_se 0.2328, #> 3. adjusted_df 343.24787. #> ✖ Required values for computing standardised effect sizes missing: #> ! Returning \"NA\" for tupple: #> 1. beta_estimate NA, #> 2. beta_se 0.3188723, #> 3. adjusted_df NA. #> ✖ Required values for computing standardised effect sizes missing: #> ! Returning \"NA\" for tupple: #> 1. beta_estimate NA, #> 2. beta_se NA, #> 3. adjusted_df NA. #> ✖ Required values for computing standardised effect sizes missing: #> ! Returning \"NA\" for tupple: #> 1. beta_estimate NA, #> 2. beta_se 0.0059286, #> 3. adjusted_df 1. #> ✖ Required values for computing standardised effect sizes missing: #> ! Returning \"NA\" for tupple: #> 1. beta_estimate NA, #> 2. beta_se NA, #> 3. adjusted_df NA. #> ✖ Required values for computing standardised effect sizes missing: #> ! Returning \"NA\" for tupple: #> 1. beta_estimate NA, #> 2. beta_se 0.007385, #> 3. adjusted_df 3.5e-25. #> ✖ Required values for computing standardised effect sizes missing: #> ! Returning \"NA\" for tupple: #> 1. beta_estimate NA, #> 2. beta_se 0.052462, #> 3. adjusted_df 3.5e-25. #> ✖ Required values for computing standardised effect sizes missing: #> ! Returning \"NA\" for tupple: #> 1. beta_estimate NA, #> 2. beta_se 0.605, #> 3. adjusted_df NA. #> ✖ Required values for computing standardised effect sizes missing: #> ! Returning \"NA\" for tupple: #> 1. beta_estimate NA, #> 2. beta_se 8.98, #> 3. adjusted_df NA. #> ✖ Required values for computing standardised effect sizes missing: #> ! Returning \"NA\" for tupple: #> 1. beta_estimate NA, #> 2. beta_se 7.97, #> 3. adjusted_df NA. #> ✖ Required values for computing standardised effect sizes missing: #> ! Returning \"NA\" for tupple: #> 1. beta_estimate NA, #> 2. beta_se 5.19, #> 3. adjusted_df NA. #> ✖ Required values for computing standardised effect sizes missing: #> ! Returning \"NA\" for tupple: #> 1. beta_estimate NA, #> 2. beta_se 18.5, #> 3. adjusted_df NA. #> ✖ Required values for computing standardised effect sizes missing: #> ! Returning \"NA\" for tupple: #> 1. beta_estimate NA, #> 2. beta_se 5.92, #> 3. adjusted_df NA. #> ✖ Required values for computing standardised effect sizes missing: #> ! Returning \"NA\" for tupple: #> 1. beta_estimate NA, #> 2. beta_se 0.529, #> 3. adjusted_df NA. #> ✖ Required values for computing standardised effect sizes missing: #> ! Returning \"NA\" for tupple: #> 1. beta_estimate NA, #> 2. beta_se 2.89, #> 3. adjusted_df NA. #> ✖ Required values for computing standardised effect sizes missing: #> ! Returning \"NA\" for tupple: #> 1. beta_estimate NA, #> 2. beta_se 0.605, #> 3. adjusted_df NA. #> ✖ Required values for computing standardised effect sizes missing: #> ! Returning \"NA\" for tupple: #> 1. beta_estimate NA, #> 2. beta_se NA, #> 3. adjusted_df NA. #> ✖ Required values for computing standardised effect sizes missing: #> ! Returning \"NA\" for tupple: #> 1. beta_estimate NA, #> 2. beta_se NA, #> 3. adjusted_df NA. #> ✖ Required values for computing standardised effect sizes missing: #> ! Returning \"NA\" for tupple: #> 1. beta_estimate NA, #> 2. beta_se 0.01312667, #> 3. adjusted_df -2.6269353. #> ✖ Required values for computing standardised effect sizes missing: #> ! Returning \"NA\" for tupple: #> 1. beta_estimate NA, #> 2. beta_se NA, #> 3. adjusted_df NA. #> ✖ Required values for computing standardised effect sizes missing: #> ! Returning \"NA\" for tupple: #> 1. beta_estimate NA, #> 2. beta_se 0.197, #> 3. adjusted_df NA. #> ✖ Required values for computing standardised effect sizes missing: #> ! Returning \"NA\" for tupple: #> 1. beta_estimate NA, #> 2. beta_se 0.192, #> 3. adjusted_df 82.703. #> ✖ Required values for computing standardised effect sizes missing: #> ! Returning \"NA\" for tupple: #> 1. beta_estimate NA, #> 2. beta_se 0.1, #> 3. adjusted_df NA. #> ✖ Required values for computing standardised effect sizes missing: #> ! Returning \"NA\" for tupple: #> 1. beta_estimate NA, #> 2. beta_se NA, #> 3. adjusted_df NA. #> ✖ Required values for computing standardised effect sizes missing: #> ! Returning \"NA\" for tupple: #> 1. beta_estimate NA, #> 2. beta_se 0.0048042, #> 3. adjusted_df 341. #> ✖ Required values for computing standardised effect sizes missing: #> ! Returning \"NA\" for tupple: #> 1. beta_estimate NA, #> 2. beta_se 0.21, #> 3. adjusted_df NA. #> ✖ Required values for computing standardised effect sizes missing: #> ! Returning \"NA\" for tupple: #> 1. beta_estimate NA, #> 2. beta_se 0.5756016, #> 3. adjusted_df 3.536992. #> # A tibble: 14 × 7 #>    exclusion_set estimate_type dataset    data                diversity_data     #>    <chr>         <chr>         <chr>      <named list>        <named list>       #>  1 complete      Zr            blue tit   <tibble [131 × 40]> <tibble>           #>  2 complete      Zr            eucalyptus <tibble [79 × 40]>  <tibble [79 × 61]> #>  3 partial       Zr            blue tit   <tibble [118 × 40]> <tibble>           #>  4 partial       Zr            eucalyptus <tibble [70 × 40]>  <tibble [70 × 61]> #>  5 complete      Zr            blue tit   <tibble [109 × 6]>  <tibble>           #>  6 complete      Zr            blue tit   <tibble [32 × 6]>   <tibble [32 × 54]> #>  7 complete      Zr            eucalyptus <tibble [55 × 6]>   <tibble [55 × 61]> #>  8 complete      Zr            eucalyptus <tibble [13 × 6]>   <tibble [13 × 61]> #>  9 partial       Zr            blue tit   <tibble [100 × 6]>  <tibble>           #> 10 partial       Zr            blue tit   <tibble [32 × 6]>   <tibble [32 × 54]> #> 11 partial       Zr            eucalyptus <tibble [52 × 6]>   <tibble [52 × 61]> #> 12 partial       Zr            eucalyptus <tibble [10 × 6]>   <tibble [10 × 61]> #> 13 complete      Zr            blue tit   <tibble [89 × 40]>  <tibble [89 × 54]> #> 14 complete      Zr            eucalyptus <tibble [34 × 40]>  <tibble [34 × 61]> #> # ℹ 2 more variables: publishable_subset <chr>, expertise_subset <chr>"},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/generate_outlier_subsets.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate Outlier Subsets for ManyEcoEvo datasets — generate_outlier_subsets","title":"Generate Outlier Subsets for ManyEcoEvo datasets — generate_outlier_subsets","text":"Removes top outlier yi datasets top 2 bottom 2 outliers Zr datasets","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/generate_outlier_subsets.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate Outlier Subsets for ManyEcoEvo datasets — generate_outlier_subsets","text":"","code":"generate_outlier_subsets(   data,   outcome_variable = NULL,   n_min = NULL,   n_max = NULL,   ignore_subsets = NULL )"},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/generate_outlier_subsets.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate Outlier Subsets for ManyEcoEvo datasets — generate_outlier_subsets","text":"data ManyEcoEvo dataframe containing formatted raw data, formatted diversity_data, estimate_type, dataset outcome_variable named list containing either/list datasets corresponding outcome variables value dataset, list estimate_types corresponding outcome variables value estimate_type. n_min integer, number bottom outliers remove n_max integer, number top outliers remove ignore_subsets list <data-masked> expressions passed dplyr::filter() ignoring specific data subsets removing outliers","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/generate_outlier_subsets.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate Outlier Subsets for ManyEcoEvo datasets — generate_outlier_subsets","text":"ManyEcoEvo dataframe added column exclusion_set new subsets data, diversity_data exclude outliers.","code":""},{"path":[]},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/generate_outlier_subsets.html","id":"function-usage","dir":"Reference","previous_headings":"","what":"Function Usage","title":"Generate Outlier Subsets for ManyEcoEvo datasets — generate_outlier_subsets","text":"n_min n_max used specify number outliers remove bottom top dataset, respectively. arguments passed n argument within dplyr::slice_min() slice_max() respectively. Note negative values n_min n_max removed dataset, positive values n retain observations dataframe. ignore_subsets used specify subsets data ignored removing outliers. useful want remove outliers datasets except specific subsets. example, want remove outliers datasets except eucalyptus dataset, pass ignore_subsets = dataset == \"eucalyptus\". function check columns specified ignore_subsets exist dataset using pointblank::test_col_exists(). , function throw error.","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/generate_outlier_subsets.html","id":"analysis-pipeline-usage","dir":"Reference","previous_headings":"","what":"Analysis Pipeline Usage","title":"Generate Outlier Subsets for ManyEcoEvo datasets — generate_outlier_subsets","text":"function ahould run computing response variables yi datasets generate_yi_subsets() Zr datasets generate_Zr_subsets(), may also executed raw data remove top n_max bottom n_min observations. Note outcome_variable #TODO: nolonger work Zr dataset, contain estimate_type col? collinearity_subset != \"collinearity_removed\" Zr datasets run reduced publishability subset.... already 10 data points!!","code":""},{"path":[]},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/generate_outlier_subsets.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generate Outlier Subsets for ManyEcoEvo datasets — generate_outlier_subsets","text":"","code":"analysis_data <-  ManyEcoEvo_yi %>% prepare_response_variables( estimate_type = \"yi\", param_table = ManyEcoEvo:::analysis_data_param_tables, dataset_standardise = \"blue tit\", dataset_log_transform = \"eucalyptus\") %>% generate_yi_subsets() %>% #TODO: must be run after prepare_response_variables?? apply_VZ_exclusions( VZ_colname = list(\"eucalyptus\" = \"se_log\", \"blue tit\" = \"VZ\"), VZ_cutoff = 3) %>%  generate_exclusion_subsets() %>%  compute_MA_inputs() #>  #> ── Computing Sorensen diversity indices inputs ───────────────────────────────── #>  #> ── Applying exclusion rules and generating exclusion subsets ─────────────────── #>  #> ── Generating out-of-sample prediction subsets. ──────────────────────────────── #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ✔ Applied back-transformation for squared effect sizes or out-of-sample predictions. #> ✔ Applied back-transformation for squared effect sizes or out-of-sample predictions. #> ✔ Applied back-transformation for squared effect sizes or out-of-sample predictions. #> ✔ Applied back-transformation for squared effect sizes or out-of-sample predictions. #> ✔ Applied back-transformation for squared effect sizes or out-of-sample predictions. #> ✔ Applied back-transformation for squared effect sizes or out-of-sample predictions. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ✔ Applied back-transformation for ^100 effect sizes or out of sample predictions. #> ✔ Applied back-transformation for cubed effect sizes #> ✔ Applied back-transformation for ^100 effect sizes or out of sample predictions. #> ✔ Applied back-transformation for cubed effect sizes #> ✔ Applied back-transformation for ^100 effect sizes or out of sample predictions. #> ✔ Applied back-transformation for cubed effect sizes #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ✔ Applied back-transformation for ^14 effect sizes or out of sample predictions. #> ✔ Applied back-transformation for ^14 effect sizes or out of sample predictions. #> ✔ Applied back-transformation for ^14 effect sizes or out of sample predictions. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ℹ No back-transformation required, identity link used. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for logit-transformed effect sizes or out-of-sample predictions #> ✔ Applied back-transformation for logit-transformed effect sizes or out-of-sample predictions #> ✔ Applied back-transformation for logit-transformed effect sizes or out-of-sample predictions #> ✔ Applied back-transformation for logit-transformed effect sizes or out-of-sample predictions #> ✔ Applied back-transformation for logit-transformed effect sizes or out-of-sample predictions #> ✔ Applied back-transformation for logit-transformed effect sizes or out-of-sample predictions #> ✔ Applied back-transformation for logit-transformed effect sizes or out-of-sample predictions #> ✔ Applied back-transformation for logit-transformed effect sizes or out-of-sample predictions #> ✔ Applied back-transformation for logit-transformed effect sizes or out-of-sample predictions #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for square-root transformed effect sizes or out-of-sample predictions. #> ✔ Applied back-transformation for square-root transformed effect sizes or out-of-sample predictions. #> ✔ Applied back-transformation for square-root transformed effect sizes or out-of-sample predictions. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ℹ Standardising and/or log-transforming response variables for \"yi\" estimates. #>  #> ── Computing meta-analysis inputsfor `estimate_type` = \"yi\" ──────────────────── #>  #> ── Standardising out-of-sample predictions ── #>  #> ── Computing meta-analysis inputs: ───────────────────────────────────────────── #>  #> ── Log-transforming response-variable ── #>  #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #>  #> ── Applying VZ exclusions ────────────────────────────────────────────────────── #> ! `VZ_cutoff` = 3 was recycled to match the number of unique datasets in `df`. #>  #> ── Excluding extreme values of VZ ── #>  #> → 0 extreme values of `VZ` removed at threshold of 3 for `dataset` \"blue tit\", `estimate_type` = \"y25\". #>  #> ── Excluding extreme values of VZ ── #>  #> → 0 extreme values of `VZ` removed at threshold of 3 for `dataset` \"blue tit\", `estimate_type` = \"y25\". #>  #> ── Excluding extreme values of VZ ── #>  #> → 0 extreme values of `VZ` removed at threshold of 3 for `dataset` \"blue tit\", `estimate_type` = \"y25\". #>  #> ── Excluding extreme values of VZ ── #>  #> → 0 extreme values of `se_log` removed at threshold of 3 for `dataset` \"blue tit\", `estimate_type` = \"y25\". #>  #> ── Excluding extreme values of VZ ── #>  #> → 0 extreme values of `se_log` removed at threshold of 3 for `dataset` \"blue tit\", `estimate_type` = \"y25\". #>  #> ── Excluding extreme values of VZ ── #>  #> → 0 extreme values of `se_log` removed at threshold of 3 for `dataset` \"blue tit\", `estimate_type` = \"y25\". analysis_data %>% generate_outlier_subsets(outcome_variable = list(dataset = list(\"eucalyptus\" = \"mean_log\", \"blue tit\" = \"Z\"), \"estimate_type\" = list(\"Zr\" = \"Zr\")), n_min = -3, n_max = -3, ignore_subsets = list(estimate_type != \"y25\", dataset != \"eucalyptus\")) #> Error: object 'estimate_type' not found"},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/generate_rating_subsets.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate subsets of ManyEcoEvo Data based on Peer Review Ratings — generate_rating_subsets","title":"Generate subsets of ManyEcoEvo Data based on Peer Review Ratings — generate_rating_subsets","text":"Generates two subsets data based complete partial exclusion datasets yi Zr estimates.","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/generate_rating_subsets.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate subsets of ManyEcoEvo Data based on Peer Review Ratings — generate_rating_subsets","text":"","code":"generate_rating_subsets(ManyEcoEvo)"},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/generate_rating_subsets.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate subsets of ManyEcoEvo Data based on Peer Review Ratings — generate_rating_subsets","text":"ManyEcoEvo ManyEcoEvo dataframe containing formatted raw data, formatted diversity_data, estimate_type, dataset","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/generate_rating_subsets.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate subsets of ManyEcoEvo Data based on Peer Review Ratings — generate_rating_subsets","text":"ManyEcoEvo dataframe added column exclusion_set new subsets data diversity_data","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/generate_rating_subsets.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Generate subsets of ManyEcoEvo Data based on Peer Review Ratings — generate_rating_subsets","text":"executed ManyEcoEvo dataframe compute_MA_inputs() function. function generates two subsets data based peer review ratings complete partial exclusion datasets yi Zr estimates. subsets generated based PublishableAsIs column data list-column. subsets named data_flawed data_flawed_major created filtering data points PublishableAsIs values \"deeply flawed unpublishable\" \"publishable major revision\" respectively. diversity_data list-column also updated reflect new subsets data.","code":""},{"path":[]},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/generate_yi_subsets.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate subsets of out-of-sample predictions data by estimate_type for multiple analysis datasets. — generate_yi_subsets","title":"Generate subsets of out-of-sample predictions data by estimate_type for multiple analysis datasets. — generate_yi_subsets","text":"Generate subsets --sample predictions data estimate_type multiple analysis datasets.","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/generate_yi_subsets.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate subsets of out-of-sample predictions data by estimate_type for multiple analysis datasets. — generate_yi_subsets","text":"","code":"generate_yi_subsets(yi_analysis)"},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/generate_yi_subsets.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate subsets of out-of-sample predictions data by estimate_type for multiple analysis datasets. — generate_yi_subsets","text":"yi_analysis dataframe containing multiple datasets --sample predictions corresponding diversity data.","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/generate_yi_subsets.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate subsets of out-of-sample predictions data by estimate_type for multiple analysis datasets. — generate_yi_subsets","text":"datraframe character columns dataset, estimate_type list-cols data diversity_data","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/generate_yi_subsets.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Generate subsets of out-of-sample predictions data by estimate_type for multiple analysis datasets. — generate_yi_subsets","text":"object yi_analysis contain character column dataset, list-columns data diversity_data. essence, data diversity_data nested dataset. data list-col grouped_df, also contain list-col back_transformed_data. column back_transformed_data contains NA values, row removed list-column data. column estimate_type present yi_analysis, removed, replaced estimate_type derived scenario SurveyID columns back_transformed_data dataset.","code":""},{"path":[]},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/generate_yi_subsets.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Generate subsets of out-of-sample predictions data by estimate_type for multiple analysis datasets. — generate_yi_subsets","text":"Elliot Gould","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/get_MA_fit_stats.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract meta-analytic statistics like \\(I^2\\), etc. — get_MA_fit_stats","title":"Extract meta-analytic statistics like \\(I^2\\), etc. — get_MA_fit_stats","text":"Extract meta-analytic statistics like \\(^2\\), etc.","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/get_MA_fit_stats.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract meta-analytic statistics like \\(I^2\\), etc. — get_MA_fit_stats","text":"","code":"get_MA_fit_stats(MA_mod)"},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/get_MA_fit_stats.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract meta-analytic statistics like \\(I^2\\), etc. — get_MA_fit_stats","text":"MA_mod fitted model class rma.mv","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/get_MA_fit_stats.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract meta-analytic statistics like \\(I^2\\), etc. — get_MA_fit_stats","text":"tidy tibble \\(\\sigma^2\\) \\(^2\\) estimates MA_mod","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/get_diversity_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Get Diversity Data — get_diversity_data","title":"Get Diversity Data — get_diversity_data","text":"Get Diversity Data","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/get_diversity_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get Diversity Data — get_diversity_data","text":"","code":"get_diversity_data(raw_data, dataset, variables = character())"},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/get_diversity_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get Diversity Data — get_diversity_data","text":"raw_data tibble raw data dataset character string either \"eucalyptus\" \"blue tit\" variables character vector length containing names variables get diversity data ","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/get_diversity_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get Diversity Data — get_diversity_data","text":"tibble diversity data either 'eucalyptus' 'blue tit' analyses","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/get_diversity_data.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Get Diversity Data — get_diversity_data","text":"Called prepare_diversity_raw","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/get_forest_plot_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Get Forest Plot Data from a Metafor Model — get_forest_plot_data","title":"Get Forest Plot Data from a Metafor Model — get_forest_plot_data","text":"Get Forest Plot Data Metafor Model","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/get_forest_plot_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get Forest Plot Data from a Metafor Model — get_forest_plot_data","text":"","code":"get_forest_plot_data(model)"},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/get_forest_plot_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get Forest Plot Data from a Metafor Model — get_forest_plot_data","text":"model metafor model object class rma.mv rma.uni","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/get_forest_plot_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get Forest Plot Data from a Metafor Model — get_forest_plot_data","text":"tibble containing data required plot forest plot","code":""},{"path":[]},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/get_forest_plot_data.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get Forest Plot Data from a Metafor Model — get_forest_plot_data","text":"","code":"get_forest_plot_data(model) #> Error in eval(expr, envir, enclos): object 'model' not found"},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/gg_forest.html","id":null,"dir":"Reference","previous_headings":"","what":"Forestplot with ggplot2 — gg_forest","title":"Forestplot with ggplot2 — gg_forest","text":"Forestplot ggplot2","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/gg_forest.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Forestplot with ggplot2 — gg_forest","text":"","code":"gg_forest(meta_model, estimate_type, dataset = character(1L))"},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/gg_forest.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Forestplot with ggplot2 — gg_forest","text":"meta_model Fitted meta-analysis model class rma estimate_type Whether estimate standardized effect size standardised sample prediction. Must one \"Zr\", \"y50\", \"y25\", \"y75\". dataset Character string equal name dataset. One \"blue tit\" \"eucalyptus\"","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/gg_forest.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Forestplot with ggplot2 — gg_forest","text":"object class ggplot2","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/i2_ml.html","id":null,"dir":"Reference","previous_headings":"","what":"i2_ml — i2_ml","title":"i2_ml — i2_ml","text":"I2 (-squared) mulilevel meta-analytic models, based Nakagawa & Santos (2012). multilevel models, can multiple I2 (see also Senior et al. 2016). Alternatively, method proposed Wolfgang Viechtbauer can also used.","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/i2_ml.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"i2_ml — i2_ml","text":"","code":"i2_ml(model, method = c(\"ratio\", \"matrix\"), data, boot = NULL)"},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/i2_ml.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"i2_ml — i2_ml","text":"model Model object class rma.mv rma. Currently model objects using mods argument work (e.g., mod = ~1). method Method used calculate I2. Two options exist: ratio-based calculation proposed Nakagawa & Santos (\"ratio\"), Wolfgang Viechtbauer's matrix method (\"matrix\"). data Data frame used fit model. boot Number simulations run produce 95 percent confidence intervals I2. Default NULL, point estimate provided.","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/i2_ml.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"i2_ml — i2_ml","text":"data frame containing model results including mean effect size estimate, confidence, prediction intervals","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/i2_ml.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"i2_ml — i2_ml","text":"Shinichi Nakagawa - s.nakagawa@unsw.edu.au Daniel Noble - daniel.noble@anu.edu.au Elliot Gould - elliot.gould@unimelb.edu.au","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/log_transform.html","id":null,"dir":"Reference","previous_headings":"","what":"log transform response-scale yi estimates — log_transform","title":"log transform response-scale yi estimates — log_transform","text":"log transform response-scale yi estimates","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/log_transform.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"log transform response-scale yi estimates — log_transform","text":"","code":"log_transform(estimate = numeric(1L), std.error = numeric(1L), sim = 10000L)"},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/log_transform.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"log transform response-scale yi estimates — log_transform","text":"estimate Point estimates original response scale std.error Standard error point estimates original response scale sim Number simulations run generating distribution sample ","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/log_transform.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"log transform response-scale yi estimates — log_transform","text":"dataframe containing mean_log, se_log, lower upper 95% CI log scale","code":""},{"path":[]},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/log_transform.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"log transform response-scale yi estimates — log_transform","text":"","code":"log_transform(1.77, 1.01, 1000) #> ✔ Log-transformed out-of-sample predictions, using 1000 simulations. #>    mean_log     se_log     lower    upper #> 1 0.4376391 0.02321932 -1.431458 1.298296"},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/log_transform_yi.html","id":null,"dir":"Reference","previous_headings":"","what":"Log-transform a data-frame of back-transformed out-of-sample estimates — log_transform_yi","title":"Log-transform a data-frame of back-transformed out-of-sample estimates — log_transform_yi","text":"Log-transform data-frame back-transformed --sample estimates","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/log_transform_yi.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Log-transform a data-frame of back-transformed out-of-sample estimates — log_transform_yi","text":"","code":"log_transform_yi(back_transformed_data, sim = 10000L, ...)"},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/log_transform_yi.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Log-transform a data-frame of back-transformed out-of-sample estimates — log_transform_yi","text":"back_transformed_data description sim Number simulations run generating distribution sample ","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/log_transform_yi.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Log-transform a data-frame of back-transformed out-of-sample estimates — log_transform_yi","text":"tibble standardised---sample predictions Z-scale, columns Z, VZ, lower upper original columns fro back_transformed_data used / updated transformation.","code":""},{"path":[]},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/make_param_table.html","id":null,"dir":"Reference","previous_headings":"","what":"Make parameter table — make_param_table","title":"Make parameter table — make_param_table","text":"Calculates mean standard deviation numeric variables dataframe tibble.","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/make_param_table.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Make parameter table — make_param_table","text":"","code":"make_param_table(analysis_data, na.rm = TRUE)"},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/make_param_table.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Make parameter table — make_param_table","text":"analysis_data dataframe tibble. na.rm Logical. missing values removed?","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/make_param_table.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Make parameter table — make_param_table","text":"tibble.","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/make_param_table.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Make parameter table — make_param_table","text":"parameter table used computation Z-values standardisation --sample predictions pred_to_Zr(). make_param_table() returns tidy, long-form tibble variable names analysis_data stored columnvariable, corresponding parameter (\"mean\" \"sd\"), value parameter.","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/make_param_table.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Make parameter table — make_param_table","text":"Currently variable names analysis_data must contain . character used split variable parameter pivot_longer()","code":""},{"path":[]},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/make_param_table.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Make parameter table — make_param_table","text":"","code":"make_param_table(ManyEcoEvo::blue_tit_data) #> # A tibble: 34 × 3 #>    variable            parameter      value #>    <chr>               <chr>          <dbl> #>  1 hatch_year          mean        2002.    #>  2 hatch_year          sd             0.787 #>  3 hatch_nest_breed_ID mean      202139.    #>  4 hatch_nest_breed_ID sd           769.    #>  5 hatch_nest_OH       mean          41.7   #>  6 hatch_nest_OH       sd             8.54  #>  7 rear_nest_breed_ID  mean      202140.    #>  8 rear_nest_breed_ID  sd           771.    #>  9 rear_nest_trt       mean           5.78  #> 10 rear_nest_trt       sd             0.816 #> # ℹ 24 more rows make_param_table(ManyEcoEvo::euc_data) #> # A tibble: 74 × 3 #>    variable                parameter      value #>    <chr>                   <chr>          <dbl> #>  1 Quadrat no              mean            4.07 #>  2 Quadrat no              sd              2.37 #>  3 Easting                 mean       374341.   #>  4 Easting                 sd          24426.   #>  5 Northing                mean      5934936.   #>  6 Northing                sd          39485.   #>  7 ExoticAnnualGrass_cover mean           12.4  #>  8 ExoticAnnualGrass_cover sd             15.3  #>  9 ExoticAnnualHerb_cover  mean            7.89 #> 10 ExoticAnnualHerb_cover  sd             11.6  #> # ℹ 64 more rows"},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/make_viz.html","id":null,"dir":"Reference","previous_headings":"","what":"Make visualisations wrapper function — make_viz","title":"Make visualisations wrapper function — make_viz","text":"Computes model summaries, tidy model summaries, model fit stats, funnel plots forest plots dataframe multiple fitted models","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/make_viz.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Make visualisations wrapper function — make_viz","text":"","code":"make_viz(data)"},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/make_viz.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Make visualisations wrapper function — make_viz","text":"data nested dataframe processed standardised data stored list-column data, grouped variables exclusion_set, dataset, estimate_type, publishable_subset, expertise_subset, collinearity_subset. group contains list-column model containing fitted models class rma.uni, rma.mv merMod.","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/make_viz.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Make visualisations wrapper function — make_viz","text":"nested dataframe grouped variables exclusion_set, dataset, estimate_type, publishable_subset, expertise_subset, collinearity_subset containing model summaries, tidy model summaries, model fit stats, funnel plots forest plots","code":""},{"path":[]},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/map_match_formulae.html","id":null,"dir":"Reference","previous_headings":"","what":"Map matching formulae to data — map_match_formulae","title":"Map matching formulae to data — map_match_formulae","text":"Map matching formulae data","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/map_match_formulae.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Map matching formulae to data — map_match_formulae","text":"","code":"map_match_formulae(data, variable_name, formulae, col_name = \"outcome_colname\")"},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/map_match_formulae.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Map matching formulae to data — map_match_formulae","text":"data tibble variable_name character string, name variable match formulae named list formulae","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/map_match_formulae.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Map matching formulae to data — map_match_formulae","text":"tibble new column outcome_colname containing rhs matched formula, NA match found","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/meta_analyse_datasets.html","id":null,"dir":"Reference","previous_headings":"","what":"Meta-analyses multiple datasets or subsets of datasets of analyst data — meta_analyse_datasets","title":"Meta-analyses multiple datasets or subsets of datasets of analyst data — meta_analyse_datasets","text":"Runs meta-analyses regression models ManyEcoEvo project analysis, including: Fitting univariate / fixed-effects meta-analysis Calculating deviation every effect size / point-estimate meta-analytic mean data subsetes absolute, box-cox transformed deviation scores univariate GLM regression transformed deviation scores sorensen diversity indices univariate GLM regression transformed deviation scores continuous peer-review ratings univariate GLM regression transformed deviation scores categorical peer-review ratings univariate GLM regression transformed deviation scores binary variable corresponding whether analysis mixed-effects model (.e. GLM random-effects) . implemented: multivariate regression #TODO deviation scores transformed categorical ratings intercept (nice plotting / exploration).","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/meta_analyse_datasets.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Meta-analyses multiple datasets or subsets of datasets of analyst data — meta_analyse_datasets","text":"","code":"meta_analyse_datasets(   data,   outcome_variable = NULL,   outcome_SE = NULL,   filter_vars = NULL )"},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/meta_analyse_datasets.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Meta-analyses multiple datasets or subsets of datasets of analyst data — meta_analyse_datasets","text":"data nested- dataframe grouped dataset / exclusion_set, estimate_type, containing list-column prepared analyst subset data effects_analysis ready meta-analysis. filter_vars list expressions filter data dataframe . E.g. rlang::exprs(exclusion_set == \"complete\", expertise_subset == \"\", publishable_subset == \"\", collinearity_subset == \"\") #' @param outcome_variable named list containing either/list datasets corresponding outcome variables value dataset, list estimate_types corresponding outcome variables value estimate_type.","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/meta_analyse_datasets.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Meta-analyses multiple datasets or subsets of datasets of analyst data — meta_analyse_datasets","text":"nested dataframe columns object parsed arg data, additional columns results analysis: MA_mod, sorensen_glm, box_cox_ratings_cont, box_cox_ratings_cat, box_cox_rating_cat_no_int, uni_mixed_effects","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/meta_analyse_datasets.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Meta-analyses multiple datasets or subsets of datasets of analyst data — meta_analyse_datasets","text":"filter_vars supplied function filter data dataframe expressions list, data subsets excluded filtering multivariate met-analysis models fitted fit_multivar_MA(). arguments outcome_variable /outcome_variable supplied, function defaults : using \"Zr\" standardised effect size \"VZr\" standard error estimate_type \"Zr\". using \"Z\" standardised --sample estimate \"VZ\" standardised --sample estimate error estimate_type one c(\"yi\", \"y25\", \"y50\", \"y75\"). function check data dataframe contains required columns meta-analysis, including variable names specified calls filter_vars argument. required columns exist function stop error. Function assumes argument outcome_variable supplied, outcome_SE also supplied, conversely, outcome_SE supplied, neither outcome_variable (TODO yet checked function).","code":""},{"path":[]},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/meta_analyse_datasets.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Meta-analyses multiple datasets or subsets of datasets of analyst data — meta_analyse_datasets","text":"","code":"filter_vars <- rlang::exprs(   exclusion_set == \"complete\",   expertise_subset == \"All\",   publishable_subset == \"All\",   collinearity_subset == \"All\" )"},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/named_group_split.html","id":null,"dir":"Reference","previous_headings":"","what":"Split data frame by groups and name elements — named_group_split","title":"Split data frame by groups and name elements — named_group_split","text":"Split data frame groups name elements","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/named_group_split.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Split data frame by groups and name elements — named_group_split","text":"","code":"named_group_split(.data, grouping_variable)"},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/named_group_split.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Split data frame by groups and name elements — named_group_split","text":".data tbl. grouping_variable Unquoted variable name group columns ","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/named_group_split.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Split data frame by groups and name elements — named_group_split","text":"named list tibbles. tibble contains rows .tbl associated group columns, including grouping variables. Note returns list_of slightly stricter simple list useful representing lists every element type.","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/named_group_split.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Split data frame by groups and name elements — named_group_split","text":"Function fail character string provided grouping_variable instead bare variable name.","code":""},{"path":[]},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/named_group_split.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Split data frame by groups and name elements — named_group_split","text":"","code":"data(euc_data) data(blue_tit_data) named_group_split(euc_data, Property) #> $Barlow #> # A tibble: 18 × 42 #>    SurveyID Date       Season      `Quadrat no` Easting Northing Aspect #>    <fct>    <date>     <chr>              <dbl>   <dbl>    <dbl> <chr>  #>  1 1        2006-07-24 Winter 2006            1  310042  5934571 nne    #>  2 2        2006-07-24 Winter 2006            2  310087  5934567 ne     #>  3 3        2006-07-24 Winter 2006            3  310240  5934699 se     #>  4 4        2006-07-24 Winter 2006            4  309998  5934968 0      #>  5 5        2006-07-24 Winter 2006            5  309958  5934752 0      #>  6 6        2006-07-24 Winter 2006            6  310137  5934765 0      #>  7 118      2006-11-10 Spring 2006            1  310059  5935151 e      #>  8 119      2006-11-10 Spring 2006            2  310272  5935064 0      #>  9 120      2006-11-10 Spring 2006            3  310195  5935288 n      #> 10 121      2006-11-10 Spring 2006            4  310218  5934982 ne     #> 11 122      2006-11-10 Spring 2006            5  310034  5934700 e      #> 12 123      2006-11-10 Spring 2006            6  309996  5934758 n      #> 13 235      2007-04-19 Autumn 2007            1  310163  5935181 e      #> 14 236      2007-04-19 Autumn 2007            2  310038  5935014 s      #> 15 237      2007-04-19 Autumn 2007            3  310122  5934637 0      #> 16 238      2007-04-19 Autumn 2007            4  310161  5934480 0      #> 17 239      2007-04-19 Autumn 2007            5  310266  5934597 se     #> 18 240      2007-04-19 Autumn 2007            6  310280  5935010 0      #> # ℹ 35 more variables: `Landscape position` <chr>, #> #   ExoticAnnualGrass_cover <dbl>, ExoticAnnualHerb_cover <dbl>, #> #   ExoticPerennialHerb_cover <dbl>, ExoticPerennialGrass_cover <dbl>, #> #   ExoticShrub_cover <dbl>, NativePerennialFern_cover <dbl>, #> #   NativePerennialGrass_cover <dbl>, NativePerennialHerb_cover <dbl>, #> #   NativePerennialGraminoid_cover <dbl>, NativeShrub_cover <dbl>, #> #   BareGround_cover <dbl>, Litter_cover <dbl>, MossLichen_cover <dbl>, … #>  #> $Blaber #> # A tibble: 15 × 42 #>    SurveyID Date       Season      `Quadrat no` Easting Northing Aspect #>    <fct>    <date>     <chr>              <dbl>   <dbl>    <dbl> <chr>  #>  1 7        2006-07-25 Winter 2006            1  386643  5936462 e      #>  2 8        2006-07-25 Winter 2006            2  386736  5936384 e      #>  3 9        2006-07-25 Winter 2006            3  386732  5936315 e      #>  4 10       2006-07-25 Winter 2006            4  386633  5936324 e      #>  5 11       2006-07-25 Winter 2006            5  386896  5936282 e      #>  6 124      2006-11-14 Spring 2006            1  387003  5936393 e      #>  7 125      2006-11-14 Spring 2006            2  386476  5936219 e      #>  8 126      2006-11-14 Spring 2006            3  386827  5936476 e      #>  9 127      2006-11-14 Spring 2006            4  386616  5936267 e      #> 10 128      2006-11-14 Spring 2006            5  386709  5936234 e      #> 11 241      2007-04-17 Autumn 2007            1  386272  5936457 e      #> 12 242      2007-04-17 Autumn 2007            2  387031  5936429 e      #> 13 243      2007-04-17 Autumn 2007            3  386358  5936349 e      #> 14 244      2007-04-17 Autumn 2007            4  386353  5936444 e      #> 15 245      2007-04-17 Autumn 2007            5  386675  5936398 e      #> # ℹ 35 more variables: `Landscape position` <chr>, #> #   ExoticAnnualGrass_cover <dbl>, ExoticAnnualHerb_cover <dbl>, #> #   ExoticPerennialHerb_cover <dbl>, ExoticPerennialGrass_cover <dbl>, #> #   ExoticShrub_cover <dbl>, NativePerennialFern_cover <dbl>, #> #   NativePerennialGrass_cover <dbl>, NativePerennialHerb_cover <dbl>, #> #   NativePerennialGraminoid_cover <dbl>, NativeShrub_cover <dbl>, #> #   BareGround_cover <dbl>, Litter_cover <dbl>, MossLichen_cover <dbl>, … #>  #> $DClark #> # A tibble: 18 × 42 #>    SurveyID Date       Season      `Quadrat no` Easting Northing Aspect #>    <fct>    <date>     <chr>              <dbl>   <dbl>    <dbl> <chr>  #>  1 12       2006-07-19 Winter 2006            1  380890  5959540 se     #>  2 13       2006-07-19 Winter 2006            2  380734  5959474 s      #>  3 14       2006-07-19 Winter 2006            3  381469  5959397 e      #>  4 15       2006-07-19 Winter 2006            4  381024  5959384 s      #>  5 16       2006-07-19 Winter 2006            5  380890  5959591 se     #>  6 17       2006-07-19 Winter 2006            6  381203  5959676 e      #>  7 129      2006-11-14 Spring 2006            1  380818  5959432 nw     #>  8 130      2006-11-14 Spring 2006            2  381282  5959592 s      #>  9 131      2006-11-14 Spring 2006            3  381475  5959610 e      #> 10 132      2006-11-14 Spring 2006            4  381423  5959607 e      #> 11 133      2006-11-14 Spring 2006            5  381170  5959382 s      #> 12 134      2006-11-14 Spring 2006            6  381127  5959717 e      #> 13 246      2007-04-17 Autumn 2007            1  381391  5959468 s      #> 14 247      2007-04-17 Autumn 2007            2  380947  5959427 0      #> 15 248      2007-04-17 Autumn 2007            3  381324  5959557 0      #> 16 249      2007-04-17 Autumn 2007            4  380756  5959400 e      #> 17 250      2007-04-17 Autumn 2007            5  381203  5959726 s      #> 18 251      2007-04-17 Autumn 2007            6  381236  5959842 e      #> # ℹ 35 more variables: `Landscape position` <chr>, #> #   ExoticAnnualGrass_cover <dbl>, ExoticAnnualHerb_cover <dbl>, #> #   ExoticPerennialHerb_cover <dbl>, ExoticPerennialGrass_cover <dbl>, #> #   ExoticShrub_cover <dbl>, NativePerennialFern_cover <dbl>, #> #   NativePerennialGrass_cover <dbl>, NativePerennialHerb_cover <dbl>, #> #   NativePerennialGraminoid_cover <dbl>, NativeShrub_cover <dbl>, #> #   BareGround_cover <dbl>, Litter_cover <dbl>, MossLichen_cover <dbl>, … #>  #> $Gough #> # A tibble: 27 × 42 #>    SurveyID Date       Season      `Quadrat no` Easting Northing Aspect #>    <fct>    <date>     <chr>              <dbl>   <dbl>    <dbl> <chr>  #>  1 18       2006-07-26 Winter 2006            1  358873  5921525 0      #>  2 19       2006-07-26 Winter 2006            2  359203  5921862 0      #>  3 20       2006-07-26 Winter 2006            3  358793  5921874 se     #>  4 21       2006-07-26 Winter 2006            4  358452  5921673 n      #>  5 22       2006-07-26 Winter 2006            5  359497  5922192 s      #>  6 23       2006-07-26 Winter 2006            6  359480  5955191 n      #>  7 24       2006-07-26 Winter 2006            7  359428  5921795 s      #>  8 25       2006-07-26 Winter 2006            8  358742  5921709 s      #>  9 26       2006-07-26 Winter 2006            9  359198  5921949 s      #> 10 135      2006-11-04 Spring 2006            1  358522  5921752 s      #> # ℹ 17 more rows #> # ℹ 35 more variables: `Landscape position` <chr>, #> #   ExoticAnnualGrass_cover <dbl>, ExoticAnnualHerb_cover <dbl>, #> #   ExoticPerennialHerb_cover <dbl>, ExoticPerennialGrass_cover <dbl>, #> #   ExoticShrub_cover <dbl>, NativePerennialFern_cover <dbl>, #> #   NativePerennialGrass_cover <dbl>, NativePerennialHerb_cover <dbl>, #> #   NativePerennialGraminoid_cover <dbl>, NativeShrub_cover <dbl>, … #>  #> $Green #> # A tibble: 12 × 42 #>    SurveyID Date       Season      `Quadrat no` Easting Northing Aspect #>    <fct>    <date>     <chr>              <dbl>   <dbl>    <dbl> <chr>  #>  1 27       2006-07-27 Winter 2006            1  360032  5871750 n      #>  2 28       2006-07-27 Winter 2006            2  359983  5871719 n      #>  3 29       2006-07-27 Winter 2006            3  360061  5871604 e      #>  4 30       2006-07-27 Winter 2006            4  359779  5871566 e      #>  5 144      2006-12-07 Spring 2006            1  359810  5871505 w      #>  6 145      2006-12-07 Spring 2006            2  359692  5871634 n      #>  7 146      2006-12-07 Spring 2006            3  359865  5871733 s      #>  8 147      2006-12-07 Spring 2006            4  359972  5871655 w      #>  9 261      2007-05-09 Autumn 2007            1  359972  5871635 n      #> 10 262      2007-05-09 Autumn 2007            2  359924  5871773 n      #> 11 263      2007-05-09 Autumn 2007            3  359869  5871765 n      #> 12 264      2007-05-09 Autumn 2007            4  359715  5871694 e      #> # ℹ 35 more variables: `Landscape position` <chr>, #> #   ExoticAnnualGrass_cover <dbl>, ExoticAnnualHerb_cover <dbl>, #> #   ExoticPerennialHerb_cover <dbl>, ExoticPerennialGrass_cover <dbl>, #> #   ExoticShrub_cover <dbl>, NativePerennialFern_cover <dbl>, #> #   NativePerennialGrass_cover <dbl>, NativePerennialHerb_cover <dbl>, #> #   NativePerennialGraminoid_cover <dbl>, NativeShrub_cover <dbl>, #> #   BareGround_cover <dbl>, Litter_cover <dbl>, MossLichen_cover <dbl>, … #>  #> $Hawkey #> # A tibble: 12 × 42 #>    SurveyID Date       Season      `Quadrat no` Easting Northing Aspect #>    <fct>    <date>     <chr>              <dbl>   <dbl>    <dbl> <chr>  #>  1 31       2006-07-25 Winter 2006            1  330170  6010619 0      #>  2 32       2006-07-25 Winter 2006            2  330187  6010583 0      #>  3 33       2006-07-25 Winter 2006            3  330110  6010544 0      #>  4 34       2006-07-25 Winter 2006            4  330200  6010497 0      #>  5 148      2006-11-10 Spring 2006            1  330118  6010800 0      #>  6 149      2006-11-10 Spring 2006            2  330540  6010844 0      #>  7 150      2006-11-10 Spring 2006            3  330210  6010800 0      #>  8 151      2006-11-10 Spring 2006            4  330125  6010555 0      #>  9 265      2007-04-18 Autumn 2007            1  330074  6010835 0      #> 10 266      2007-04-18 Autumn 2007            2  330228  6010621 0      #> 11 267      2007-04-18 Autumn 2007            3  330258  6010626 0      #> 12 268      2007-04-18 Autumn 2007            4  330133  6010679 0      #> # ℹ 35 more variables: `Landscape position` <chr>, #> #   ExoticAnnualGrass_cover <dbl>, ExoticAnnualHerb_cover <dbl>, #> #   ExoticPerennialHerb_cover <dbl>, ExoticPerennialGrass_cover <dbl>, #> #   ExoticShrub_cover <dbl>, NativePerennialFern_cover <dbl>, #> #   NativePerennialGrass_cover <dbl>, NativePerennialHerb_cover <dbl>, #> #   NativePerennialGraminoid_cover <dbl>, NativeShrub_cover <dbl>, #> #   BareGround_cover <dbl>, Litter_cover <dbl>, MossLichen_cover <dbl>, … #>  #> $JClark #> # A tibble: 21 × 42 #>    SurveyID Date       Season      `Quadrat no` Easting Northing Aspect #>    <fct>    <date>     <chr>              <dbl>   <dbl>    <dbl> <chr>  #>  1 35       2006-07-26 Winter 2006            1  367739  5821489 sw     #>  2 36       2006-07-26 Winter 2006            2  368058  5872589 w      #>  3 37       2006-07-26 Winter 2006            3  368143  5872626 s      #>  4 38       2006-07-26 Winter 2006            4  368131  5872189 s      #>  5 39       2006-07-26 Winter 2006            5  367696  5872366 nw     #>  6 40       2006-07-26 Winter 2006            6  368650  5872203 w      #>  7 41       2006-07-26 Winter 2006            7  368188  5872013 se     #>  8 152      2006-12-07 Spring 2006            1  367727  5872320 s      #>  9 153      2006-12-07 Spring 2006            2  367851  5872147 nw     #> 10 154      2006-12-07 Spring 2006            3  367744  5871824 w      #> # ℹ 11 more rows #> # ℹ 35 more variables: `Landscape position` <chr>, #> #   ExoticAnnualGrass_cover <dbl>, ExoticAnnualHerb_cover <dbl>, #> #   ExoticPerennialHerb_cover <dbl>, ExoticPerennialGrass_cover <dbl>, #> #   ExoticShrub_cover <dbl>, NativePerennialFern_cover <dbl>, #> #   NativePerennialGrass_cover <dbl>, NativePerennialHerb_cover <dbl>, #> #   NativePerennialGraminoid_cover <dbl>, NativeShrub_cover <dbl>, … #>  #> $Kellock #> # A tibble: 27 × 42 #>    SurveyID Date       Season      `Quadrat no` Easting Northing Aspect #>    <fct>    <date>     <chr>              <dbl>   <dbl>    <dbl> <chr>  #>  1 42       2006-07-26 Winter 2006            1  409176  5987415 n      #>  2 43       2006-07-25 Winter 2006            2  409242  5987228 s      #>  3 44       2006-07-25 Winter 2006            3  408941  5987483 e      #>  4 45       2006-07-26 Winter 2006            4  409111  5987866 s      #>  5 46       2006-07-25 Winter 2006            5  409489  5987803 0      #>  6 47       2006-07-25 Winter 2006            6  408888  5987382 se     #>  7 48       2006-07-25 Winter 2006            7  409174  5987798 s      #>  8 49       2006-07-25 Winter 2006            8  408864  5987984 w      #>  9 50       2006-07-25 Winter 2006            9  409135  5987761 ne     #> 10 159      2006-11-10 Spring 2006            1  408962  5987848 w      #> # ℹ 17 more rows #> # ℹ 35 more variables: `Landscape position` <chr>, #> #   ExoticAnnualGrass_cover <dbl>, ExoticAnnualHerb_cover <dbl>, #> #   ExoticPerennialHerb_cover <dbl>, ExoticPerennialGrass_cover <dbl>, #> #   ExoticShrub_cover <dbl>, NativePerennialFern_cover <dbl>, #> #   NativePerennialGrass_cover <dbl>, NativePerennialHerb_cover <dbl>, #> #   NativePerennialGraminoid_cover <dbl>, NativeShrub_cover <dbl>, … #>  #> $Martin #> # A tibble: 33 × 42 #>    SurveyID Date       Season      `Quadrat no` Easting Northing Aspect #>    <fct>    <date>     <chr>              <dbl>   <dbl>    <dbl> <chr>  #>  1 51       2006-07-20 Winter 2006            1  387782  5968745 e      #>  2 52       2006-07-20 Winter 2006            2  388746  5967248 0      #>  3 53       2006-07-20 Winter 2006            3  388765  5956890 ne     #>  4 54       2006-07-20 Winter 2006            4  388358  5956799 0      #>  5 55       2006-07-20 Winter 2006            5  388477  5956640 0      #>  6 56       2006-07-20 Winter 2006            6  388029  5956943 0      #>  7 57       2006-07-20 Winter 2006            7  388341  5956084 0      #>  8 58       2006-07-20 Winter 2006            8  388423  5956006 se     #>  9 59       2006-07-20 Winter 2006            9  388452  5971319 0      #> 10 60       2006-07-20 Winter 2006           10  388732  5960630 0      #> # ℹ 23 more rows #> # ℹ 35 more variables: `Landscape position` <chr>, #> #   ExoticAnnualGrass_cover <dbl>, ExoticAnnualHerb_cover <dbl>, #> #   ExoticPerennialHerb_cover <dbl>, ExoticPerennialGrass_cover <dbl>, #> #   ExoticShrub_cover <dbl>, NativePerennialFern_cover <dbl>, #> #   NativePerennialGrass_cover <dbl>, NativePerennialHerb_cover <dbl>, #> #   NativePerennialGraminoid_cover <dbl>, NativeShrub_cover <dbl>, … #>  #> $McCracken #> # A tibble: 24 × 42 #>    SurveyID Date       Season      `Quadrat no` Easting Northing Aspect #>    <fct>    <date>     <chr>              <dbl>   <dbl>    <dbl> <chr>  #>  1 62       2006-07-18 Winter 2006            1  358110  5957069 0      #>  2 63       2006-07-18 Winter 2006            2  358317  5957468 0      #>  3 64       2006-07-18 Winter 2006            3  357720  5957153 0      #>  4 65       2006-07-18 Winter 2006            4  358331  5957240 0      #>  5 66       2006-07-18 Winter 2006            5  358632  5957291 0      #>  6 67       2006-07-18 Winter 2006            6  358145  5957383 0      #>  7 68       2006-07-18 Winter 2006            7  358137  5957448 0      #>  8 69       2006-07-18 Winter 2006            8  358289  5956904 0      #>  9 179      2006-11-11 Spring 2006            1  358300  5956890 0      #> 10 180      2006-11-11 Spring 2006            2  358234  5957048 0      #> # ℹ 14 more rows #> # ℹ 35 more variables: `Landscape position` <chr>, #> #   ExoticAnnualGrass_cover <dbl>, ExoticAnnualHerb_cover <dbl>, #> #   ExoticPerennialHerb_cover <dbl>, ExoticPerennialGrass_cover <dbl>, #> #   ExoticShrub_cover <dbl>, NativePerennialFern_cover <dbl>, #> #   NativePerennialGrass_cover <dbl>, NativePerennialHerb_cover <dbl>, #> #   NativePerennialGraminoid_cover <dbl>, NativeShrub_cover <dbl>, … #>  #> $Olive #> # A tibble: 15 × 42 #>    SurveyID Date       Season      `Quadrat no` Easting Northing Aspect #>    <fct>    <date>     <chr>              <dbl>   <dbl>    <dbl> <chr>  #>  1 70       2006-07-27 Winter 2006            1  377590  5876368 0      #>  2 71       2006-07-27 Winter 2006            2  377744  5976421 e      #>  3 72       2006-07-27 Winter 2006            3  377219  5876496 s      #>  4 73       2006-07-27 Winter 2006            4  377015  5876440 e      #>  5 74       2006-07-27 Winter 2006            5  377790  5876366 e      #>  6 187      2006-12-06 Spring 2006            1  377201  5876434 s      #>  7 188      2006-12-06 Spring 2006            2  377301  5876368 s      #>  8 189      2006-12-06 Spring 2006            3  377707  5876436 s      #>  9 190      2006-12-06 Spring 2006            4  377587  5876420 n      #> 10 191      2006-12-06 Spring 2006            5  377862  5876384 0      #> 11 304      2007-05-08 Autumn 2007            1  377394  5876407 n      #> 12 305      2007-05-08 Autumn 2007            2  377181  5876421 n      #> 13 306      2007-05-08 Autumn 2007            3  377259  5876280 e      #> 14 307      2007-05-08 Autumn 2007            4  377951  5876374 e      #> 15 308      2007-05-08 Autumn 2007            5  377623  5876345 0      #> # ℹ 35 more variables: `Landscape position` <chr>, #> #   ExoticAnnualGrass_cover <dbl>, ExoticAnnualHerb_cover <dbl>, #> #   ExoticPerennialHerb_cover <dbl>, ExoticPerennialGrass_cover <dbl>, #> #   ExoticShrub_cover <dbl>, NativePerennialFern_cover <dbl>, #> #   NativePerennialGrass_cover <dbl>, NativePerennialHerb_cover <dbl>, #> #   NativePerennialGraminoid_cover <dbl>, NativeShrub_cover <dbl>, #> #   BareGround_cover <dbl>, Litter_cover <dbl>, MossLichen_cover <dbl>, … #>  #> $Rokahr #> # A tibble: 21 × 42 #>    SurveyID Date       Season      `Quadrat no` Easting Northing Aspect #>    <fct>    <date>     <chr>              <dbl>   <dbl>    <dbl> <chr>  #>  1 75       2006-07-25 Winter 2006            1  387771  5985347 0      #>  2 76       2006-07-25 Winter 2006            2  388366  5985356 0      #>  3 77       2006-07-25 Winter 2006            3  387809  5985141 0      #>  4 78       2006-07-25 Winter 2006            4  387671  5984967 0      #>  5 79       2006-07-25 Winter 2006            5  387695  5985380 0      #>  6 80       2006-07-25 Winter 2006            6  387753  5985068 0      #>  7 81       2006-07-25 Winter 2006            7  388043  5985088 0      #>  8 192      2006-11-10 Spring 2006            1  387721  5985370 0      #>  9 193      2006-11-10 Spring 2006            2  388091  5985252 0      #> 10 194      2006-11-10 Spring 2006            3  387748  5985167 0      #> # ℹ 11 more rows #> # ℹ 35 more variables: `Landscape position` <chr>, #> #   ExoticAnnualGrass_cover <dbl>, ExoticAnnualHerb_cover <dbl>, #> #   ExoticPerennialHerb_cover <dbl>, ExoticPerennialGrass_cover <dbl>, #> #   ExoticShrub_cover <dbl>, NativePerennialFern_cover <dbl>, #> #   NativePerennialGrass_cover <dbl>, NativePerennialHerb_cover <dbl>, #> #   NativePerennialGraminoid_cover <dbl>, NativeShrub_cover <dbl>, … #>  #> $Sharrock #> # A tibble: 12 × 42 #>    SurveyID Date       Season      `Quadrat no` Easting Northing Aspect #>    <fct>    <date>     <chr>              <dbl>   <dbl>    <dbl> <chr>  #>  1 82       2006-07-19 Winter 2006            1  383318  5955469 nw     #>  2 83       2006-07-19 Winter 2006            2  383400  5955169 w      #>  3 84       2006-07-19 Winter 2006            3  383228  5955360 s      #>  4 85       2006-07-19 Winter 2006            4  383368  5955220 w      #>  5 199      2006-11-14 Spring 2006            1  383259  5955400 w      #>  6 200      2006-11-14 Spring 2006            2  383454  5955569 w      #>  7 201      2006-11-14 Spring 2006            3  383340  5955291 nw     #>  8 202      2006-11-14 Spring 2006            4  383247  5955254 nw     #>  9 316      2007-04-17 Autumn 2007            1  383431  5955513 w      #> 10 317      2007-04-17 Autumn 2007            2  383359  5955547 0      #> 11 318      2007-04-17 Autumn 2007            3  383463  5955256 0      #> 12 319      2007-04-17 Autumn 2007            4  383492  5955228 s      #> # ℹ 35 more variables: `Landscape position` <chr>, #> #   ExoticAnnualGrass_cover <dbl>, ExoticAnnualHerb_cover <dbl>, #> #   ExoticPerennialHerb_cover <dbl>, ExoticPerennialGrass_cover <dbl>, #> #   ExoticShrub_cover <dbl>, NativePerennialFern_cover <dbl>, #> #   NativePerennialGrass_cover <dbl>, NativePerennialHerb_cover <dbl>, #> #   NativePerennialGraminoid_cover <dbl>, NativeShrub_cover <dbl>, #> #   BareGround_cover <dbl>, Litter_cover <dbl>, MossLichen_cover <dbl>, … #>  #> $Staff #> # A tibble: 27 × 42 #>    SurveyID Date       Season      `Quadrat no` Easting Northing Aspect #>    <fct>    <date>     <chr>              <dbl>   <dbl>    <dbl> <chr>  #>  1 86       2006-07-27 Winter 2006            1  385708  5939744 nw     #>  2 87       2006-07-27 Winter 2006            2  386193  5939749 s      #>  3 88       2006-07-27 Winter 2006            3  385599  5939313 0      #>  4 89       2006-07-27 Winter 2006            4  385701  5939171 sw     #>  5 90       2006-07-27 Winter 2006            5  386179  5939590 n      #>  6 91       2006-07-27 Winter 2006            6  386037  5939836 n      #>  7 92       2006-07-27 Winter 2006            7  385604  5939140 e      #>  8 93       2006-07-27 Winter 2006            8  385700  5939655 s      #>  9 94       2006-07-27 Winter 2006            9  385991  5939583 n      #> 10 203      2006-11-15 Spring 2006            1  386235  5939864 nw     #> # ℹ 17 more rows #> # ℹ 35 more variables: `Landscape position` <chr>, #> #   ExoticAnnualGrass_cover <dbl>, ExoticAnnualHerb_cover <dbl>, #> #   ExoticPerennialHerb_cover <dbl>, ExoticPerennialGrass_cover <dbl>, #> #   ExoticShrub_cover <dbl>, NativePerennialFern_cover <dbl>, #> #   NativePerennialGrass_cover <dbl>, NativePerennialHerb_cover <dbl>, #> #   NativePerennialGraminoid_cover <dbl>, NativeShrub_cover <dbl>, … #>  #> $Stoney #> # A tibble: 21 × 42 #>    SurveyID Date       Season      `Quadrat no` Easting Northing Aspect #>    <fct>    <date>     <chr>              <dbl>   <dbl>    <dbl> <chr>  #>  1 95       2006-07-27 Winter 2006            1  410529  5895093 e      #>  2 96       2006-07-27 Winter 2006            2  410683  5895072 e      #>  3 97       2006-07-27 Winter 2006            3  410440  5895054 ne     #>  4 98       2006-07-27 Winter 2006            4  410545  5895038 e      #>  5 99       2006-07-27 Winter 2006            5  410374  5895094 se     #>  6 100      2006-07-27 Winter 2006            6  410210  5895023 e      #>  7 101      2006-07-27 Winter 2006            7  410284  5895820 ne     #>  8 212      2006-12-08 Spring 2006            1  410616  5899138 e      #>  9 213      2006-12-08 Spring 2006            2  410623  5899408 e      #> 10 214      2006-12-08 Spring 2006            3  410572  5898758 e      #> # ℹ 11 more rows #> # ℹ 35 more variables: `Landscape position` <chr>, #> #   ExoticAnnualGrass_cover <dbl>, ExoticAnnualHerb_cover <dbl>, #> #   ExoticPerennialHerb_cover <dbl>, ExoticPerennialGrass_cover <dbl>, #> #   ExoticShrub_cover <dbl>, NativePerennialFern_cover <dbl>, #> #   NativePerennialGrass_cover <dbl>, NativePerennialHerb_cover <dbl>, #> #   NativePerennialGraminoid_cover <dbl>, NativeShrub_cover <dbl>, … #>  #> $Taylor #> # A tibble: 15 × 42 #>    SurveyID Date       Season      `Quadrat no` Easting Northing Aspect #>    <fct>    <date>     <chr>              <dbl>   <dbl>    <dbl> <chr>  #>  1 102      2006-07-24 Winter 2006            1  389720  5954557 0      #>  2 103      2006-07-24 Winter 2006            2  378805  5954456 0      #>  3 104      2006-07-24 Winter 2006            3  389669  5954833 0      #>  4 105      2006-07-24 Winter 2006            4  389746  5954624 0      #>  5 106      2006-07-24 Winter 2006            5  389635  5954910 0      #>  6 219      2006-10-14 Spring 2006            1  389718  5954830 0      #>  7 220      2006-10-14 Spring 2006            2  389698  5954770 0      #>  8 221      2006-10-14 Spring 2006            3  389775  5954594 0      #>  9 222      2006-10-14 Spring 2006            4  389817  5954875 0      #> 10 223      2006-10-14 Spring 2006            5  389750  5954882 0      #> 11 336      2007-04-16 Autumn 2007            4  389851  5954634 0      #> 12 337      2007-04-16 Autumn 2007            1  389643  5954703 0      #> 13 338      2007-04-16 Autumn 2007            2  389653  5954793 0      #> 14 339      2007-04-16 Autumn 2007            3  389607  5954928 0      #> 15 340      2007-04-16 Autumn 2007            5  389854  5954441 0      #> # ℹ 35 more variables: `Landscape position` <chr>, #> #   ExoticAnnualGrass_cover <dbl>, ExoticAnnualHerb_cover <dbl>, #> #   ExoticPerennialHerb_cover <dbl>, ExoticPerennialGrass_cover <dbl>, #> #   ExoticShrub_cover <dbl>, NativePerennialFern_cover <dbl>, #> #   NativePerennialGrass_cover <dbl>, NativePerennialHerb_cover <dbl>, #> #   NativePerennialGraminoid_cover <dbl>, NativeShrub_cover <dbl>, #> #   BareGround_cover <dbl>, Litter_cover <dbl>, MossLichen_cover <dbl>, … #>  #> $Wakefield #> # A tibble: 12 × 42 #>    SurveyID Date       Season      `Quadrat no` Easting Northing Aspect #>    <fct>    <date>     <chr>              <dbl>   <dbl>    <dbl> <chr>  #>  1 107      2006-07-27 Winter 2006            1  348307  5874042 nw     #>  2 108      2006-07-27 Winter 2006            2  348206  5874084 s      #>  3 109      2006-07-27 Winter 2006            3  348532  5874001 nw     #>  4 110      2006-07-27 Winter 2006            4  348165  5874028 s      #>  5 224      2006-12-07 Spring 2006            1  348305  5873844 s      #>  6 225      2006-12-07 Spring 2006            2  348562  5874018 n      #>  7 226      2006-12-07 Spring 2006            3  348253  5879750 s      #>  8 227      2006-12-07 Spring 2006            4  348391  5873773 s      #>  9 341      2007-05-09 Autumn 2007            1  348451  5873910 se     #> 10 342      2007-05-09 Autumn 2007            2  348442  5873883 s      #> 11 343      2007-05-09 Autumn 2007            3  348251  5873900 0      #> 12 344      2007-05-09 Autumn 2007            4  348188  5873921 s      #> # ℹ 35 more variables: `Landscape position` <chr>, #> #   ExoticAnnualGrass_cover <dbl>, ExoticAnnualHerb_cover <dbl>, #> #   ExoticPerennialHerb_cover <dbl>, ExoticPerennialGrass_cover <dbl>, #> #   ExoticShrub_cover <dbl>, NativePerennialFern_cover <dbl>, #> #   NativePerennialGrass_cover <dbl>, NativePerennialHerb_cover <dbl>, #> #   NativePerennialGraminoid_cover <dbl>, NativeShrub_cover <dbl>, #> #   BareGround_cover <dbl>, Litter_cover <dbl>, MossLichen_cover <dbl>, … #>  #> $Yorston #> # A tibble: 21 × 42 #>    SurveyID Date       Season      `Quadrat no` Easting Northing Aspect #>    <fct>    <date>     <chr>              <dbl>   <dbl>    <dbl> <chr>  #>  1 111      2006-07-26 Winter 2006            1  359010  5894495 nw     #>  2 112      2006-07-26 Winter 2006            2  359018  5894606 nw     #>  3 113      2006-07-26 Winter 2006            3  358205  5895793 s      #>  4 114      2006-07-26 Winter 2006            4  358932  5894600 nw     #>  5 115      2006-07-26 Winter 2006            5  358861  5894634 w      #>  6 116      2006-07-26 Winter 2006            6  358074  5895284 s      #>  7 117      2006-07-26 Winter 2006            7  357961  5895704 ne     #>  8 228      2006-11-17 Spring 2006            1  358010  5895886 w      #>  9 229      2006-11-17 Spring 2006            2  358179  5895876 w      #> 10 230      2006-11-17 Spring 2006            3  358917  5894850 w      #> # ℹ 11 more rows #> # ℹ 35 more variables: `Landscape position` <chr>, #> #   ExoticAnnualGrass_cover <dbl>, ExoticAnnualHerb_cover <dbl>, #> #   ExoticPerennialHerb_cover <dbl>, ExoticPerennialGrass_cover <dbl>, #> #   ExoticShrub_cover <dbl>, NativePerennialFern_cover <dbl>, #> #   NativePerennialGrass_cover <dbl>, NativePerennialHerb_cover <dbl>, #> #   NativePerennialGraminoid_cover <dbl>, NativeShrub_cover <dbl>, … #>  named_group_split(blue_tit_data, hatch_Area) #> $B #> # A tibble: 726 × 41 #>    chick_ring_number hatch_year hatch_nest_breed_ID hatch_Box hatch_mom_Ring #>    <chr>                  <dbl>               <dbl> <chr>     <chr>          #>  1 P804103                 2001              201123 B100      .              #>  2 P804104                 2001              201123 B100      .              #>  3 P804106                 2001              201123 B100      .              #>  4 P804107                 2001              201123 B100      .              #>  5 P804108                 2001              201123 B100      .              #>  6 P804110                 2001              201123 B100      .              #>  7 P804112                 2001              201123 B100      .              #>  8 P804115                 2001              201123 B100      .              #>  9 P804117                 2001              201123 B100      .              #> 10 P804118                 2001              201123 B100      .              #> # ℹ 716 more rows #> # ℹ 36 more variables: hatch_nest_dad_Ring <chr>, `Extra-pair_paternity` <chr>, #> #   `Extra-pair_dad_ring` <chr>, `genetic_dad_ring_(WP_or_EP)` <chr>, #> #   hatch_nest_LD <chr>, hatch_nest_CS <chr>, hatch_nest_OH <dbl>, #> #   d0_hatch_nest_brood_size <chr>, d14_hatch_nest_brood_size <chr>, #> #   rear_nest_breed_ID <dbl>, rear_area <chr>, rear_Box <chr>, #> #   rear_mom_Ring <chr>, rear_dad_Ring <chr>, rear_nest_trt <dbl>, … #>  #> $C #> # A tibble: 577 × 41 #>    chick_ring_number hatch_year hatch_nest_breed_ID hatch_Box hatch_mom_Ring #>    <chr>                  <dbl>               <dbl> <chr>     <chr>          #>  1 P804016                 2001              201194 C130      P803008        #>  2 P804017                 2001              201194 C130      P803008        #>  3 P804018                 2001              201167 C26       P803005        #>  4 P804019                 2001              201194 C130      P803008        #>  5 P804020                 2001              201167 C26       P803005        #>  6 P804021                 2001              201194 C130      P803008        #>  7 P804022                 2001              201194 C130      P803008        #>  8 P804023                 2001              201194 C130      P803008        #>  9 P804024                 2001              201167 C26       P803005        #> 10 P804025                 2001              201194 C130      P803008        #> # ℹ 567 more rows #> # ℹ 36 more variables: hatch_nest_dad_Ring <chr>, `Extra-pair_paternity` <chr>, #> #   `Extra-pair_dad_ring` <chr>, `genetic_dad_ring_(WP_or_EP)` <chr>, #> #   hatch_nest_LD <chr>, hatch_nest_CS <chr>, hatch_nest_OH <dbl>, #> #   d0_hatch_nest_brood_size <chr>, d14_hatch_nest_brood_size <chr>, #> #   rear_nest_breed_ID <dbl>, rear_area <chr>, rear_Box <chr>, #> #   rear_mom_Ring <chr>, rear_dad_Ring <chr>, rear_nest_trt <dbl>, … #>  #> $CP #> # A tibble: 229 × 41 #>    chick_ring_number hatch_year hatch_nest_breed_ID hatch_Box hatch_mom_Ring #>    <chr>                  <dbl>               <dbl> <chr>     <chr>          #>  1 P804196                 2001              201225 CP40A     P803102        #>  2 P804197                 2001              201225 CP40A     P803102        #>  3 P804198                 2001              201225 CP40A     P803102        #>  4 P804199                 2001              201225 CP40A     P803102        #>  5 P804456                 2001              201225 CP40A     P803102        #>  6 P804457                 2001              201225 CP40A     P803102        #>  7 P804458                 2001              201225 CP40A     P803102        #>  8 P804459                 2001              201225 CP40A     P803102        #>  9 P804463                 2001              201225 CP40A     P803102        #> 10 P804464                 2001              201225 CP40A     P803102        #> # ℹ 219 more rows #> # ℹ 36 more variables: hatch_nest_dad_Ring <chr>, `Extra-pair_paternity` <chr>, #> #   `Extra-pair_dad_ring` <chr>, `genetic_dad_ring_(WP_or_EP)` <chr>, #> #   hatch_nest_LD <chr>, hatch_nest_CS <chr>, hatch_nest_OH <dbl>, #> #   d0_hatch_nest_brood_size <chr>, d14_hatch_nest_brood_size <chr>, #> #   rear_nest_breed_ID <dbl>, rear_area <chr>, rear_Box <chr>, #> #   rear_mom_Ring <chr>, rear_dad_Ring <chr>, rear_nest_trt <dbl>, … #>  #> $E #> # A tibble: 333 × 41 #>    chick_ring_number hatch_year hatch_nest_breed_ID hatch_Box hatch_mom_Ring #>    <chr>                  <dbl>               <dbl> <chr>     <chr>          #>  1 P804180                 2001              201260 E51B      P803087        #>  2 P804186                 2001              201260 E51B      P803087        #>  3 P804189                 2001              201260 E51B      P803087        #>  4 P804190                 2001              201260 E51B      P803087        #>  5 P804192                 2001              201260 E51B      P803087        #>  6 P804548                 2001              201227 E3        K578406        #>  7 P804549                 2001              201227 E3        K578406        #>  8 P804550                 2001              201227 E3        K578406        #>  9 P804552                 2001              201227 E3        K578406        #> 10 P804553                 2001              201227 E3        K578406        #> # ℹ 323 more rows #> # ℹ 36 more variables: hatch_nest_dad_Ring <chr>, `Extra-pair_paternity` <chr>, #> #   `Extra-pair_dad_ring` <chr>, `genetic_dad_ring_(WP_or_EP)` <chr>, #> #   hatch_nest_LD <chr>, hatch_nest_CS <chr>, hatch_nest_OH <dbl>, #> #   d0_hatch_nest_brood_size <chr>, d14_hatch_nest_brood_size <chr>, #> #   rear_nest_breed_ID <dbl>, rear_area <chr>, rear_Box <chr>, #> #   rear_mom_Ring <chr>, rear_dad_Ring <chr>, rear_nest_trt <dbl>, … #>  #> $MP #> # A tibble: 375 × 41 #>    chick_ring_number hatch_year hatch_nest_breed_ID hatch_Box hatch_mom_Ring #>    <chr>                  <dbl>               <dbl> <chr>     <chr>          #>  1 P804101                 2001              201288 MP55      P803016        #>  2 P804102                 2001              201288 MP55      P803016        #>  3 P804105                 2001              201288 MP55      P803016        #>  4 P804109                 2001              201288 MP55      P803016        #>  5 P804111                 2001              201288 MP55      P803016        #>  6 P804113                 2001              201288 MP55      P803016        #>  7 P804114                 2001              201288 MP55      P803016        #>  8 P804116                 2001              201288 MP55      P803016        #>  9 P804119                 2001              201288 MP55      P803016        #> 10 P804121                 2001              201288 MP55      P803016        #> # ℹ 365 more rows #> # ℹ 36 more variables: hatch_nest_dad_Ring <chr>, `Extra-pair_paternity` <chr>, #> #   `Extra-pair_dad_ring` <chr>, `genetic_dad_ring_(WP_or_EP)` <chr>, #> #   hatch_nest_LD <chr>, hatch_nest_CS <chr>, hatch_nest_OH <dbl>, #> #   d0_hatch_nest_brood_size <chr>, d14_hatch_nest_brood_size <chr>, #> #   rear_nest_breed_ID <dbl>, rear_area <chr>, rear_Box <chr>, #> #   rear_mom_Ring <chr>, rear_dad_Ring <chr>, rear_nest_trt <dbl>, … #>  #> $O #> # A tibble: 600 × 41 #>    chick_ring_number hatch_year hatch_nest_breed_ID hatch_Box hatch_mom_Ring #>    <chr>                  <dbl>               <dbl> <chr>     <chr>          #>  1 P804142                 2001              201319 O27       P803035        #>  2 P804143                 2001              201319 O27       P803035        #>  3 P804144                 2001              201319 O27       P803035        #>  4 P804145                 2001              201319 O27       P803035        #>  5 P804146                 2001              201319 O27       P803035        #>  6 P804181                 2001              201325 O38B      .              #>  7 P804183                 2001              201325 O38B      .              #>  8 P804184                 2001              201325 O38B      .              #>  9 P804185                 2001              201325 O38B      .              #> 10 P804187                 2001              201325 O38B      .              #> # ℹ 590 more rows #> # ℹ 36 more variables: hatch_nest_dad_Ring <chr>, `Extra-pair_paternity` <chr>, #> #   `Extra-pair_dad_ring` <chr>, `genetic_dad_ring_(WP_or_EP)` <chr>, #> #   hatch_nest_LD <chr>, hatch_nest_CS <chr>, hatch_nest_OH <dbl>, #> #   d0_hatch_nest_brood_size <chr>, d14_hatch_nest_brood_size <chr>, #> #   rear_nest_breed_ID <dbl>, rear_area <chr>, rear_Box <chr>, #> #   rear_mom_Ring <chr>, rear_dad_Ring <chr>, rear_nest_trt <dbl>, … #>  #> $P #> # A tibble: 91 × 41 #>    chick_ring_number hatch_year hatch_nest_breed_ID hatch_Box hatch_mom_Ring #>    <chr>                  <dbl>               <dbl> <chr>     <chr>          #>  1 P805234                 2001              201364 P24       P803249        #>  2 P805235                 2001              201364 P24       P803249        #>  3 P805236                 2001              201364 P24       P803249        #>  4 P805240                 2001              201364 P24       P803249        #>  5 P805241                 2001              201364 P24       P803249        #>  6 P805242                 2001              201364 P24       P803249        #>  7 P805875                 2001              201360 P10       P803358        #>  8 P805876                 2001              201360 P10       P803358        #>  9 P805878                 2001              201360 P10       P803358        #> 10 P805910                 2001              201357 P3        P803362        #> # ℹ 81 more rows #> # ℹ 36 more variables: hatch_nest_dad_Ring <chr>, `Extra-pair_paternity` <chr>, #> #   `Extra-pair_dad_ring` <chr>, `genetic_dad_ring_(WP_or_EP)` <chr>, #> #   hatch_nest_LD <chr>, hatch_nest_CS <chr>, hatch_nest_OH <dbl>, #> #   d0_hatch_nest_brood_size <chr>, d14_hatch_nest_brood_size <chr>, #> #   rear_nest_breed_ID <dbl>, rear_area <chr>, rear_Box <chr>, #> #   rear_mom_Ring <chr>, rear_dad_Ring <chr>, rear_nest_trt <dbl>, … #>  #> $SW #> # A tibble: 405 × 41 #>    chick_ring_number hatch_year hatch_nest_breed_ID hatch_Box hatch_mom_Ring #>    <chr>                  <dbl>               <dbl> <chr>     <chr>          #>  1 P804149                 2001              201393 SW113     P803040        #>  2 P804151                 2001              201393 SW113     P803040        #>  3 P804152                 2001              201393 SW113     P803040        #>  4 P804257                 2001              201397 SW128     P803048        #>  5 P804258                 2001              201397 SW128     P803048        #>  6 P804259                 2001              201397 SW128     P803048        #>  7 P804260                 2001              201397 SW128     P803048        #>  8 P804261                 2001              201397 SW128     P803048        #>  9 P804262                 2001              201397 SW128     P803048        #> 10 P804263                 2001              201397 SW128     P803048        #> # ℹ 395 more rows #> # ℹ 36 more variables: hatch_nest_dad_Ring <chr>, `Extra-pair_paternity` <chr>, #> #   `Extra-pair_dad_ring` <chr>, `genetic_dad_ring_(WP_or_EP)` <chr>, #> #   hatch_nest_LD <chr>, hatch_nest_CS <chr>, hatch_nest_OH <dbl>, #> #   d0_hatch_nest_brood_size <chr>, d14_hatch_nest_brood_size <chr>, #> #   rear_nest_breed_ID <dbl>, rear_area <chr>, rear_Box <chr>, #> #   rear_mom_Ring <chr>, rear_dad_Ring <chr>, rear_nest_trt <dbl>, … #>  #> $W #> # A tibble: 384 × 41 #>    chick_ring_number hatch_year hatch_nest_breed_ID hatch_Box hatch_mom_Ring #>    <chr>                  <dbl>               <dbl> <chr>     <chr>          #>  1 P804042                 2001              201419 W47       .              #>  2 P804043                 2001              201417 W43       P803018        #>  3 P804044                 2001              201417 W43       P803018        #>  4 P804045                 2001              201417 W43       P803018        #>  5 P804046                 2001              201419 W47       .              #>  6 P804047                 2001              201419 W47       .              #>  7 P804048                 2001              201419 W47       .              #>  8 P804178                 2001              201414 W37       P803056        #>  9 P804179                 2001              201414 W37       P803056        #> 10 P804193                 2001              201428 W60       P803080        #> # ℹ 374 more rows #> # ℹ 36 more variables: hatch_nest_dad_Ring <chr>, `Extra-pair_paternity` <chr>, #> #   `Extra-pair_dad_ring` <chr>, `genetic_dad_ring_(WP_or_EP)` <chr>, #> #   hatch_nest_LD <chr>, hatch_nest_CS <chr>, hatch_nest_OH <dbl>, #> #   d0_hatch_nest_brood_size <chr>, d14_hatch_nest_brood_size <chr>, #> #   rear_nest_breed_ID <dbl>, rear_area <chr>, rear_Box <chr>, #> #   rear_mom_Ring <chr>, rear_dad_Ring <chr>, rear_nest_trt <dbl>, … #>"},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/pipe.html","id":null,"dir":"Reference","previous_headings":"","what":"Pipe operator — %>%","title":"Pipe operator — %>%","text":"See magrittr::%>% details.","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/pipe.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Pipe operator — %>%","text":"","code":"lhs %>% rhs"},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/pipe.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Pipe operator — %>%","text":"lhs value magrittr placeholder. rhs function call using magrittr semantics.","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/pipe.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Pipe operator — %>%","text":"result calling rhs(lhs).","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/plot_cont_rating_effects.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot Marginal Effects for Numeric Rating Model — plot_cont_rating_effects","title":"Plot Marginal Effects for Numeric Rating Model — plot_cont_rating_effects","text":"Plot Marginal Effects Numeric Rating Model","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/plot_cont_rating_effects.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot Marginal Effects for Numeric Rating Model — plot_cont_rating_effects","text":"","code":"plot_cont_rating_effects(   df = data.frame(),   response = character(),   predictor = character(),   group = NULL,   plot = TRUE,   back_transform = FALSE )"},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/plot_cont_rating_effects.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot Marginal Effects for Numeric Rating Model — plot_cont_rating_effects","text":"df Dataframe column 'abs_deviation_score_estimate', 'lambda' predictor, response columns response character vector naming response variable column df predictor character vector naming predictor variable column df group optional character vector naming random effect / grouping variable column df plot logical indicating whether plot rendered interactively , defaults TRUE back_transform logical indicating whether response variable back-transformed box-cox transformed scale absolute deviation scores","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/plot_cont_rating_effects.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot Marginal Effects for Numeric Rating Model — plot_cont_rating_effects","text":"list, first element containing fitted statistical model second element containing plot","code":""},{"path":[]},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/plot_cont_rating_effects.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot Marginal Effects for Numeric Rating Model — plot_cont_rating_effects","text":"","code":"# ManyEcoEvo_results$effects_analysis[[1]] %>% #TODO use package data object instead of targets object # unnest(review_data) %>% #   plot_cont_rating_effects(response = \"box_cox_abs_deviation_score_estimate\", #                            predictor = \"RateAnalysis\", #                            group = \"ReviewerId\", #                            back_transform = TRUE) %>% #   pluck(2) + #   ggforce::facet_zoom(xlim = c(0,100), ylim = c(0,0.55)) + #   ggpubr::theme_pubclean() + #   ggplot2::xlab(\"Rating\") + #   ggplot2::ylab(\"Deviation In Effect Size from Analytic Mean\")"},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/plot_effects_diversity.html","id":null,"dir":"Reference","previous_headings":"","what":"Marginal Effects Plot of Diversity Index Model — plot_effects_diversity","title":"Marginal Effects Plot of Diversity Index Model — plot_effects_diversity","text":"Marginal Effects Plot Diversity Index Model","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/plot_effects_diversity.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Marginal Effects Plot of Diversity Index Model — plot_effects_diversity","text":"","code":"plot_effects_diversity(mod, df, back_transform = FALSE)"},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/plot_effects_diversity.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Marginal Effects Plot of Diversity Index Model — plot_effects_diversity","text":"mod fitted model class 'lm' df dataframe columns, lambda, abs_deviation_score_estimate, box_cox_abs_deviation_score_estimate, mean_diversity_index back_transform logical, back-transform box-cox transformed absolute deviation scores ","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/plot_effects_diversity.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Marginal Effects Plot of Diversity Index Model — plot_effects_diversity","text":"ggplot original data,  predicted values confidence values fitted model","code":""},{"path":[]},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/plot_effects_diversity.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Marginal Effects Plot of Diversity Index Model — plot_effects_diversity","text":"","code":"# targets::tar_load(ManyEcoEvo_results) #TODO change this to package data # library(tidyverse) # plot_effects_diversity(mod = ManyEcoEvo_results$sorensen_glm[[5]], # df = ManyEcoEvo_results$effects_analysis[[5]] %>% #dat # select(mean_diversity_index, study_id, #          starts_with(\"box_cox\"), #                   starts_with(\"abs_dev\"), #                            lambda), #                            back_transform = TRUE)"},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/plot_forest.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot a Forest Plot — plot_forest","title":"Plot a Forest Plot — plot_forest","text":"Plot forest plot using data get_forest_plot_data","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/plot_forest.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot a Forest Plot — plot_forest","text":"","code":"plot_forest(data, intercept = TRUE, MA_mean = TRUE)"},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/plot_forest.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot a Forest Plot — plot_forest","text":"data tibble containing data required plot forest plot intercept Logical. horizontal line added 0? MA_mean Logical. dashed line added meta-analytic mean?","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/plot_forest.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot a Forest Plot — plot_forest","text":"ggplot object","code":""},{"path":[]},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/plot_forest.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot a Forest Plot — plot_forest","text":"","code":"data(ManyEcoEvo_results) model <- ManyEcoEvo_results %>% pluck(\"MA_mod\", 1)  plot_data <- get_forest_plot_data(model) plot_forest(plot_data)  plot_forest(plot_data, intercept = FALSE)  plot_forest(plot_data, MA_mean = FALSE)  plot_forest(plot_data, intercept = FALSE, MA_mean = FALSE)"},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/plot_model_means_box_cox_cat.html","id":null,"dir":"Reference","previous_headings":"","what":"plot_model_means_box_cox_cat — plot_model_means_box_cox_cat","title":"plot_model_means_box_cox_cat — plot_model_means_box_cox_cat","text":"Plot model means box-cox transformed deviation scores function categorical ratings","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/plot_model_means_box_cox_cat.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"plot_model_means_box_cox_cat — plot_model_means_box_cox_cat","text":"","code":"plot_model_means_box_cox_cat(   dat,   variable,   predictor_means,   new_order,   title,   lambda,   back_transform = FALSE )"},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/plot_model_means_box_cox_cat.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"plot_model_means_box_cox_cat — plot_model_means_box_cox_cat","text":"dat Data plotting variable Categorical predictor variable plot predictor_means tibble containing means confidence intervals predictor variable new_order character vector new order levels categorical predictor title character vector plot title lambda length 1 numeric vector lambda value used box-cox transformation back_transform logical indicating whether back-transform box-cox transformed data","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/plot_model_means_box_cox_cat.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"plot_model_means_box_cox_cat — plot_model_means_box_cox_cat","text":"ggplot object","code":""},{"path":[]},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/plot_model_means_orchard.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot orchard-plot style model means — plot_model_means_orchard","title":"Plot orchard-plot style model means — plot_model_means_orchard","text":"Plot means model predictor variable","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/plot_model_means_orchard.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot orchard-plot style model means — plot_model_means_orchard","text":"","code":"plot_model_means_orchard(dat, variable, predictor_means, new_order, title)"},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/plot_model_means_orchard.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot orchard-plot style model means — plot_model_means_orchard","text":"dat tibble data plot variable character string predictor variable plot predictor_means tibble means model new_order character vector new order variable title character string plot title","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/plot_model_means_orchard.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot orchard-plot style model means — plot_model_means_orchard","text":"ggplot object","code":""},{"path":[]},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/poss_fit_boxcox_ratings_cat.html","id":null,"dir":"Reference","previous_headings":"","what":"Possibly fit_boxcox_ratings_cat() — poss_fit_boxcox_ratings_cat","title":"Possibly fit_boxcox_ratings_cat() — poss_fit_boxcox_ratings_cat","text":"Wrapper fit_boxcox_ratings_cat() returns NA error encountered","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/poss_fit_boxcox_ratings_cat.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Possibly fit_boxcox_ratings_cat() — poss_fit_boxcox_ratings_cat","text":"","code":"poss_fit_boxcox_ratings_cat(...)"},{"path":[]},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/poss_fit_boxcox_ratings_cont.html","id":null,"dir":"Reference","previous_headings":"","what":"Possibly fit fit_boxcox_ratings_cont() model — poss_fit_boxcox_ratings_cont","title":"Possibly fit fit_boxcox_ratings_cont() model — poss_fit_boxcox_ratings_cont","text":"Wrapper fit_boxcox_ratings_cont() returns NA error thrown","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/poss_fit_boxcox_ratings_cont.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Possibly fit fit_boxcox_ratings_cont() model — poss_fit_boxcox_ratings_cont","text":"","code":"poss_fit_boxcox_ratings_cont(...)"},{"path":[]},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/poss_fit_boxcox_ratings_ord.html","id":null,"dir":"Reference","previous_headings":"","what":"Possibly fit_box_cox_ratings() — poss_fit_boxcox_ratings_ord","title":"Possibly fit_box_cox_ratings() — poss_fit_boxcox_ratings_ord","text":"wrapper fit_box_cox_ratings() returns NA error thrown","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/poss_fit_boxcox_ratings_ord.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Possibly fit_box_cox_ratings() — poss_fit_boxcox_ratings_ord","text":"","code":"poss_fit_boxcox_ratings_ord(...)"},{"path":[]},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/poss_fit_metafor_mv.html","id":null,"dir":"Reference","previous_headings":"","what":"Possibly fit_metafor_mv() — poss_fit_metafor_mv","title":"Possibly fit_metafor_mv() — poss_fit_metafor_mv","text":"Wrapper fit_metafor_mv() returns NA error thrown","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/poss_fit_metafor_mv.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Possibly fit_metafor_mv() — poss_fit_metafor_mv","text":"","code":"poss_fit_metafor_mv(...)"},{"path":[]},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/poss_fit_sorensen_glm.html","id":null,"dir":"Reference","previous_headings":"","what":"Possibly fit_sorensen_glm() — poss_fit_sorensen_glm","title":"Possibly fit_sorensen_glm() — poss_fit_sorensen_glm","text":"version fit_sorensen_glm() returns NA error encountered","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/poss_fit_sorensen_glm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Possibly fit_sorensen_glm() — poss_fit_sorensen_glm","text":"","code":"poss_fit_sorensen_glm(...)"},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/poss_fit_uni_mixed_effects.html","id":null,"dir":"Reference","previous_headings":"","what":"Possibly fit_uni_mixed_effects() — poss_fit_uni_mixed_effects","title":"Possibly fit_uni_mixed_effects() — poss_fit_uni_mixed_effects","text":"Wrapper fit_uni_mixed_effects() returns NA error thrown.","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/poss_fit_uni_mixed_effects.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Possibly fit_uni_mixed_effects() — poss_fit_uni_mixed_effects","text":"","code":"poss_fit_uni_mixed_effects(...)"},{"path":[]},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/pred_to_Z.html","id":null,"dir":"Reference","previous_headings":"","what":"Z-standardise a dataframe of back-transformed Out-Of-Sample Predictions — pred_to_Z","title":"Z-standardise a dataframe of back-transformed Out-Of-Sample Predictions — pred_to_Z","text":"Standardizes --sample predictions computing Fisher's Z transformed Correlation Coefficient analysts' --sample prediction estimates corresponding standard error.","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/pred_to_Z.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Z-standardise a dataframe of back-transformed Out-Of-Sample Predictions — pred_to_Z","text":"","code":"pred_to_Z(back_transformed_data, params)"},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/pred_to_Z.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Z-standardise a dataframe of back-transformed Out-Of-Sample Predictions — pred_to_Z","text":"back_transformed_data dataframe tibble columns \"estimate\" \"se.fit\", containing yi SE\\(yi\\) values respectively response_variable_name character vector","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/pred_to_Z.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Z-standardise a dataframe of back-transformed Out-Of-Sample Predictions — pred_to_Z","text":"tibble standardised---sample predictions Z-scale, columns Z, VZ, lower upper, original columns fro back_transformed_data used / updated transformation.","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/pred_to_Z.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Z-standardise a dataframe of back-transformed Out-Of-Sample Predictions — pred_to_Z","text":"function used standardize --sample predictions response scale Z-scale. pred_to_Z() expects estimates response scale, link scale. function computes Z-score VZ-score --sample prediction estimate corresponding standard error using Z_VZ_preds().","code":""},{"path":[]},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/prepare_ManyEcoEvo.html","id":null,"dir":"Reference","previous_headings":"","what":"Prepare ManyEcoEvo raw dataset — prepare_ManyEcoEvo","title":"Prepare ManyEcoEvo raw dataset — prepare_ManyEcoEvo","text":"Prepare ManyEcoEvo raw dataset","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/prepare_ManyEcoEvo.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Prepare ManyEcoEvo raw dataset — prepare_ManyEcoEvo","text":"","code":"prepare_ManyEcoEvo(master_data_raw, master_raw_metadata, all_review_data)"},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/prepare_ManyEcoEvo.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Prepare ManyEcoEvo raw dataset — prepare_ManyEcoEvo","text":"master_data_raw Raw data eucalyptus blue tit analyses master_raw_metadata Metadata describing master_data_raw all_review_data Review data datasets contained master_data_raw, generated prepare_review_data.","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/prepare_ManyEcoEvo.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Prepare ManyEcoEvo raw dataset — prepare_ManyEcoEvo","text":"tibble ManyEcoEvo analyst response data effect-sizes ($Z_r$).","code":""},{"path":[]},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/prepare_ManyEcoEvo_yi.html","id":null,"dir":"Reference","previous_headings":"","what":"Prepare ManyEcoEvo raw dataset for out-of-sample predictions — prepare_ManyEcoEvo_yi","title":"Prepare ManyEcoEvo raw dataset for out-of-sample predictions — prepare_ManyEcoEvo_yi","text":"Prepare ManyEcoEvo raw dataset --sample predictions","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/prepare_ManyEcoEvo_yi.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Prepare ManyEcoEvo raw dataset for out-of-sample predictions — prepare_ManyEcoEvo_yi","text":"","code":"prepare_ManyEcoEvo_yi(   master_data_raw,   master_raw_metadata,   all_prediction_data )"},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/prepare_ManyEcoEvo_yi.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Prepare ManyEcoEvo raw dataset for out-of-sample predictions — prepare_ManyEcoEvo_yi","text":"master_data_raw Raw data eucalyptus blue tit analyses master_raw_metadata Metadata describing master_data_raw all_prediction_data Prediction data datasets contained tibble all_review_data Review data datasets contained master_data_raw, generated prepare_review_data. ManyEcoEvo ManyEcoEvo data generated prepare_ManyEcoEvo","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/prepare_ManyEcoEvo_yi.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Prepare ManyEcoEvo raw dataset for out-of-sample predictions — prepare_ManyEcoEvo_yi","text":"tibble ManyEcoEvo analyst response data --sample predictions ($y_i$).","code":""},{"path":[]},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/prepare_analyst_summary_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Prepare data for summarising analyst summary statistics — prepare_analyst_summary_data","title":"Prepare data for summarising analyst summary statistics — prepare_analyst_summary_data","text":"Prepares data summarising summary statistics across entire study unnesting data joining prepared data preparation summarising subsets data summarise_study().","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/prepare_analyst_summary_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Prepare data for summarising analyst summary statistics — prepare_analyst_summary_data","text":"","code":"prepare_analyst_summary_data(   data,   data_subset_name = \"all\",   id_subsets = list(),   subset_names = character(0L) )"},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/prepare_analyst_summary_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Prepare data for summarising analyst summary statistics — prepare_analyst_summary_data","text":"data ManyAnalyst style tibble containing data analysed. data_subset_name character vector length 1, name subset data. id_subsets list tibbles containing id_col subset data. subset_names character vector equal length id_subsets; name data subsets id_subsets.","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/prepare_analyst_summary_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Prepare data for summarising analyst summary statistics — prepare_analyst_summary_data","text":"tibble containing subsets analyst summary statistics data.","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/prepare_analyst_summary_data.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Prepare data for summarising analyst summary statistics — prepare_analyst_summary_data","text":"","code":"id_subsets <- list(ManyEcoEvo:::effect_ids, ManyEcoEvo:::prediction_ids) subset_names <- c(\"effects\", \"predictions\") prepare_analyst_summary_data(   ManyEcoEvo::ManyEcoEvo,   \"all\",   id_subsets,   subset_names ) #> # A tibble: 3 × 2 #>   data                subset_name #>   <list>              <chr>       #> 1 <tibble [302 × 40]> all         #> 2 <tibble [210 × 40]> effects     #> 3 <tibble [88 × 40]>  predictions"},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/prepare_df_for_summarising.html","id":null,"dir":"Reference","previous_headings":"","what":"Prepare data for summarising descriptive statistics — prepare_df_for_summarising","title":"Prepare data for summarising descriptive statistics — prepare_df_for_summarising","text":"Calculates number fixed variables, number random variables, sample size, number interactions, number linear models, number generalised models, number fixed effects, number random effects analysis dataset. Also codes whether analysis employs linear model, generalised model, Bayesian model.","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/prepare_df_for_summarising.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Prepare data for summarising descriptive statistics — prepare_df_for_summarising","text":"","code":"prepare_df_for_summarising(data)"},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/prepare_df_for_summarising.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Prepare data for summarising descriptive statistics — prepare_df_for_summarising","text":"data tibble containing many-analyst data summarised.","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/prepare_df_for_summarising.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Prepare data for summarising descriptive statistics — prepare_df_for_summarising","text":"tibble containing data prepared summarising.","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/prepare_df_for_summarising.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Prepare data for summarising descriptive statistics — prepare_df_for_summarising","text":"","code":"ManyEcoEvo::ManyEcoEvo %>%   select(data) %>%   unnest(everything()) %>%   prepare_df_for_summarising() #> # A tibble: 302 × 40 #>    response_id       submission_id analysis_id split_id TeamIdentifier id_col    #>    <chr>                     <dbl>       <dbl>    <dbl> <chr>          <chr>     #>  1 R_11787O3NmejXKAH             1           2        2 Ayr            Ayr-1-2-2 #>  2 R_11787O3NmejXKAH             1           2        3 Ayr            Ayr-1-2-3 #>  3 R_11787O3NmejXKAH             1           2        1 Ayr            Ayr-1-2-1 #>  4 R_126erjKKuN3IwSJ             2           2        1 Bega           Bega-2-2… #>  5 R_126erjKKuN3IwSJ             2           2        2 Bega           Bega-2-2… #>  6 R_126erjKKuN3IwSJ             1           1        1 Bega           Bega-1-1… #>  7 R_126erjKKuN3IwSJ             1           1        2 Bega           Bega-1-1… #>  8 R_12cozGev3IOOBG2             4           4        1 Bell           Bell-4-4… #>  9 R_12cozGev3IOOBG2             3           3        1 Bell           Bell-3-3… #> 10 R_12cozGev3IOOBG2             1           1        1 Bell           Bell-1-1… #> # ℹ 292 more rows #> # ℹ 34 more variables: beta_estimate <dbl>, contrast <chr>, adjusted_df <dbl>, #> #   beta_SE <dbl>, transformation <chr>, link_function_reported <chr>, #> #   dataset <chr>, mixed_model <dbl>, #> #   response_transformation_description <chr>, #> #   response_transformation_status <chr>, response_variable_type <chr>, #> #   response_construction_description <chr>, response_variable_name <chr>, …"},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/prepare_diversity_raw.html","id":null,"dir":"Reference","previous_headings":"","what":"Prepare diversity index data — prepare_diversity_raw","title":"Prepare diversity index data — prepare_diversity_raw","text":"Prepares data required calculating Sorensen diversity indices across analyses. \\(Non-targets function\\)","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/prepare_diversity_raw.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Prepare diversity index data — prepare_diversity_raw","text":"","code":"prepare_diversity_raw(master_data_raw, master_raw_metadata)"},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/prepare_diversity_raw.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Prepare diversity index data — prepare_diversity_raw","text":"master_data_raw Raw dataset eucalyptus blue tit data master_raw_metadata Metadata describing variable names master_data_raw","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/prepare_diversity_raw.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Prepare diversity index data — prepare_diversity_raw","text":"tibble raw diversity index data","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/prepare_diversity_summary_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Prepare data for summarising variable diversity — prepare_diversity_summary_data","title":"Prepare data for summarising variable diversity — prepare_diversity_summary_data","text":"Prepares data summarising variable diversity across entire study unnesting diversity data joining prepared data preparation summarising subsets data summarise_study().","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/prepare_diversity_summary_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Prepare data for summarising variable diversity — prepare_diversity_summary_data","text":"","code":"prepare_diversity_summary_data(   data,   data_subset_name = \"all\",   id_subsets = list(),   subset_names = character(0L) )"},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/prepare_diversity_summary_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Prepare data for summarising variable diversity — prepare_diversity_summary_data","text":"data ManyAnalyst style tibble containing data analysed. data_subset_name character vector length 1, name subset data. id_subsets list tibbles containing id_col subset data. subset_names character vector equal length id_subsets; name data subsets id_subsets.","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/prepare_diversity_summary_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Prepare data for summarising variable diversity — prepare_diversity_summary_data","text":"tibble containing subsets variable diversity data data.","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/prepare_diversity_summary_data.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Prepare data for summarising variable diversity — prepare_diversity_summary_data","text":"","code":"id_subsets <- list(ManyEcoEvo:::effect_ids, ManyEcoEvo:::prediction_ids) subset_names <- c(\"effects\", \"predictions\") prepare_diversity_summary_data(   ManyEcoEvo::ManyEcoEvo,   \"all\",   id_subsets,   subset_names ) # TODO consider adding filter_expressions #> # A tibble: 3 × 2 #>   data                 subset_name #>   <list>               <chr>       #> 1 <tibble [302 × 117]> all         #> 2 <tibble [210 × 117]> effects     #> 3 <tibble [88 × 117]>  predictions"},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/prepare_response_variables.html","id":null,"dir":"Reference","previous_headings":"","what":"Prepare response variable data for nested ManyEcoEvo dataset — prepare_response_variables","title":"Prepare response variable data for nested ManyEcoEvo dataset — prepare_response_variables","text":"Prepare response variable data nested ManyEcoEvo dataset","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/prepare_response_variables.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Prepare response variable data for nested ManyEcoEvo dataset — prepare_response_variables","text":"","code":"prepare_response_variables(   ManyEcoEvo,   estimate_type = character(1L),   param_table = NULL,   dataset_standardise = NULL,   dataset_log_transform = NULL,   ... )"},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/prepare_response_variables.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Prepare response variable data for nested ManyEcoEvo dataset — prepare_response_variables","text":"ManyEcoEvo Complete ManyEcoEvo dataset containing nested datasets different analysis exclusion set dataset estimate_type character string length 1, equal either \"Zr\", \"yi\", \"y25\", \"y50\", \"y75\", indicating type estimates prepared. param_table table parameters \\(mean, sd\\) response variables used analysts. tibble pulled named object exported ManyEcoEvo::. can overwritten users's param_table dataset. dataset_standardise character string length 1, equal name dataset standardise response variables . NULL (default), datasets standardised. dataset_log_transform character string length 1, equal name dataset log-transform response variables . NULL (default), datasets log-transformed.","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/prepare_response_variables.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Prepare response variable data for nested ManyEcoEvo dataset — prepare_response_variables","text":"tibble nested list-columns","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/prepare_response_variables.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Prepare response variable data for nested ManyEcoEvo dataset — prepare_response_variables","text":"Operates nested list-columns dataframes, dataframe contains response variable data single analysis. function standardises response variable data analysis, returns modified dataset data list-column. Note ManyEcoEvo estimate_type column, added value estimate_type. transformation functions require estimate_type column present dataset.","code":""},{"path":[]},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/prepare_response_variables.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Prepare response variable data for nested ManyEcoEvo dataset — prepare_response_variables","text":"","code":"data(ManyEcoEvo) ManyEcoEvo %>% prepare_response_variables(estimate_type = \"Zr\") #> ℹ Standardising response variables for \"Zr\" estimates. #>  #> ── Computing meta-analysis inputsfor `estimate_type` = \"Zr\" ──────────────────── #>  #> ── Computing standardised effect sizes `Zr` and variance `VZr` ── #>  #> ✖ Required values for computing standardised effect sizes missing: #> ! Returning \"NA\" for tupple: #> 1. beta_estimate NA, #> 2. beta_se NA, #> 3. adjusted_df 484.0193. #> ✖ Required values for computing standardised effect sizes missing: #> ! Returning \"NA\" for tupple: #> 1. beta_estimate NA, #> 2. beta_se NA, #> 3. adjusted_df 666.56874. #> ✖ Required values for computing standardised effect sizes missing: #> ! Returning \"NA\" for tupple: #> 1. beta_estimate NA, #> 2. beta_se NA, #> 3. adjusted_df 590.18263. #> ✖ Required values for computing standardised effect sizes missing: #> ! Returning \"NA\" for tupple: #> 1. beta_estimate NA, #> 2. beta_se 0.006225, #> 3. adjusted_df NA. #> ✖ Required values for computing standardised effect sizes missing: #> ! Returning \"NA\" for tupple: #> 1. beta_estimate NA, #> 2. beta_se 0.003996, #> 3. adjusted_df NA. #> ✖ Required values for computing standardised effect sizes missing: #> ! Returning \"NA\" for tupple: #> 1. beta_estimate NA, #> 2. beta_se NA, #> 3. adjusted_df NA. #> ✖ Required values for computing standardised effect sizes missing: #> ! Returning \"NA\" for tupple: #> 1. beta_estimate NA, #> 2. beta_se NA, #> 3. adjusted_df NA. #> ✖ Required values for computing standardised effect sizes missing: #> ! Returning \"NA\" for tupple: #> 1. beta_estimate NA, #> 2. beta_se NA, #> 3. adjusted_df NA. #> ✖ Required values for computing standardised effect sizes missing: #> ! Returning \"NA\" for tupple: #> 1. beta_estimate NA, #> 2. beta_se NA, #> 3. adjusted_df NA. #> ✖ Required values for computing standardised effect sizes missing: #> ! Returning \"NA\" for tupple: #> 1. beta_estimate NA, #> 2. beta_se NA, #> 3. adjusted_df NA. #> ✖ Required values for computing standardised effect sizes missing: #> ! Returning \"NA\" for tupple: #> 1. beta_estimate NA, #> 2. beta_se NA, #> 3. adjusted_df 481. #> ✖ Required values for computing standardised effect sizes missing: #> ! Returning \"NA\" for tupple: #> 1. beta_estimate NA, #> 2. beta_se 0.09247, #> 3. adjusted_df 316.17526. #> ✖ Required values for computing standardised effect sizes missing: #> ! Returning \"NA\" for tupple: #> 1. beta_estimate NA, #> 2. beta_se 0.029, #> 3. adjusted_df 366.3. #> ✖ Required values for computing standardised effect sizes missing: #> ! Returning \"NA\" for tupple: #> 1. beta_estimate NA, #> 2. beta_se 0.042, #> 3. adjusted_df NA. #> ✖ Required values for computing standardised effect sizes missing: #> ! Returning \"NA\" for tupple: #> 1. beta_estimate NA, #> 2. beta_se NA, #> 3. adjusted_df NA. #> ✖ Required values for computing standardised effect sizes missing: #> ! Returning \"NA\" for tupple: #> 1. beta_estimate NA, #> 2. beta_se 0.01416305, #> 3. adjusted_df 257.905. #> ✖ Required values for computing standardised effect sizes missing: #> ! Returning \"NA\" for tupple: #> 1. beta_estimate NA, #> 2. beta_se NA, #> 3. adjusted_df NA. #> ✖ Required values for computing standardised effect sizes missing: #> ! Returning \"NA\" for tupple: #> 1. beta_estimate NA, #> 2. beta_se 0.030382264, #> 3. adjusted_df 2372.82. #> ✖ Required values for computing standardised effect sizes missing: #> ! Returning \"NA\" for tupple: #> 1. beta_estimate NA, #> 2. beta_se 0.01409, #> 3. adjusted_df NA. #> ✖ Required values for computing standardised effect sizes missing: #> ! Returning \"NA\" for tupple: #> 1. beta_estimate NA, #> 2. beta_se 0.008781, #> 3. adjusted_df NA. #> ✖ Required values for computing standardised effect sizes missing: #> ! Returning \"NA\" for tupple: #> 1. beta_estimate NA, #> 2. beta_se 0.014853, #> 3. adjusted_df NA. #> ✖ Required values for computing standardised effect sizes missing: #> ! Returning \"NA\" for tupple: #> 1. beta_estimate NA, #> 2. beta_se NA, #> 3. adjusted_df NA. #> ✖ Required values for computing standardised effect sizes missing: #> ! Returning \"NA\" for tupple: #> 1. beta_estimate NA, #> 2. beta_se NA, #> 3. adjusted_df NA. #> ✖ Required values for computing standardised effect sizes missing: #> ! Returning \"NA\" for tupple: #> 1. beta_estimate NA, #> 2. beta_se NA, #> 3. adjusted_df NA. #> ✖ Required values for computing standardised effect sizes missing: #> ! Returning \"NA\" for tupple: #> 1. beta_estimate NA, #> 2. beta_se NA, #> 3. adjusted_df NA. #> ✖ Required values for computing standardised effect sizes missing: #> ! Returning \"NA\" for tupple: #> 1. beta_estimate NA, #> 2. beta_se 0.000769, #> 3. adjusted_df NA. #> ✖ Required values for computing standardised effect sizes missing: #> ! Returning \"NA\" for tupple: #> 1. beta_estimate NA, #> 2. beta_se NA, #> 3. adjusted_df NA. #> ✖ Required values for computing standardised effect sizes missing: #> ! Returning \"NA\" for tupple: #> 1. beta_estimate NA, #> 2. beta_se NA, #> 3. adjusted_df NA. #> ✖ Required values for computing standardised effect sizes missing: #> ! Returning \"NA\" for tupple: #> 1. beta_estimate NA, #> 2. beta_se NA, #> 3. adjusted_df NA. #> ✖ Required values for computing standardised effect sizes missing: #> ! Returning \"NA\" for tupple: #> 1. beta_estimate NA, #> 2. beta_se 0.033978443, #> 3. adjusted_df 347.4992526. #> ✖ Required values for computing standardised effect sizes missing: #> ! Returning \"NA\" for tupple: #> 1. beta_estimate NA, #> 2. beta_se NA, #> 3. adjusted_df NA. #> ✖ Required values for computing standardised effect sizes missing: #> ! Returning \"NA\" for tupple: #> 1. beta_estimate NA, #> 2. beta_se NA, #> 3. adjusted_df NA. #> ✖ Required values for computing standardised effect sizes missing: #> ! Returning \"NA\" for tupple: #> 1. beta_estimate NA, #> 2. beta_se 0.01823188, #> 3. adjusted_df 55.44391. #> ✖ Required values for computing standardised effect sizes missing: #> ! Returning \"NA\" for tupple: #> 1. beta_estimate NA, #> 2. beta_se 0.02039768, #> 3. adjusted_df NA. #> ✖ Required values for computing standardised effect sizes missing: #> ! Returning \"NA\" for tupple: #> 1. beta_estimate NA, #> 2. beta_se 0.02496, #> 3. adjusted_df NA. #> ✖ Required values for computing standardised effect sizes missing: #> ! Returning \"NA\" for tupple: #> 1. beta_estimate NA, #> 2. beta_se 0.03575, #> 3. adjusted_df NA. #>  #> ── Computing meta-analysis inputsfor `estimate_type` = \"Zr\" ──────────────────── #>  #> ── Computing standardised effect sizes `Zr` and variance `VZr` ── #>  #> ✖ Required values for computing standardised effect sizes missing: #> ! Returning \"NA\" for tupple: #> 1. beta_estimate NA, #> 2. beta_se 0.29212, #> 3. adjusted_df 21. #> ✖ Required values for computing standardised effect sizes missing: #> ! Returning \"NA\" for tupple: #> 1. beta_estimate NA, #> 2. beta_se 0.007831, #> 3. adjusted_df NA. #> ✖ Required values for computing standardised effect sizes missing: #> ! Returning \"NA\" for tupple: #> 1. beta_estimate NA, #> 2. beta_se 0.07216, #> 3. adjusted_df 0.560867697. #> ✖ Required values for computing standardised effect sizes missing: #> ! Returning \"NA\" for tupple: #> 1. beta_estimate NA, #> 2. beta_se 0.57, #> 3. adjusted_df NA. #> ✖ Required values for computing standardised effect sizes missing: #> ! Returning \"NA\" for tupple: #> 1. beta_estimate NA, #> 2. beta_se NA, #> 3. adjusted_df NA. #> ✖ Required values for computing standardised effect sizes missing: #> ! Returning \"NA\" for tupple: #> 1. beta_estimate NA, #> 2. beta_se NA, #> 3. adjusted_df NA. #> ✖ Required values for computing standardised effect sizes missing: #> ! Returning \"NA\" for tupple: #> 1. beta_estimate NA, #> 2. beta_se NA, #> 3. adjusted_df NA. #> ✖ Required values for computing standardised effect sizes missing: #> ! Returning \"NA\" for tupple: #> 1. beta_estimate NA, #> 2. beta_se NA, #> 3. adjusted_df NA. #> ✖ Required values for computing standardised effect sizes missing: #> ! Returning \"NA\" for tupple: #> 1. beta_estimate NA, #> 2. beta_se NA, #> 3. adjusted_df NA. #> ✖ Required values for computing standardised effect sizes missing: #> ! Returning \"NA\" for tupple: #> 1. beta_estimate NA, #> 2. beta_se 0.2328, #> 3. adjusted_df 343.24787. #> ✖ Required values for computing standardised effect sizes missing: #> ! Returning \"NA\" for tupple: #> 1. beta_estimate NA, #> 2. beta_se 0.3188723, #> 3. adjusted_df NA. #> ✖ Required values for computing standardised effect sizes missing: #> ! Returning \"NA\" for tupple: #> 1. beta_estimate NA, #> 2. beta_se NA, #> 3. adjusted_df NA. #> ✖ Required values for computing standardised effect sizes missing: #> ! Returning \"NA\" for tupple: #> 1. beta_estimate NA, #> 2. beta_se 0.0059286, #> 3. adjusted_df 1. #> ✖ Required values for computing standardised effect sizes missing: #> ! Returning \"NA\" for tupple: #> 1. beta_estimate NA, #> 2. beta_se NA, #> 3. adjusted_df NA. #> ✖ Required values for computing standardised effect sizes missing: #> ! Returning \"NA\" for tupple: #> 1. beta_estimate NA, #> 2. beta_se 0.007385, #> 3. adjusted_df 3.5e-25. #> ✖ Required values for computing standardised effect sizes missing: #> ! Returning \"NA\" for tupple: #> 1. beta_estimate NA, #> 2. beta_se 0.052462, #> 3. adjusted_df 3.5e-25. #> ✖ Required values for computing standardised effect sizes missing: #> ! Returning \"NA\" for tupple: #> 1. beta_estimate NA, #> 2. beta_se 0.605, #> 3. adjusted_df NA. #> ✖ Required values for computing standardised effect sizes missing: #> ! Returning \"NA\" for tupple: #> 1. beta_estimate NA, #> 2. beta_se 8.98, #> 3. adjusted_df NA. #> ✖ Required values for computing standardised effect sizes missing: #> ! Returning \"NA\" for tupple: #> 1. beta_estimate NA, #> 2. beta_se 7.97, #> 3. adjusted_df NA. #> ✖ Required values for computing standardised effect sizes missing: #> ! Returning \"NA\" for tupple: #> 1. beta_estimate NA, #> 2. beta_se 5.19, #> 3. adjusted_df NA. #> ✖ Required values for computing standardised effect sizes missing: #> ! Returning \"NA\" for tupple: #> 1. beta_estimate NA, #> 2. beta_se 18.5, #> 3. adjusted_df NA. #> ✖ Required values for computing standardised effect sizes missing: #> ! Returning \"NA\" for tupple: #> 1. beta_estimate NA, #> 2. beta_se 5.92, #> 3. adjusted_df NA. #> ✖ Required values for computing standardised effect sizes missing: #> ! Returning \"NA\" for tupple: #> 1. beta_estimate NA, #> 2. beta_se 0.529, #> 3. adjusted_df NA. #> ✖ Required values for computing standardised effect sizes missing: #> ! Returning \"NA\" for tupple: #> 1. beta_estimate NA, #> 2. beta_se 2.89, #> 3. adjusted_df NA. #> ✖ Required values for computing standardised effect sizes missing: #> ! Returning \"NA\" for tupple: #> 1. beta_estimate NA, #> 2. beta_se 0.605, #> 3. adjusted_df NA. #> ✖ Required values for computing standardised effect sizes missing: #> ! Returning \"NA\" for tupple: #> 1. beta_estimate NA, #> 2. beta_se NA, #> 3. adjusted_df NA. #> ✖ Required values for computing standardised effect sizes missing: #> ! Returning \"NA\" for tupple: #> 1. beta_estimate NA, #> 2. beta_se NA, #> 3. adjusted_df NA. #> ✖ Required values for computing standardised effect sizes missing: #> ! Returning \"NA\" for tupple: #> 1. beta_estimate NA, #> 2. beta_se 0.01312667, #> 3. adjusted_df -2.6269353. #> ✖ Required values for computing standardised effect sizes missing: #> ! Returning \"NA\" for tupple: #> 1. beta_estimate NA, #> 2. beta_se NA, #> 3. adjusted_df NA. #> ✖ Required values for computing standardised effect sizes missing: #> ! Returning \"NA\" for tupple: #> 1. beta_estimate NA, #> 2. beta_se 0.197, #> 3. adjusted_df NA. #> ✖ Required values for computing standardised effect sizes missing: #> ! Returning \"NA\" for tupple: #> 1. beta_estimate NA, #> 2. beta_se 0.192, #> 3. adjusted_df 82.703. #> ✖ Required values for computing standardised effect sizes missing: #> ! Returning \"NA\" for tupple: #> 1. beta_estimate NA, #> 2. beta_se 0.1, #> 3. adjusted_df NA. #> ✖ Required values for computing standardised effect sizes missing: #> ! Returning \"NA\" for tupple: #> 1. beta_estimate NA, #> 2. beta_se NA, #> 3. adjusted_df NA. #> ✖ Required values for computing standardised effect sizes missing: #> ! Returning \"NA\" for tupple: #> 1. beta_estimate NA, #> 2. beta_se 0.0048042, #> 3. adjusted_df 341. #> ✖ Required values for computing standardised effect sizes missing: #> ! Returning \"NA\" for tupple: #> 1. beta_estimate NA, #> 2. beta_se 0.21, #> 3. adjusted_df NA. #> ✖ Required values for computing standardised effect sizes missing: #> ! Returning \"NA\" for tupple: #> 1. beta_estimate NA, #> 2. beta_se 0.5756016, #> 3. adjusted_df 3.536992. #> # A tibble: 2 × 4 #>   dataset    data                diversity_data      estimate_type #>   <chr>      <list>              <named list>        <chr>         #> 1 blue tit   <tibble [174 × 40]> <tibble [174 × 54]> Zr            #> 2 eucalyptus <tibble [128 × 40]> <tibble [128 × 61]> Zr"},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/prepare_response_variables_yi.html","id":null,"dir":"Reference","previous_headings":"","what":"Prepare response variable data for nested ManyEcoEvo dataset - out of sample predictions only — prepare_response_variables_yi","title":"Prepare response variable data for nested ManyEcoEvo dataset - out of sample predictions only — prepare_response_variables_yi","text":"Prepare response variable data nested ManyEcoEvo dataset - sample predictions ","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/prepare_response_variables_yi.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Prepare response variable data for nested ManyEcoEvo dataset - out of sample predictions only — prepare_response_variables_yi","text":"","code":"prepare_response_variables_yi(   ManyEcoEvo,   estimate_type = character(1L),   param_table = NULL )"},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/prepare_response_variables_yi.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Prepare response variable data for nested ManyEcoEvo dataset - out of sample predictions only — prepare_response_variables_yi","text":"ManyEcoEvo Complete ManyEcoEvo dataset containing nested datasets different analysis exclusion set dataset estimate_type character string length 1, equal either \"yi\", \"y25\", \"y50\", \"y75\", indicating type estimates prepared. param_table table parameters \\(mean, sd\\) response variables used analysts. tibble pulled named object exported ManyEcoEvo::. can overwritten users's param_table dataset.","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/prepare_response_variables_yi.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Prepare response variable data for nested ManyEcoEvo dataset - out of sample predictions only — prepare_response_variables_yi","text":"tibble nested list-columns","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/prepare_response_variables_yi.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Prepare response variable data for nested ManyEcoEvo dataset - out of sample predictions only — prepare_response_variables_yi","text":"Operates nested list-columns data. function back-transforms response variables link response scale dataset ManyEcoEvo dataset. back-transformed data stored list-column called back_transformed_data. useful wanting conduct meta-analysis response scale, e.g. Eucalyptus count data. estimate_type used specify type estimate standardised parsed back_transform_response_vars_yi()","code":""},{"path":[]},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/prepare_review_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Prepare peer-review data from Qualtrics — prepare_review_data","title":"Prepare peer-review data from Qualtrics — prepare_review_data","text":"Prepare peer-review data Qualtrics","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/prepare_review_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Prepare peer-review data from Qualtrics — prepare_review_data","text":"","code":"prepare_review_data(bt_reviews, euc_reviews)"},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/prepare_review_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Prepare peer-review data from Qualtrics — prepare_review_data","text":"bt_reviews Blue tit review euc_reviews","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/prepare_review_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Prepare peer-review data from Qualtrics — prepare_review_data","text":"tibble peer-review data blue tit eucalyptus analyses","code":""},{"path":[]},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/prepare_sorenson_summary_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Prepare data for summarising Sorensen diversity indices — prepare_sorenson_summary_data","title":"Prepare data for summarising Sorensen diversity indices — prepare_sorenson_summary_data","text":"Prepares data summarising Sorensen diversity indices across entire study unnesting diversity indices joining prepared data preparation summarising subsets data summarise_study().","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/prepare_sorenson_summary_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Prepare data for summarising Sorensen diversity indices — prepare_sorenson_summary_data","text":"","code":"prepare_sorenson_summary_data(   data,   data_subset_name = \"all\",   id_subsets = list(),   subset_names = character(0L),   filter_expressions = NULL )"},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/prepare_sorenson_summary_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Prepare data for summarising Sorensen diversity indices — prepare_sorenson_summary_data","text":"data ManyAnalyst style tibble containing data analysed. data_subset_name character vector length 1, name subset data. id_subsets list tibbles containing id_col subset data. subset_names character vector equal length id_subsets; name data subsets id_subsets. filter_expressions list expressions filter data .","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/prepare_sorenson_summary_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Prepare data for summarising Sorensen diversity indices — prepare_sorenson_summary_data","text":"tibble containing subsets Sorensen diversity indices data.","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/prepare_sorenson_summary_data.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Prepare data for summarising Sorensen diversity indices — prepare_sorenson_summary_data","text":"","code":"id_subsets <- list(ManyEcoEvo:::effect_ids, ManyEcoEvo:::prediction_ids) subset_names <- c(\"effects\", \"predictions\") filter_vars <- rlang::exprs(   exclusion_set == \"complete\",   estimate_type == \"Zr\",   publishable_subset == \"All\",   expertise_subset == \"All\",   collinearity_subset == \"All\" ) prepare_sorenson_summary_data(ManyEcoEvo::ManyEcoEvo_results,   \"all\",   id_subsets,   subset_names,   filter_expressions = filter_vars ) #> # A tibble: 3 × 2 #>   data               subset_name #>   <list>             <chr>       #> 1 <tibble [210 × 4]> all         #> 2 <tibble [210 × 4]> effects     #> 3 <tibble [88 × 4]>  predictions"},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/preprocess_prediction_files.html","id":null,"dir":"Reference","previous_headings":"","what":"Preprocess Prediction Files — preprocess_prediction_files","title":"Preprocess Prediction Files — preprocess_prediction_files","text":"Preprocess Prediction Files","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/preprocess_prediction_files.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Preprocess Prediction Files — preprocess_prediction_files","text":"","code":"preprocess_prediction_files(predictions_validation, all_surveys)"},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/preprocess_prediction_files.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Preprocess Prediction Files — preprocess_prediction_files","text":"predictions_validation dataframe containing outputs pointblank validation multiple sample prediction files all_surveys tibble analyst-data datasets","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/preprocess_prediction_files.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Preprocess Prediction Files — preprocess_prediction_files","text":"pointblank check columns nested list-column checks, submission_id computed question, new_names replacement column names given new_names, filepath appended \"data-raw/analyst_data/S2\"","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/preprocess_updated_prediction_files.html","id":null,"dir":"Reference","previous_headings":"","what":"Performs QA on re-submitted out-of-sample prediction files — preprocess_updated_prediction_files","title":"Performs QA on re-submitted out-of-sample prediction files — preprocess_updated_prediction_files","text":"Performs QA re-submitted --sample prediction files","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/preprocess_updated_prediction_files.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Performs QA on re-submitted out-of-sample prediction files — preprocess_updated_prediction_files","text":"","code":"preprocess_updated_prediction_files(df = data.frame())"},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/preprocess_updated_prediction_files.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Performs QA on re-submitted out-of-sample prediction files — preprocess_updated_prediction_files","text":"df dataframe containing information new prediction files","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/preprocess_updated_prediction_files.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Performs QA on re-submitted out-of-sample prediction files — preprocess_updated_prediction_files","text":"tibble list-columns containing outputs point-blank checks","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/process_analyst_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Wrapper function to standardise response variables — pmap_wrap","title":"Wrapper function to standardise response variables — pmap_wrap","text":"function generates response data meta-analysis without standardising effect sizes / --sample predictions.","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/process_analyst_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Wrapper function to standardise response variables — pmap_wrap","text":"","code":"pmap_wrap(..., fns, env = caller_env())  standardise_response(   data,   estimate_type = character(1L),   param_table = NULL,   dataset = character(1L),   ... )  process_response(data, ...)  log_transform_response(data, sim = 10000L, ...)"},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/process_analyst_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Wrapper function to standardise response variables — pmap_wrap","text":"... Ignored data tibble analyst data list-column called estimate_type type estimate standardised. Character vector length 1, whose value may \"Zr\", \"yi\", \"y25\", \"y50\", \"y75\". param_table table estimated 'population' parameters variable analysis datasets. dataset Character vector length 1. name dataset processed, e.g. blue tit eucalyptus. sim numeric vector length 1L number simulations passed log_transform()","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/process_analyst_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Wrapper function to standardise response variables — pmap_wrap","text":"tibble analyst data standardised values contained list-column called 'back_transformed_data'","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/process_analyst_data.html","id":"functions","dir":"Reference","previous_headings":"","what":"Functions","title":"Wrapper function to standardise response variables — pmap_wrap","text":"standardise_response(): Standardise response data meta-analysis process_response(): Process response data meta-analysis standardise effect-sizes log_transform_response(): Standardise response data meta-analysis","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/process_analyst_data.html","id":"standardise-response-","dir":"Reference","previous_headings":"","what":"standardise_response()","title":"Wrapper function to standardise response variables — pmap_wrap","text":"estimate_type \"Zr\", standardise_response() standardises effect-sizes est_to_zr(), assuming beta_estimate beta_SE values already back-transformed appropriate scale. #TODO check . estimate-type \"yi\" otherwise, function: assigns transformation_type assign_transformation_type(), assumes Converts --sample predictions link- transformed-response scale back original response scale using convert_predictions(). Standardises predictions original response-scale Z-scale, pred_to_Z(). Note $y_i$ sample predictions standardised, param_table NA NULL given variable, response variable standardised, NA returned entry back_transformed_data.","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/process_analyst_data.html","id":"process-response-","dir":"Reference","previous_headings":"","what":"process_response()","title":"Wrapper function to standardise response variables — pmap_wrap","text":"Formats tibbles list-column back_transformed_data ensure correct columns present meta-analysis, matching outputs standardise_response(). blue tit data data$back_transformed_data$fit eucalyptus data, data$back_transformed_data$estimate renamed Z. se.fit renamed VZ.","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/process_analyst_data.html","id":"log-transform-response-","dir":"Reference","previous_headings":"","what":"log_transform_response()","title":"Wrapper function to standardise response variables — pmap_wrap","text":"maps log_transform_yi() onto back-transformed data stored list-columns within data","code":""},{"path":[]},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/process_analyst_data.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Wrapper function to standardise response variables — pmap_wrap","text":"","code":"# Standardise effect-sizes for eucalyptus dataset  data(ManyEcoEvo) ManyEcoEvo %>%  filter(dataset == \"eucalyptus\") %>%  pluck(\"data\", 1) %>%  standardise_response(estimate_type = \"Zr\",                        param_table =  NULL,                       dataset =  \"eucalyptus\") #>  #> ── Computing meta-analysis inputsfor `estimate_type` = \"Zr\" ──────────────────── #>  #> ── Computing standardised effect sizes `Zr` and variance `VZr` ── #>  #> ✖ Required values for computing standardised effect sizes missing: #> ! Returning \"NA\" for tupple: #> 1. beta_estimate NA, #> 2. beta_se 0.29212, #> 3. adjusted_df 21. #> ✖ Required values for computing standardised effect sizes missing: #> ! Returning \"NA\" for tupple: #> 1. beta_estimate NA, #> 2. beta_se 0.007831, #> 3. adjusted_df NA. #> ✖ Required values for computing standardised effect sizes missing: #> ! Returning \"NA\" for tupple: #> 1. beta_estimate NA, #> 2. beta_se 0.07216, #> 3. adjusted_df 0.560867697. #> ✖ Required values for computing standardised effect sizes missing: #> ! Returning \"NA\" for tupple: #> 1. beta_estimate NA, #> 2. beta_se 0.57, #> 3. adjusted_df NA. #> ✖ Required values for computing standardised effect sizes missing: #> ! Returning \"NA\" for tupple: #> 1. beta_estimate NA, #> 2. beta_se NA, #> 3. adjusted_df NA. #> ✖ Required values for computing standardised effect sizes missing: #> ! Returning \"NA\" for tupple: #> 1. beta_estimate NA, #> 2. beta_se NA, #> 3. adjusted_df NA. #> ✖ Required values for computing standardised effect sizes missing: #> ! Returning \"NA\" for tupple: #> 1. beta_estimate NA, #> 2. beta_se NA, #> 3. adjusted_df NA. #> ✖ Required values for computing standardised effect sizes missing: #> ! Returning \"NA\" for tupple: #> 1. beta_estimate NA, #> 2. beta_se NA, #> 3. adjusted_df NA. #> ✖ Required values for computing standardised effect sizes missing: #> ! Returning \"NA\" for tupple: #> 1. beta_estimate NA, #> 2. beta_se NA, #> 3. adjusted_df NA. #> ✖ Required values for computing standardised effect sizes missing: #> ! Returning \"NA\" for tupple: #> 1. beta_estimate NA, #> 2. beta_se 0.2328, #> 3. adjusted_df 343.24787. #> ✖ Required values for computing standardised effect sizes missing: #> ! Returning \"NA\" for tupple: #> 1. beta_estimate NA, #> 2. beta_se 0.3188723, #> 3. adjusted_df NA. #> ✖ Required values for computing standardised effect sizes missing: #> ! Returning \"NA\" for tupple: #> 1. beta_estimate NA, #> 2. beta_se NA, #> 3. adjusted_df NA. #> ✖ Required values for computing standardised effect sizes missing: #> ! Returning \"NA\" for tupple: #> 1. beta_estimate NA, #> 2. beta_se 0.0059286, #> 3. adjusted_df 1. #> ✖ Required values for computing standardised effect sizes missing: #> ! Returning \"NA\" for tupple: #> 1. beta_estimate NA, #> 2. beta_se NA, #> 3. adjusted_df NA. #> ✖ Required values for computing standardised effect sizes missing: #> ! Returning \"NA\" for tupple: #> 1. beta_estimate NA, #> 2. beta_se 0.007385, #> 3. adjusted_df 3.5e-25. #> ✖ Required values for computing standardised effect sizes missing: #> ! Returning \"NA\" for tupple: #> 1. beta_estimate NA, #> 2. beta_se 0.052462, #> 3. adjusted_df 3.5e-25. #> ✖ Required values for computing standardised effect sizes missing: #> ! Returning \"NA\" for tupple: #> 1. beta_estimate NA, #> 2. beta_se 0.605, #> 3. adjusted_df NA. #> ✖ Required values for computing standardised effect sizes missing: #> ! Returning \"NA\" for tupple: #> 1. beta_estimate NA, #> 2. beta_se 8.98, #> 3. adjusted_df NA. #> ✖ Required values for computing standardised effect sizes missing: #> ! Returning \"NA\" for tupple: #> 1. beta_estimate NA, #> 2. beta_se 7.97, #> 3. adjusted_df NA. #> ✖ Required values for computing standardised effect sizes missing: #> ! Returning \"NA\" for tupple: #> 1. beta_estimate NA, #> 2. beta_se 5.19, #> 3. adjusted_df NA. #> ✖ Required values for computing standardised effect sizes missing: #> ! Returning \"NA\" for tupple: #> 1. beta_estimate NA, #> 2. beta_se 18.5, #> 3. adjusted_df NA. #> ✖ Required values for computing standardised effect sizes missing: #> ! Returning \"NA\" for tupple: #> 1. beta_estimate NA, #> 2. beta_se 5.92, #> 3. adjusted_df NA. #> ✖ Required values for computing standardised effect sizes missing: #> ! Returning \"NA\" for tupple: #> 1. beta_estimate NA, #> 2. beta_se 0.529, #> 3. adjusted_df NA. #> ✖ Required values for computing standardised effect sizes missing: #> ! Returning \"NA\" for tupple: #> 1. beta_estimate NA, #> 2. beta_se 2.89, #> 3. adjusted_df NA. #> ✖ Required values for computing standardised effect sizes missing: #> ! Returning \"NA\" for tupple: #> 1. beta_estimate NA, #> 2. beta_se 0.605, #> 3. adjusted_df NA. #> ✖ Required values for computing standardised effect sizes missing: #> ! Returning \"NA\" for tupple: #> 1. beta_estimate NA, #> 2. beta_se NA, #> 3. adjusted_df NA. #> ✖ Required values for computing standardised effect sizes missing: #> ! Returning \"NA\" for tupple: #> 1. beta_estimate NA, #> 2. beta_se NA, #> 3. adjusted_df NA. #> ✖ Required values for computing standardised effect sizes missing: #> ! Returning \"NA\" for tupple: #> 1. beta_estimate NA, #> 2. beta_se 0.01312667, #> 3. adjusted_df -2.6269353. #> ✖ Required values for computing standardised effect sizes missing: #> ! Returning \"NA\" for tupple: #> 1. beta_estimate NA, #> 2. beta_se NA, #> 3. adjusted_df NA. #> ✖ Required values for computing standardised effect sizes missing: #> ! Returning \"NA\" for tupple: #> 1. beta_estimate NA, #> 2. beta_se 0.197, #> 3. adjusted_df NA. #> ✖ Required values for computing standardised effect sizes missing: #> ! Returning \"NA\" for tupple: #> 1. beta_estimate NA, #> 2. beta_se 0.192, #> 3. adjusted_df 82.703. #> ✖ Required values for computing standardised effect sizes missing: #> ! Returning \"NA\" for tupple: #> 1. beta_estimate NA, #> 2. beta_se 0.1, #> 3. adjusted_df NA. #> ✖ Required values for computing standardised effect sizes missing: #> ! Returning \"NA\" for tupple: #> 1. beta_estimate NA, #> 2. beta_se NA, #> 3. adjusted_df NA. #> ✖ Required values for computing standardised effect sizes missing: #> ! Returning \"NA\" for tupple: #> 1. beta_estimate NA, #> 2. beta_se 0.0048042, #> 3. adjusted_df 341. #> ✖ Required values for computing standardised effect sizes missing: #> ! Returning \"NA\" for tupple: #> 1. beta_estimate NA, #> 2. beta_se 0.21, #> 3. adjusted_df NA. #> ✖ Required values for computing standardised effect sizes missing: #> ! Returning \"NA\" for tupple: #> 1. beta_estimate NA, #> 2. beta_se 0.5756016, #> 3. adjusted_df 3.536992. #> # A tibble: 128 × 40 #>    response_id       submission_id analysis_id split_id TeamIdentifier id_col    #>    <chr>                     <dbl>       <dbl>    <dbl> <chr>          <chr>     #>  1 R_0MuZ4chnmwTaLiV             1           1        1 Bicheno        Bicheno-… #>  2 R_0MuZ4chnmwTaLiV             1           1        2 Bicheno        Bicheno-… #>  3 R_12R6XuSRUcRemui             1           1        1 Biloela        Biloela-… #>  4 R_1BWpZlSbkmSofe1             1           1        1 Bingara        Bingara-… #>  5 R_1Ej3sywrrnzy7KJ             1           1        1 Birchip        Birchip-… #>  6 R_1FJQlMO4buRu6S2             1           1        1 Birdwoo        Birdwoo-… #>  7 R_1ib6zw7qoq0lHlf             1           1        1 Blayney        Blayney-… #>  8 R_1ItMbxJAVt7RRtX             1           1        1 Bodalla        Bodalla-… #>  9 R_1kH1Ko3yaLsrD0E             1           1        1 Bombala        Bombala-… #> 10 R_1l9qIgUeSEKY3ME             1           1        1 Bonalbo        Bonalbo-… #> # ℹ 118 more rows #> # ℹ 34 more variables: beta_estimate <dbl>, contrast <chr>, adjusted_df <dbl>, #> #   beta_SE <dbl>, transformation <chr>, link_function_reported <chr>, #> #   dataset <chr>, mixed_model <dbl>, #> #   response_transformation_description <chr>, #> #   response_transformation_status <chr>, response_variable_type <chr>, #> #   response_construction_description <chr>, response_variable_name <chr>, … data(ManyEcoEvo_yi) ManyEcoEvo_yi %>% filter(dataset == \"eucalyptus\") %>%   pluck(\"data\", 1) %>%   back_transform_response_vars_yi(\"yi\", \"eucalyptus\") %>%   log_transform_response() #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for logit-transformed effect sizes or out-of-sample predictions #> ✔ Applied back-transformation for logit-transformed effect sizes or out-of-sample predictions #> ✔ Applied back-transformation for logit-transformed effect sizes or out-of-sample predictions #> ✔ Applied back-transformation for logit-transformed effect sizes or out-of-sample predictions #> ✔ Applied back-transformation for logit-transformed effect sizes or out-of-sample predictions #> ✔ Applied back-transformation for logit-transformed effect sizes or out-of-sample predictions #> ✔ Applied back-transformation for logit-transformed effect sizes or out-of-sample predictions #> ✔ Applied back-transformation for logit-transformed effect sizes or out-of-sample predictions #> ✔ Applied back-transformation for logit-transformed effect sizes or out-of-sample predictions #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for square-root transformed effect sizes or out-of-sample predictions. #> ✔ Applied back-transformation for square-root transformed effect sizes or out-of-sample predictions. #> ✔ Applied back-transformation for square-root transformed effect sizes or out-of-sample predictions. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #> ✔ Applied back-transformation for log-transformed effect sizes or out-of-sample predictions, using 10000 simulations. #>  #> ── Computing meta-analysis inputs: ───────────────────────────────────────────── #>  #> ── Log-transforming response-variable ── #>  #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> ✔ Log-transformed out-of-sample predictions, using 10000 simulations. #> # A tibble: 52 × 26 #>    response_id       submission_id analysis_id split_id response_transformatio…¹ #>    <chr>                     <dbl>       <dbl>    <dbl> <chr>                    #>  1 R_1ItMbxJAVt7RRtX             1           1        1 NA                       #>  2 R_1LTZWsikoIaKdMu             1           1        1 NA                       #>  3 R_1LXqc8NAdABndjl             1           1        1 NA                       #>  4 R_1NqVW3amqwy69rK             3           3        1 NA                       #>  5 R_1l9qIgUeSEKY3ME             1           1        1 NA                       #>  6 R_1l9qIgUeSEKY3ME             2           2        1 NA                       #>  7 R_1r2FSn2AXuCimpi             1           1        1 NA                       #>  8 R_1reUKfTYXhTqVMo             1           1        1 NA                       #>  9 R_21I1NvXiVXIGkqp             1           1        1 NA                       #> 10 R_21jtSu9hB9Shf6Y             1           1        1 NA                       #> # ℹ 42 more rows #> # ℹ abbreviated name: ¹​response_transformation_description #> # ℹ 21 more variables: response_transformation_status <chr>, #> #   response_variable_type <chr>, response_construction_description <chr>, #> #   response_variable_name <chr>, response_id_S2 <chr>, id_col <chr>, #> #   TeamIdentifier <chr>, question <chr>, file_name <chr>, filepath <chr>, #> #   checks <named list>, exclusions_all <chr>, mixed_model <dbl>, …"},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/read_submission_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Read out-of-sample-prediction analyst submission data — read_submission_data","title":"Read out-of-sample-prediction analyst submission data — read_submission_data","text":"Read --sample-prediction analyst submission data","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/read_submission_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Read out-of-sample-prediction analyst submission data — read_submission_data","text":"","code":"read_submission_data(filepath)"},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/read_submission_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Read out-of-sample-prediction analyst submission data — read_submission_data","text":"filepath","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/read_submission_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Read out-of-sample-prediction analyst submission data — read_submission_data","text":"tibble sample prediction data","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/rename_prediction_cols.html","id":null,"dir":"Reference","previous_headings":"","what":"Rename Prediction Columns — rename_prediction_cols","title":"Rename Prediction Columns — rename_prediction_cols","text":"Renames prediction columns output convert_predictions","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/rename_prediction_cols.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Rename Prediction Columns — rename_prediction_cols","text":"","code":"rename_prediction_cols(.data, key_var, .old_data)"},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/rename_prediction_cols.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Rename Prediction Columns — rename_prediction_cols","text":".data tibble sample predictions response variable scale key_var tibble key variables used conversion .old_data tibble original data used conversion","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/rename_prediction_cols.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Rename Prediction Columns — rename_prediction_cols","text":"tibble sample predictions response variable scale correct column names","code":""},{"path":[]},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/rm_inf_na.html","id":null,"dir":"Reference","previous_headings":"","what":"Removes infinite and NA values from a dataframe of standardised effects — rm_inf_na","title":"Removes infinite and NA values from a dataframe of standardised effects — rm_inf_na","text":"Removes infinite NA values dataframe standardised effects","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/rm_inf_na.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Removes infinite and NA values from a dataframe of standardised effects — rm_inf_na","text":"","code":"rm_inf_na(effects_analysis, Z_colname, VZ_colname)"},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/rm_inf_na.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Removes infinite and NA values from a dataframe of standardised effects — rm_inf_na","text":"effects_analysis dataframe containing standardised effects Z_colname unquoted bare column name \\(Z\\) \\(Z_r\\) estimates VZ_colname unquoted bare column name containing \\(VZ\\) \\(\\text{VZ}_r\\) estimates","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/rm_inf_na.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Removes infinite and NA values from a dataframe of standardised effects — rm_inf_na","text":"dataframe without","code":""},{"path":[]},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/rm_inf_na.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Removes infinite and NA values from a dataframe of standardised effects — rm_inf_na","text":"","code":"data(ManyEcoEvo_results) ManyEcoEvo_results %>%  pluck(\"effects_analysis\", 1) %>%  rm_inf_na(beta_estimate, beta_SE) #> # A tibble: 131 × 50 #>    response_id       submission_id analysis_id split_id TeamIdentifier study_id  #>    <chr>                     <dbl>       <dbl>    <dbl> <chr>          <chr>     #>  1 R_126erjKKuN3IwSJ             2           2        1 Bega           Bega-2-2… #>  2 R_126erjKKuN3IwSJ             2           2        2 Bega           Bega-2-2… #>  3 R_126erjKKuN3IwSJ             1           1        1 Bega           Bega-1-1… #>  4 R_126erjKKuN3IwSJ             1           1        2 Bega           Bega-1-1… #>  5 R_12cozGev3IOOBG2             2           2        1 Bell           Bell-2-2… #>  6 R_1CC5PPCXcQPgu42             1           1        1 Berr           Berr-1-1… #>  7 R_1dzfML4yheLxG0D             1           1        1 Bruc           Bruc-1-1… #>  8 R_1E099fIoICERZIZ             1           1        2 Burr           Burr-1-1… #>  9 R_1E099fIoICERZIZ             1           1        1 Burr           Burr-1-1… #> 10 R_1E099fIoICERZIZ             2           2        2 Burr           Burr-2-2… #> # ℹ 121 more rows #> # ℹ 44 more variables: beta_estimate <dbl>, contrast <chr>, adjusted_df <dbl>, #> #   beta_SE <dbl>, transformation <chr>, link_function_reported <chr>, #> #   dataset <chr>, mixed_model <dbl>, #> #   response_transformation_description <chr>, #> #   response_transformation_status <chr>, response_variable_type <chr>, #> #   response_construction_description <chr>, response_variable_name <chr>, …"},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/run_model_checks.html","id":null,"dir":"Reference","previous_headings":"","what":"Perform model checking on series of fitted models for different datasets, exclusion sets and estimate types — run_model_checks","title":"Perform model checking on series of fitted models for different datasets, exclusion sets and estimate types — run_model_checks","text":"Checks convergence, singularity heteroscedasticy","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/run_model_checks.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Perform model checking on series of fitted models for different datasets, exclusion sets and estimate types — run_model_checks","text":"","code":"run_model_checks(data, model_name = character(0L))"},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/run_model_checks.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Perform model checking on series of fitted models for different datasets, exclusion sets and estimate types — run_model_checks","text":"data series fitted models stored list-columns different model_names, exclusion_sets, datasets estimate_types model_name character string model name extracted nested data frame. String must contained data$model_name","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/run_model_checks.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Perform model checking on series of fitted models for different datasets, exclusion sets and estimate types — run_model_checks","text":"tibble whose columns contain outcomes different model checks","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/slice_conditionally.html","id":null,"dir":"Reference","previous_headings":"","what":"Slice Conditionally — slice_conditionally","title":"Slice Conditionally — slice_conditionally","text":"Slice Conditionally","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/slice_conditionally.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Slice Conditionally — slice_conditionally","text":"","code":"slice_conditionally(data, n_min, n_max, outcome_variable)"},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/slice_conditionally.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Slice Conditionally — slice_conditionally","text":"data tibble n_min integer, number bottom outliers remove n_max integer, number top outliers remove outcome_variable character string, name outcome variable","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/split_yi_subsets.html","id":null,"dir":"Reference","previous_headings":"","what":"Split a dataset of out-of-sample predictions by estimate_type — split_yi_subsets","title":"Split a dataset of out-of-sample predictions by estimate_type — split_yi_subsets","text":"Reorganises data nesting based individual analysis submissions, nesting based type estimate.","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/split_yi_subsets.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Split a dataset of out-of-sample predictions by estimate_type — split_yi_subsets","text":"","code":"split_yi_subsets(.data)"},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/split_yi_subsets.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Split a dataset of out-of-sample predictions by estimate_type — split_yi_subsets","text":".data dataset containing --sample predictions","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/split_yi_subsets.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Split a dataset of out-of-sample predictions by estimate_type — split_yi_subsets","text":"tibble --sample predictions subset estimate_type stored list-column data.","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/split_yi_subsets.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Split a dataset of out-of-sample predictions by estimate_type — split_yi_subsets","text":"function used split dataset --sample predictions estimate_type, --sample predictions stored list-column called back_transformed_data, one data frame data per analysis submission. estimate_type derived either scenario SurveyID columns back_transformed_data dataset. estimate_type used nest data estimate_type list-column data. Removes unnecessary data .data: augmented_data checks.","code":""},{"path":[]},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/split_yi_subsets.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Split a dataset of out-of-sample predictions by estimate_type — split_yi_subsets","text":"Elliot Gould","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/subset_fns_Zr.html","id":null,"dir":"Reference","previous_headings":"","what":"Subsetting Functions for effect-size meta-analysis — subset_fns_Zr","title":"Subsetting Functions for effect-size meta-analysis — subset_fns_Zr","text":"Generates list functions used subset processed ManyEcoEvo dataset","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/subset_fns_Zr.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Subsetting Functions for effect-size meta-analysis — subset_fns_Zr","text":"","code":"subset_fns_Zr()"},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/subset_fns_Zr.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Subsetting Functions for effect-size meta-analysis — subset_fns_Zr","text":"named list lambda functions","code":""},{"path":[]},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/subset_fns_yi.html","id":null,"dir":"Reference","previous_headings":"","what":"Subsetting Functions for out-of-sample predictions meta-analysis — subset_fns_yi","title":"Subsetting Functions for out-of-sample predictions meta-analysis — subset_fns_yi","text":"Generates list functions used subset processed ManyEcoEvo dataset (e.g.data(ManyEcoEvo_results) containing --sample predictions $y_i$.","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/subset_fns_yi.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Subsetting Functions for out-of-sample predictions meta-analysis — subset_fns_yi","text":"","code":"subset_fns_yi()"},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/subset_fns_yi.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Subsetting Functions for out-of-sample predictions meta-analysis — subset_fns_yi","text":"named list lambda functions","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/subset_fns_yi.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Subsetting Functions for out-of-sample predictions meta-analysis — subset_fns_yi","text":"subset functions used filter predictions included meta-analysis.","code":""},{"path":[]},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/summarise_analyses_by_reviewer.html","id":null,"dir":"Reference","previous_headings":"","what":"Summarise analyses reviewed by reviewer — summarise_analyses_by_reviewer","title":"Summarise analyses reviewed by reviewer — summarise_analyses_by_reviewer","text":"Summarise analyses reviewed reviewer","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/summarise_analyses_by_reviewer.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summarise analyses reviewed by reviewer — summarise_analyses_by_reviewer","text":"","code":"summarise_analyses_by_reviewer(review_data)"},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/summarise_analyses_by_reviewer.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summarise analyses reviewed by reviewer — summarise_analyses_by_reviewer","text":"review_data dataframe containing variables dataset, response_id, ReviewerId.","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/summarise_analyses_by_reviewer.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Summarise analyses reviewed by reviewer — summarise_analyses_by_reviewer","text":"dataframe summarising mean, sd, min, max number reviews provided unique reviewer across analyses datasets review_data.","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/summarise_analyses_by_reviewer.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Summarise analyses reviewed by reviewer — summarise_analyses_by_reviewer","text":"","code":"data(ManyEcoEvo) ManyEcoEvo %>%   ungroup() %>%   select(data, -dataset) %>%   unnest(data) %>%   select(ends_with(\"_id\"), id_col, dataset, review_data) %>%   unnest(review_data) %>%   summarise_analyses_by_reviewer() #> # A tibble: 1 × 4 #>    mean    sd   min   max #>   <dbl> <dbl> <int> <int> #> 1  4.29  1.83     1    15"},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/summarise_analysis_types.html","id":null,"dir":"Reference","previous_headings":"","what":"Summarise Analysis Types — summarise_analysis_types","title":"Summarise Analysis Types — summarise_analysis_types","text":"Generates summary number analysis teams, total analyses, models normal error distributions, mixed effects models, models developed using Bayesian statistical methods given analysis type.","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/summarise_analysis_types.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summarise Analysis Types — summarise_analysis_types","text":"","code":"summarise_analysis_types(ManyEcoEvo_results, ManyEcoEvo_yi_results, ManyEcoEvo)"},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/summarise_analysis_types.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summarise Analysis Types — summarise_analysis_types","text":"ManyEcoEvo_results tibble ManyEcoEvo_results ManyEcoEvo_yi_results tibble ManyEcoEvo_yi_results ManyEcoEvo tibble ManyEcoEvo","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/summarise_analysis_types.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Summarise Analysis Types — summarise_analysis_types","text":"summarised tibble variables subset, dataset, num_teams, total_analyses, sum_linear, sum_mixed, sum_Bayesian.","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/summarise_analysis_types.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Summarise Analysis Types — summarise_analysis_types","text":"Applies count_binary_coded_features() count_teams_analyses() generate data summaries.","code":""},{"path":[]},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/summarise_analysis_types.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Summarise Analysis Types — summarise_analysis_types","text":"Hannah S. Fraser Elliot Gould","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/summarise_analysis_types.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Summarise Analysis Types — summarise_analysis_types","text":"","code":"summarise_analysis_types(ManyEcoEvo_results, ManyEcoEvo_yi_results, ManyEcoEvo) #> Error in group_by(., estimate_type, dataset): Must group by variables found in `.data`. #> Column `estimate_type` is not found. #> Column `dataset` is not found."},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/summarise_conclusions.html","id":null,"dir":"Reference","previous_headings":"","what":"Summarise counts of qualitative conclusions across all datasets — summarise_conclusions","title":"Summarise counts of qualitative conclusions across all datasets — summarise_conclusions","text":"Summarise counts qualitative conclusions across datasets","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/summarise_conclusions.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summarise counts of qualitative conclusions across all datasets — summarise_conclusions","text":"","code":"summarise_conclusions(ManyEcoEvo_results, ManyEcoEvo_yi_results, ManyEcoEvo)"},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/summarise_conclusions.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summarise counts of qualitative conclusions across all datasets — summarise_conclusions","text":"ManyEcoEvo_results tibble ManyEcoEvo_results ManyEcoEvo_yi_results tibble ManyEcoEvo_yi_results ManyEcoEvo tibble ManyEcoEvo","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/summarise_conclusions.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Summarise counts of qualitative conclusions across all datasets — summarise_conclusions","text":"dataframe count values unique Conclusion columns subset (\"effects\", \"predictions\", \"\"), dataset.","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/summarise_conclusions.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Summarise counts of qualitative conclusions across all datasets — summarise_conclusions","text":"Data summary generated summarise_conclusions_data().","code":""},{"path":[]},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/summarise_conclusions.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Summarise counts of qualitative conclusions across all datasets — summarise_conclusions","text":"Hannah S. Fraser Elliot Gould","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/summarise_conclusions.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Summarise counts of qualitative conclusions across all datasets — summarise_conclusions","text":"","code":"data(ManyEcoEvo_results) data(ManyEcoEvo_yi_results) data(ManyEcoEvo) summarise_conclusions(ManyEcoEvo_results, ManyEcoEvo_yi_results, ManyEcoEvo) #> Error in filter(., exclusion_set == \"complete\", ): ℹ In argument: `exclusion_set == \"complete\"`. #> Caused by error: #> ! object 'exclusion_set' not found"},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/summarise_conclusions_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Count qualitative conclusions across all analyses for each dataset — summarise_conclusions_data","title":"Count qualitative conclusions across all analyses for each dataset — summarise_conclusions_data","text":"Count qualitative conclusions across analyses dataset","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/summarise_conclusions_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Count qualitative conclusions across all analyses for each dataset — summarise_conclusions_data","text":"","code":"summarise_conclusions_data(data)"},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/summarise_conclusions_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Count qualitative conclusions across all analyses for each dataset — summarise_conclusions_data","text":"data dataframe containing columns split_id, analysis_id, dataset, Conclusion","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/summarise_conclusions_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Count qualitative conclusions across all analyses for each dataset — summarise_conclusions_data","text":"dataframe counts n unique value Conclusion dataset","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/summarise_conclusions_data.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Count qualitative conclusions across all analyses for each dataset — summarise_conclusions_data","text":"Hannah S. Fraser Elliot Gould","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/summarise_conclusions_data.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Count qualitative conclusions across all analyses for each dataset — summarise_conclusions_data","text":"","code":"data(ManyEcoEvo) ManyEcoEvo$data[[1]] %>%   filter(Conclusion != \"CHECK\") %>%   summarise_conclusions_data() #> # A tibble: 5 × 3 #>   dataset  Conclusion     n #>   <chr>    <chr>      <int> #> 1 blue tit mixed          5 #> 2 blue tit neg_c         37 #> 3 blue tit neg_q         27 #> 4 blue tit none_c         4 #> 5 blue tit none_q         1"},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/summarise_model_composition.html","id":null,"dir":"Reference","previous_headings":"","what":"Summarise Model Composition — summarise_model_composition","title":"Summarise Model Composition — summarise_model_composition","text":"Calculate descriptive statistics (mean, sd, min, max) number fixed effects, number random effects, number interactions sample size models dataset across sample predictions standardized corelation coefficients.","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/summarise_model_composition.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summarise Model Composition — summarise_model_composition","text":"","code":"summarise_model_composition(   ManyEcoEvo_results,   ManyEcoEvo_yi_results,   ManyEcoEvo )"},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/summarise_model_composition.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summarise Model Composition — summarise_model_composition","text":"ManyEcoEvo_results tibble ManyEcoEvo_results ManyEcoEvo_yi_results tibble ManyEcoEvo_yi_results ManyEcoEvo tibble ManyEcoEvo","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/summarise_model_composition.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Summarise Model Composition — summarise_model_composition","text":"dataframe","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/summarise_model_composition.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Summarise Model Composition — summarise_model_composition","text":"Generates summary data summarise_model_composition_data().","code":""},{"path":[]},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/summarise_model_composition.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Summarise Model Composition — summarise_model_composition","text":"Hannah S. Fraser Elliot Gould","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/summarise_model_composition.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Summarise Model Composition — summarise_model_composition","text":"","code":"summarise_model_composition(ManyEcoEvo_results, ManyEcoEvo_yi_results, ManyEcoEvo) #> Error in group_by(., estimate_type, dataset): Must group by variables found in `.data`. #> Column `estimate_type` is not found. #> Column `dataset` is not found."},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/summarise_model_composition_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Summarise model composition for a single dataframe of out of sample predictions or out or effect sizes — summarise_model_composition_data","title":"Summarise model composition for a single dataframe of out of sample predictions or out or effect sizes — summarise_model_composition_data","text":"Summarise model composition single dataframe sample predictions effect sizes","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/summarise_model_composition_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summarise model composition for a single dataframe of out of sample predictions or out or effect sizes — summarise_model_composition_data","text":"","code":"summarise_model_composition_data(data)"},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/summarise_model_composition_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summarise model composition for a single dataframe of out of sample predictions or out or effect sizes — summarise_model_composition_data","text":"data dataframe variables dataset, num_fixed_effects, num_random_effects, num_interactions, sample_size","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/summarise_model_composition_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Summarise model composition for a single dataframe of out of sample predictions or out or effect sizes — summarise_model_composition_data","text":"dataframe tidy format yielding descriptive summary statistics (mean, sd, min max) key variables described data, includes variables subset, dataset, variable, fn, value","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/summarise_model_composition_data.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Summarise model composition for a single dataframe of out of sample predictions or out or effect sizes — summarise_model_composition_data","text":"Hannah S. Fraser Elliot Gould","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/summarise_model_composition_data.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Summarise model composition for a single dataframe of out of sample predictions or out or effect sizes — summarise_model_composition_data","text":"","code":"ManyEcoEvo %>%   ungroup() %>%   filter(dataset == \"blue tit\") %>%   select(data) %>%   unnest(data) %>%   summarise_model_composition_data() #> # A tibble: 1 × 17 #>   dataset  fixed_mean fixed_sd fixed_min fixed_max random_mean random_sd #>   <chr>         <dbl>    <dbl>     <dbl>     <dbl>       <dbl>     <dbl> #> 1 blue tit       5.28     3.02         1        19        3.64      2.37 #> # ℹ 10 more variables: random_min <dbl>, random_max <dbl>, #> #   interactions_mean <dbl>, interactions_sd <dbl>, interactions_min <dbl>, #> #   interactions_max <dbl>, n_mean <dbl>, n_sd <dbl>, n_min <dbl>, n_max <dbl>"},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/summarise_reviews.html","id":null,"dir":"Reference","previous_headings":"","what":"Summarise Peer-Reviews — summarise_reviews","title":"Summarise Peer-Reviews — summarise_reviews","text":"Calculates summary statistics (mean, sd, min, max) number analyses peer-reviewed reviewer, number reviews received analysis.","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/summarise_reviews.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summarise Peer-Reviews — summarise_reviews","text":"","code":"summarise_reviews(ManyEcoEvo, ManyEcoEvo_results, ManyEcoEvo_yi_results)"},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/summarise_reviews.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summarise Peer-Reviews — summarise_reviews","text":"ManyEcoEvo tibble ManyEcoEvo ManyEcoEvo_results tibble ManyEcoEvo_results ManyEcoEvo_yi_results tibble ManyEcoEvo_yi_results","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/summarise_reviews.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Summarise Peer-Reviews — summarise_reviews","text":"named list length two summarised_data_analyses containing tibble summary statistics outcome subset (effects predictions) generated summarise_analyses_by_reviewer(), summarised_data_reviews containing tibble sumary statistics outcome subset, dataset generated summarise_reviews_per_analysis().","code":""},{"path":[]},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/summarise_reviews.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Summarise Peer-Reviews — summarise_reviews","text":"Hannah S. Fraser Elliot Gould","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/summarise_reviews.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Summarise Peer-Reviews — summarise_reviews","text":"","code":"data(ManyEcoEvo) data(ManyEcoEvo_results) data(ManyEcoEvo_yi_results) summarise_reviews(ManyEcoEvo, ManyEcoEvo_results, ManyEcoEvo_yi_results) #> Error in group_by(., estimate_type, dataset): Must group by variables found in `.data`. #> Column `estimate_type` is not found. #> Column `dataset` is not found."},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/summarise_reviews_per_analysis.html","id":null,"dir":"Reference","previous_headings":"","what":"Summarise reviews per each analysis — summarise_reviews_per_analysis","title":"Summarise reviews per each analysis — summarise_reviews_per_analysis","text":"Summarise reviews per analysis","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/summarise_reviews_per_analysis.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summarise reviews per each analysis — summarise_reviews_per_analysis","text":"","code":"summarise_reviews_per_analysis(review_data)"},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/summarise_reviews_per_analysis.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summarise reviews per each analysis — summarise_reviews_per_analysis","text":"review_data dataframe containing variables dataset, response_id, ReviewerId.","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/summarise_reviews_per_analysis.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Summarise reviews per each analysis — summarise_reviews_per_analysis","text":"dataframe variables dataset, mean, sd, min, max number times analysis reviewed","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/summarise_reviews_per_analysis.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Summarise reviews per each analysis — summarise_reviews_per_analysis","text":"","code":"data(ManyEcoEvo) ManyEcoEvo %>%   ungroup() %>%   select(data, -dataset) %>%   unnest(data) %>%   select(ends_with(\"_id\"), id_col, dataset, review_data) %>%   unnest(review_data) %>%   summarise_reviews_per_analysis() #> # A tibble: 2 × 5 #>   dataset     mean    sd   min   max #>   <chr>      <dbl> <dbl> <int> <int> #> 1 blue tit    3.86 0.773     2     6 #> 2 eucalyptus  4.03 0.880     2     6"},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/summarise_sorensen_index.html","id":null,"dir":"Reference","previous_headings":"","what":"Summarise Mean Sorensen's Index Estimates — summarise_sorensen_index","title":"Summarise Mean Sorensen's Index Estimates — summarise_sorensen_index","text":"Summarise Mean Sorensen's Index Estimates","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/summarise_sorensen_index.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summarise Mean Sorensen's Index Estimates — summarise_sorensen_index","text":"","code":"summarise_sorensen_index(ManyEcoEvo_results, ManyEcoEvo_yi_results)"},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/summarise_sorensen_index.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summarise Mean Sorensen's Index Estimates — summarise_sorensen_index","text":"ManyEcoEvo_results tibble ManyEcoEvo_results ManyEcoEvo_yi_results tibble ManyEcoEvo_yi_results","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/summarise_sorensen_index.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Summarise Mean Sorensen's Index Estimates — summarise_sorensen_index","text":"tibble aggregate summary statistics (mean, sd, min, max) mean Sorensen's index estimates across subset dataset.","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/summarise_sorensen_index.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Summarise Mean Sorensen's Index Estimates — summarise_sorensen_index","text":"Generates data summary summarise_sorensen_index_data().","code":""},{"path":[]},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/summarise_sorensen_index.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Summarise Mean Sorensen's Index Estimates — summarise_sorensen_index","text":"Hannah S. Fraser Elliot Gould","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/summarise_sorensen_index.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Summarise Mean Sorensen's Index Estimates — summarise_sorensen_index","text":"","code":"summarise_sorensen_index(ManyEcoEvo_results, ManyEcoEvo_yi_results) #> Error in filter(., exclusion_set == \"complete\"): ℹ In argument: `exclusion_set == \"complete\"`. #> Caused by error: #> ! object 'exclusion_set' not found"},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/summarise_sorensen_index_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Summarise Sorensen's Mean Index Estimates for a dataframe — summarise_sorensen_index_data","title":"Summarise Sorensen's Mean Index Estimates for a dataframe — summarise_sorensen_index_data","text":"Summarises Sorensen's index estimates single dataframe estimates","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/summarise_sorensen_index_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summarise Sorensen's Mean Index Estimates for a dataframe — summarise_sorensen_index_data","text":"","code":"summarise_sorensen_index_data(data)"},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/summarise_sorensen_index_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summarise Sorensen's Mean Index Estimates for a dataframe — summarise_sorensen_index_data","text":"data dataframe containing mean_diversity_index Sorensen's index estimates analysis id_col, dataset.","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/summarise_sorensen_index_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Summarise Sorensen's Mean Index Estimates for a dataframe — summarise_sorensen_index_data","text":"dataframe mean, sd, min, max mean Sorensen's index values dataset.","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/summarise_sorensen_index_data.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Summarise Sorensen's Mean Index Estimates for a dataframe — summarise_sorensen_index_data","text":"","code":"ManyEcoEvo_results %>%   filter(     exclusion_set == \"complete\",     publishable_subset == \"All\",     expertise_subset == \"All\"   ) %>%   ungroup() %>%   select(dataset, diversity_indices) %>%   unnest(diversity_indices) %>%   summarise_sorensen_index_data() #> # A tibble: 2 × 5 #>   dataset     mean     sd   min   max #>   <chr>      <dbl>  <dbl> <dbl> <dbl> #> 1 blue tit   0.591 0.0972 0.431 0.859 #> 2 eucalyptus 0.690 0.0839 0.548 0.982"},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/summarise_study.html","id":null,"dir":"Reference","previous_headings":"","what":"Summarise ManyAnalyst study data — summarise_study","title":"Summarise ManyAnalyst study data — summarise_study","text":"Summarises ManyAnalyst study data calculating summary statistics subset data.","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/summarise_study.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summarise ManyAnalyst study data — summarise_study","text":"","code":"summarise_study(   ManyEcoEvo,   ManyEcoEvo_results,   id_subsets,   subset_names,   filter_vars = NULL )"},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/summarise_study.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summarise ManyAnalyst study data — summarise_study","text":"ManyEcoEvo ManyAnalyst style tibble containing data analysed. ManyEcoEvo_results ManyAnalyst results style tibble containing results data analysed. id_subsets list tibbles containing id_col subset data. subset_names character vector equal length id_subsets; name data subsets id_subsets. filter_vars list expressions filter ManyEcoEvo_results data","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/summarise_study.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Summarise ManyAnalyst study data — summarise_study","text":"tibble containing summary statistics subset data.","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/summarise_study.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Summarise ManyAnalyst study data — summarise_study","text":"","code":"id_subsets <- list(ManyEcoEvo:::effect_ids, ManyEcoEvo:::prediction_ids) subset_names <- c(\"effects\", \"predictions\") filter_vars <- rlang::exprs(   exclusion_set == \"complete\",   estimate_type == \"Zr\",   publishable_subset == \"All\",   expertise_subset == \"All\",   collinearity_subset == \"All\" ) summarise_study(ManyEcoEvo::ManyEcoEvo, ManyEcoEvo::ManyEcoEvo_results, id_subsets, subset_names, filter_vars = filter_vars) #> # A tibble: 3 × 9 #>   subset_name data                n_teams sorensen_summary teams_per_subset   #>   <chr>       <list>                <int> <list>           <list>             #> 1 all         <tibble [302 × 40]>     145 <tibble [2 × 5]> <tibble [146 × 3]> #> 2 effects     <tibble [210 × 40]>     102 <tibble [2 × 5]> <tibble [103 × 3]> #> 3 predictions <tibble [88 × 40]>       56 <tibble [2 × 5]> <tibble [57 × 3]>  #> # ℹ 4 more variables: conclusions_summary <list>, #> #   variable_count_summary <list>, model_term_summary <list>, #> #   model_type_summary <list>"},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/summarise_variable_counts.html","id":null,"dir":"Reference","previous_headings":"","what":"Summarise variable usage across analyses — summarise_variable_counts","title":"Summarise variable usage across analyses — summarise_variable_counts","text":"Using count_analyses_variables_used() calculates counts analyses variable used given dataset. summarisation counts ( mean, sd, min max) optional, see details.","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/summarise_variable_counts.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summarise variable usage across analyses — summarise_variable_counts","text":"","code":"summarise_variable_counts(   ManyEcoEvo,   ManyEcoEvo_results,   ManyEcoEvo_yi_results,   output = \"count\" )"},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/summarise_variable_counts.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summarise variable usage across analyses — summarise_variable_counts","text":"ManyEcoEvo tibble ManyEcoEvo ManyEcoEvo_results tibble ManyEcoEvo_results ManyEcoEvo_yi_results tibble ManyEcoEvo_yi_results output length 1 character vector equal \"count\" \"aggregate\"","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/summarise_variable_counts.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Summarise variable usage across analyses — summarise_variable_counts","text":"dataframe count values n summary statistic values n_mean,n_sd,n_min,n_max counts depending value supplied output argument.","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/summarise_variable_counts.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Summarise variable usage across analyses — summarise_variable_counts","text":"calculate count values, supply \"count\" argument output. calculate summary statistics counts, supply \"aggregate\" argument output instead.","code":""},{"path":[]},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/summarise_variable_counts.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Summarise variable usage across analyses — summarise_variable_counts","text":"Hannah S. Fraser Elliot Gould","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/summarise_variable_counts.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Summarise variable usage across analyses — summarise_variable_counts","text":"","code":"summarise_variable_counts(ManyEcoEvo, ManyEcoEvo_results, ManyEcoEvo_yi_results, \"count\") #> Error in group_by(., estimate_type, dataset): Must group by variables found in `.data`. #> Column `estimate_type` is not found. #> Column `dataset` is not found.  summarise_variable_counts(ManyEcoEvo, ManyEcoEvo_results, ManyEcoEvo_yi_results, \"aggregate\") #> Error in group_by(., estimate_type, dataset): Must group by variables found in `.data`. #> Column `estimate_type` is not found. #> Column `dataset` is not found."},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/validate.html","id":null,"dir":"Reference","previous_headings":"","what":"Validating analyst-submitted predictions — validate","title":"Validating analyst-submitted predictions — validate","text":"Validates structure analyst-submitted predictions, ensuring required columns present correct format.","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/validate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Validating analyst-submitted predictions — validate","text":"","code":"validate_predictions_df_blue_tit(input, type = \"filepath\")  validate_predictions_df_euc(input, type = \"filepath\")  validate_predictions(data_set, input, type = \"filepath\")"},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/validate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Validating analyst-submitted predictions — validate","text":"input Either filepath dataframe, corresponding type argument specification type character string length 1, equal either \"filepath\" \"df\". Defaults \"filepath\" data_set dataset analysed, either \"blue tit\" \"eucalyptus\"","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/validate.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Validating analyst-submitted predictions — validate","text":"pointblank agent, class ptblank_agent, yet interrogated","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/validate.html","id":"functions","dir":"Reference","previous_headings":"","what":"Functions","title":"Validating analyst-submitted predictions — validate","text":"validate_predictions_df_blue_tit(): Validate Blue tit predictions data validate_predictions_df_euc(): Validate Eucalyptus predictions data validate_predictions(): Wrapper-function validate_predictions_df_euc() validate_predictions_df_blue_tit()","code":""},{"path":[]},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/variance_box_cox.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate the variance of the Box-Cox transformed absolute deviation scores — variance_box_cox","title":"Calculate the variance of the Box-Cox transformed absolute deviation scores — variance_box_cox","text":"Calculate variance Box-Cox transformed absolute deviation scores","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/variance_box_cox.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate the variance of the Box-Cox transformed absolute deviation scores — variance_box_cox","text":"","code":"variance_box_cox(folded_mu, folded_v, lambda)"},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/variance_box_cox.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate the variance of the Box-Cox transformed absolute deviation scores — variance_box_cox","text":"folded_mu mean folded absolute deviation scores folded_v variance folded VZr lambda lambda value used Box-Cox transformation","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/reference/variance_box_cox.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate the variance of the Box-Cox transformed absolute deviation scores — variance_box_cox","text":"variance Box-Cox transformed absolute deviation scores","code":""},{"path":[]},{"path":"https://egouldo.github.io/ManyEcoEvo/news/index.html","id":"manyecoevo-273","dir":"Changelog","previous_headings":"","what":"ManyEcoEvo 2.7.3","title":"ManyEcoEvo 2.7.3","text":"Fix #136 generate Zr outlier subsets exclusion_set == \"complete\", exclusion_set == \"partial\"","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/news/index.html","id":"manyecoevo-272","dir":"Changelog","previous_headings":"","what":"ManyEcoEvo 2.7.2","title":"ManyEcoEvo 2.7.2","text":"separated column creation occur three conditions: NULL outcome_variable supplied, character string supplied, expression argument supplied separated subset creation occur separately results conditional evaluation Added conditional behaviour character vector supplied feat!: added arg checks #116 cli output condition triggered explicitly supply outcome_variable outcome_SE args Zr #118 docs: Add explanation updated behaviour estimate_type missing ManyEcoEvo dataframe #118 build: devtools::document()","code":""},{"path":"https://egouldo.github.io/ManyEcoEvo/news/index.html","id":"manyecoevo-260","dir":"Changelog","previous_headings":"","what":"ManyEcoEvo 2.6.0","title":"ManyEcoEvo 2.6.0","text":"Update arg supply targets call prepare_response_variables() #118 updates #118 add pmap internal helper function differential application transformation / standardisation standardise_response() #118 delete old pmap helper function dat data help auto-matching pmap within prepare_response_variables() wrapper #118 ensure family fns … arg pmap application prepare_response_variables() since fns different argument lengths names accidentally deleted upgrading #118, added creation transform_datasets tibbles cases now, apply appropriate functions final code chunk end #118 ensure application Z_VZ_preds takes generalised colnames yi, yi_se instead using hard-coded dataset application #97 #118 call new arg dataset_log_transform fn log-transform outcomes euc yi analysis #118 add log-transformation equivalent standardise_response() process_resonse() #102 add function documentation, including examples #118 extract lower upper transformed vals line addition log_transform_response() / changes standardise_response() #116 check appropriate required variable (.e. function needs back_transformed_data, checked augmented_data dat arg, wouldn’t throw required error augmented_data present dat #102 add import, return, see also roxygen doc tags, replace note details tag, rename fn doc title #116 update argument checks conditional expression #118 match output log_transform_yi() (now returns additional cols lower upper, c(\"Z\",\"VZ\")) #118 match process log_transform_yi() #97 generalise processing euc/bt datasets without hard-coding dataset names fns, remove associated dataset-specific argument checking #116 #118 adapt response variable preparation accept additional argument dataset_log_transform apply argument checks #116, add roxygen param #102 #118 adapt response variable processing accept either//none dataset standardisation/log-transformation. equivalent pred_to_z() #102 write documentation #102 add import tags log_transform() link equivalent functions, apply default argument values / checks #97 rename argument","code":""}]
